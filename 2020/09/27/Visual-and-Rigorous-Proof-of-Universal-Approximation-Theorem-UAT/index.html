<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Acknowledgement: This course (CSCI 8980) is being offered by Prof. Ju Sun at the University of Minnesota in Fall 2020. Pictures of slides are from the course.   Gaoxiang: This lecture is scribed by m">
<meta property="og:type" content="article">
<meta property="og:title" content="Visual and Rigorous Proof of Universal Approximation Theorem (UAT)">
<meta property="og:url" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/index.html">
<meta property="og:site_name" content="Leon">
<meta property="og:description" content="Acknowledgement: This course (CSCI 8980) is being offered by Prof. Ju Sun at the University of Minnesota in Fall 2020. Pictures of slides are from the course.   Gaoxiang: This lecture is scribed by m">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/general_view_and_nn_view.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/figure1.png">
<meta property="og:image" content="https://math.now.sh?inline=f_0">
<meta property="og:image" content="https://math.now.sh?inline=f_0">
<meta property="og:image" content="https://math.now.sh?inline=H">
<meta property="og:image" content="https://math.now.sh?inline=H">
<meta property="og:image" content="https://math.now.sh?inline=f%20%5Cin%20H">
<meta property="og:image" content="https://math.now.sh?inline=f_0">
<meta property="og:image" content="https://math.now.sh?inline=H">
<meta property="og:image" content="https://math.now.sh?inline=f_0">
<meta property="og:image" content="https://math.now.sh?inline=f">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/figure2.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cmapsto%20%5Cmathbb%20R">
<meta property="og:image" content="https://math.now.sh?inline=f">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma">
<meta property="og:image" content="https://math.now.sh?inline=%5Cleft%5C%7B%5Cmathbf%20x%20%5Cmapsto%20%5Csigma%28%5Cmathbf%20w%5E%5Cintercal%20%5Cmathbf%20x%20%2B%20b%29%20%5Cright%5C%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/figure3.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cleft%5C%7B%5Cmathbb%20x%20%5Cmapsto%20%5Cfrac%7B1%7D%7B1%2B%20e%5E%7B-%5Cleft%28%20%5Cmathbb%20w%5E%5Cintercal%20%5Cmathbb%20x%20%2B%20b%20%5Cright%29%7D%7D%20%5Cright%5C%7D">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/figure4.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma%5Cleft%28%20%5Cmathbb%20w_L%5E%5Cintercal%20%5Cleft(%20%5Cmathbb%20W_%7BL-1%7D%20%20%20%5Cleft(%20%5Cdots%20%20%5Cleft(%20%5Cmathbb%20W_1%20%5Cmathbb%20x%20%2B%20%5Cmathbb%20b_1%20%5Cright%29%20%2B%20%5Cdots%20%5Cright)%20%20%5Cmathbb%20b_%7BL-1%7D%20%20%20%20%5Cright)%20%20%2B%20b_L%20%5Cright)">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/1d.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%20%5Cto%20%5Cmathbb%20R">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma%20%3D%20%5Cfrac%7B1%7D%7B1%2B%20e%5E%7B-%5Cleft%28%20%5Cmathbb%20w%5E%5Cintercal%20%5Cmathbb%20x%20%2B%20b%20%5Cright%29%7D%7D">
<meta property="og:image" content="https://math.now.sh?inline=w">
<meta property="og:image" content="https://math.now.sh?inline=b">
<meta property="og:image" content="https://math.now.sh?inline=w_2">
<meta property="og:image" content="https://math.now.sh?inline=w_1">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/figure5.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/2d.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%5E2%20%5Cto%20%5Cmathbb%20R">
<meta property="og:image" content="https://math.now.sh?inline=h">
<meta property="og:image" content="https://math.now.sh?inline=2h">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/figure67.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%5E2">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%5En">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cto%20%5Cmathbb%20R%5Em">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cto%20%5Cmathbb%20R">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/theorem01.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma">
<meta property="og:image" content="https://math.now.sh?inline=%5Cvarepsilon">
<meta property="og:image" content="https://math.now.sh?inline=f">
<meta property="og:image" content="https://math.now.sh?inline=F">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/diff.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Csigma">
<meta property="og:image" content="https://math.now.sh?inline=%5Cleft%7C%20f%28x%29%20-%20f(y)%20%5Cright%7C%20%5Cle%20%5Cleft%7C%20x%20-%20y%20%5Cright%7C%2C%20%5Cforall%5C%3B%20x%2C%20y%20%5Cin%20%5Cmathbb%7BR%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5E1">
<meta property="og:image" content="https://math.now.sh?inline=%5Cvarepsilon">
<meta property="og:image" content="https://math.now.sh?inline=%5Cfrac%7B1%7D%7B%5Cvarepsilon%7D">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28%5Cvarepsilon%5E%7B-2%7D%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28%5Cvarepsilon%5E%7B-n%7D%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28n%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28a%5En%29">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/two_class_fun.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/thm1.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/thm2.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/pro2.png">
<meta property="og:image" content="https://math.now.sh?inline=n">
<meta property="og:image" content="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/thm13.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/reference.png">
<meta property="article:published_time" content="2020-09-28T02:16:59.000Z">
<meta property="article:modified_time" content="2020-10-02T06:05:58.040Z">
<meta property="article:author" content="Gaoxiang Luo">
<meta property="article:tag" content="Study Note">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Neural Network">
<meta property="article:tag" content="Theory">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/general_view_and_nn_view.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Visual and Rigorous Proof of Universal Approximation Theorem (UAT)</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Leon" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2020/09/29/Data-Mining-Bayesian-Classifiers/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/09/25/Data-Mining-Classification-with-Decision-Tree/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&text=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&is_video=false&description=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)&body=Check out this article: https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&name=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&t=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Why should we trust Neural Networks (NNs)?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Why should UAT hold?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">UAT in rigorous form</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">From shallow to deep Neural Networks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">Reference</span></a></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Visual and Rigorous Proof of Universal Approximation Theorem (UAT)
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Leon</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2020-09-28T02:16:59.000Z" itemprop="datePublished">2020-09-27</time>
        
        (Updated: <time datetime="2020-10-02T06:05:58.040Z" itemprop="dateModified">2020-10-02</time>)
        
      
    </div>


      

      
    <div class="article-tag">
        <i class="fas fa-tag"></i>
        <a class="tag-link-link" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a>, <a class="tag-link-link" href="/tags/Neural-Network/" rel="tag">Neural Network</a>, <a class="tag-link-link" href="/tags/Study-Note/" rel="tag">Study Note</a>, <a class="tag-link-link" href="/tags/Theory/" rel="tag">Theory</a>
    </div>


    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <blockquote>
<p>Acknowledgement: This course (CSCI 8980) is being offered by <a target="_blank" rel="noopener" href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p>
</blockquote>
<blockquote>
<p>Gaoxiang: This lecture is scribed by myself and Andrew Walker.</p>
</blockquote>
<h1>Why should we trust Neural Networks (NNs)?</h1>
<p>We will start by looking at the supervised learning. Although today’s NNs are not only for the supervised learning, we will use this embedded illustration from machine learning to give you some ideas.</p>
<p><img src="general_view_and_nn_view.png" alt="general_view_and_nn_view"><br>
As shown above, the only difference between these two views is that we choose a NN architecture instead of selecting a family of functions. The idea behind both views is function approximation, and we want to emphasize more in function approximation to give you a more accurate description of supervised learning.</p>
<p><img src="figure1.png" alt="figure1"><br>
Basically you can think of supervised learning in this way. First of all, we have an underlying true function <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and our data can be generated by <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with dense sampling, which are the blue dots in above. Second, we choose a family of functions <img src="https://math.now.sh?inline=H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. The purpose here is to learn from this family <img src="https://math.now.sh?inline=H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to find a function <img src="https://math.now.sh?inline=f%20%5Cin%20H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (orange curve) that is close to the ground truth function <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. This is different with the views mentioned earlier. Those views are to fit the data, which is more about the training error. But here if you really find the ground truth function by learning, you will do perfectly well on eliminating test error.</p>
<p>There are two aspects of this more accurate description. Does our family of functions <img src="https://math.now.sh?inline=H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> really have the power to find <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? This is what we called <strong>Approximation Capacity</strong>. Another important aspect to consider is <strong>Optimization &amp; Generalization</strong>, because sometimes even you choose a powerful function class, it does not guarantee that you will find the best <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Since optimization will be covered later in this class, now let us look at the capacity of our family functions.</p>
<p>Before we look at the capacity of NN, let us clarify some notations.</p>
<ul>
<li>k-layer NNs: with k layers of weights (along the deepest path)</li>
<li>k-hidden-layer NNs: with k hidden layers of nodes</li>
</ul>
<p><img src="figure2.png" alt="figure2"><br>
Now let us think of a single-output (i.e., <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cmapsto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) problem, and we can start with one neuron. It’s basically summing up all input with weights, add a threshold/offset, and pass through a non-linear function <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> which is called the activation function <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. As <img src="https://math.now.sh?inline=%5Cleft%5C%7B%5Cmathbf%20x%20%5Cmapsto%20%5Csigma%28%5Cmathbf%20w%5E%5Cintercal%20%5Cmathbf%20x%20%2B%20b%29%20%5Cright%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> shown, the output that a single neuron can represent largely depends on what kind of activation function <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> we have. If we choose an identity function, it will turn out to be linear, which is not powerful. If we choose a sign function like perceptron, which is a 0/1 function with hyperplane threshold, it has some constrain as well.</p>
<p><img src="figure3.png" alt="figure3"><br>
For instance, if we have 1s on 1-quadrant and 3-quadrant, and 0s on 2-quadrant and 4-quadrant, we cannot draw a line to classify these two classes. Even if we choose sigmoid function <img src="https://math.now.sh?inline=%5Cleft%5C%7B%5Cmathbb%20x%20%5Cmapsto%20%5Cfrac%7B1%7D%7B1%2B%20e%5E%7B-%5Cleft%28%20%5Cmathbb%20w%5E%5Cintercal%20%5Cmathbb%20x%20%2B%20b%20%5Cright%29%7D%7D%20%5Cright%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and ReLU, we still cannot solve the quadrants’ example mentioned earlier, because all of the functions above are monotonic in a certain direction (as shown in above), when the ground truth function, that we try to get close to, is not monotonic.</p>
<p><img src="figure4.png" alt="figure4"><br>
Instead of trying to think of a very complicated <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what if we add more layers like <img src="https://math.now.sh?inline=%5Csigma%5Cleft%28%20%5Cmathbb%20w_L%5E%5Cintercal%20%5Cleft(%20%5Cmathbb%20W_%7BL-1%7D%20%20%20%5Cleft(%20%5Cdots%20%20%5Cleft(%20%5Cmathbb%20W_1%20%5Cmathbb%20x%20%2B%20%5Cmathbb%20b_1%20%5Cright%29%20%2B%20%5Cdots%20%5Cright)%20%20%5Cmathbb%20b_%7BL-1%7D%20%20%20%20%5Cright)%20%20%2B%20b_L%20%5Cright)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? Adding depth alone is not going to help because it’s multiplying weights repeatedly, and composition of linear operation will still be linear. Therefore, we want to try not only adding layers but also adding nonlinearity into NNs. Surpassingly, this turns out to be really powerful. This leads to the fundamental belief of DNNs – <strong>Universal Approximation Theorem (UAT)</strong>. This theorem states:<br>
<strong>The 2-layer network can approximate arbitrary continuous functions arbitrarily well, provided that the hidden layer is sufficiently wide.</strong></p>
<h1>Why should UAT hold?</h1>
<p><img src="1d.png" alt="1d"><br>
The live demo is from <a target="_blank" rel="noopener" href="http://neuralnetworksanddeeplearning.com/chap4.html">http://neuralnetworksanddeeplearning.com/chap4.html</a>.<br>
Let us start with a single-input-single-output function <img src="https://math.now.sh?inline=%5Cmathbb%20R%20%5Cto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> using sigmoid <img src="https://math.now.sh?inline=%5Csigma%20%3D%20%5Cfrac%7B1%7D%7B1%2B%20e%5E%7B-%5Cleft%28%20%5Cmathbb%20w%5E%5Cintercal%20%5Cmathbb%20x%20%2B%20b%20%5Cright%29%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, whose graph is typically like (a). If we increase the value of <img src="https://math.now.sh?inline=w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> significantly, we will get a function which is almost the same as step function, as illustrated in (b). Next, if we change the value of <img src="https://math.now.sh?inline=b" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what we’re doing is moving the graph horizontally like ©. Now let us consider two neurons summing up in (d), which is similar to adding two step functions together. More interestingly, if we change the weight of <img src="https://math.now.sh?inline=w_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to the opposite of <img src="https://math.now.sh?inline=w_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, we will get a bump function in (e). Once we take more neurons into account, we will end up with lots of consecutive bumps in (f).</p>
<p><img src="figure5.png" alt="figure5"><br>
This is really similar to Riemann Sum while defining an integral, where you can draw a smooth curve passing through upper bound’s midpoint of the bump (Midpoint Rule) or the top-left corner of the bump (Trapezoidal Rule). Therefore, this 1-hidden layer NN is powerful enough to approximate many non-linear functions if we want to expend the number of neurons as many as we need. Now the question is how about high-dimensional?</p>
<p><img src="2d.png" alt="2d"><br>
The idea is similar in high dimensions. This is a two-inputs-one-output function <img src="https://math.now.sh?inline=%5Cmathbb%20R%5E2%20%5Cto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> using sigmoid. First of all, we turn off the weight in one direction, and the graph just looks like sigmoid in (1). If we again increase the weight sharply, we will get a step function in (2). Now let us turn on weight for another direction, and repeat the previous steps. What we get is is a bump function (two step functions in two orthogonal directions) in (3). Next, if we add more neurons to each direction, then there will be summing up of step functions in each direction, which will generally lead to summing up of bump functions in (4). We observe that if the height of a bump is <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then in (4) the highest bump is in height <img src="https://math.now.sh?inline=2h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Having comparing to the 1D case mentioned earlier, we want to get only the highest bump, which we call a tower in (5), by applying some offsets/cut-off positions. At this point, if we double the neurons in the hidden layer corresponding to each input, we’re able to get two towers. I believe you will get the idea at this point. More neurons in the hidden layers, more towers we can construct.</p>
<p><img src="figure67.png" alt="figure67"><br>
As shown in the left above, I believe you’re convinced that with 1 hidden layer, we can construct many towers (in this case, square towers as inputs are 2D), to approximate any 2D functions arbitrarily well. This is also what we called <strong>Shallow Network Networks</strong>, which is NN with 1 hidden layer. The example above in based on 2D input <img src="https://math.now.sh?inline=%5Cmathbb%20R%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what if we want to have high-dimensional input <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Then we don’t have to be as rigid as we were in only x and y directions to construct many square towers. As the input space increases, we could have had more cuts on our square towers then it will be closer and closer to many circle towers. At this point, you might ask what if the output space is also high-dimensional such as <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cto%20%5Cmathbb%20R%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> functions. The answer is we can approximate each <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> separately and then glue them together. I believe you’re convinced that a shallow NN or a 2-layer NN is already powerful enough, but one constrain obviously is that we need lots of neurons if we only have 1 hidden layer. Later we will introduce Deep Neural Networks (DNNs) and why we want to add one more hidden layer.</p>
<h1>UAT in rigorous form</h1>
<p>The Universal Approximation Theorem is a fundamental theorem underpinning the power behind the neural network’s prediction ability. The first formulation of the UAT (that has now developed into many variations) was developed in the late 1980’s. This section includes the mathematical discussion of the UAT.</p>
<p><img src="theorem01.png" alt="theorem01"><br>
Breaking this theorem down, we see <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is an activation function. The variable <img src="https://math.now.sh?inline=%5Cvarepsilon" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the arbitrary level of precision we would like to reach between our target function <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and our neural network function <img src="https://math.now.sh?inline=F" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. This theorem states that within the constraints, a single layer neural network with a large enough number of nodes can fit with arbitrarily small error any target function. The visual proof in the last section was intuitive, but the rigorous proof requires functional analysis and quadratic theory. We will not cover the rigorous proof in this course.</p>
<p>Notice the key limitations in the original formulation of the UAT — the target function must lie on the hypercube, the activation function must be non-constant, bounded, and continuous, the target function must be continuous. These statements have been somewhat addressed since the original formulation. The target function may lie on a space other than the hypercube; it just has to be compact (bounded and closed). A commonly-used activation function (ReLU) is not bounded, although a composition of ReLUs is. The target function needs to be continuous, although the classification problem is by definition discontinuous. However, the discontinuous classification can be approximated arbitrarily well by a very steep sigmoid function, for example.</p>
<p><img src="diff.png" alt="diff"><br>
In fact, the UAT has been found to apply for <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> as general as the set of all non-polynomial functions. [LLPS93]</p>
<h1>From shallow to deep Neural Networks</h1>
<p>The UAT says that a shallow, single-layer neural network can hit arbitrarily accurate levels of prediction. So why do we use multi-layer (or deep) neural networks? The UAT says the number of nodes is an integer N, but places no upper limit on N.</p>
<p>The value of N blows up very quickly for higher-dimensionality datasets. To show this, we return to our visual proof terminology. Assume our target function is 1-Lipschitz (essentially, it does not ever have a slope greater than 1 or -1. Formally: <img src="https://math.now.sh?inline=%5Cleft%7C%20f%28x%29%20-%20f(y)%20%5Cright%7C%20%5Cle%20%5Cleft%7C%20x%20-%20y%20%5Cright%7C%2C%20%5Cforall%5C%3B%20x%2C%20y%20%5Cin%20%5Cmathbb%7BR%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) and has a domain in <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5E1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. With this in mind, to achieve <img src="https://math.now.sh?inline=%5Cvarepsilon" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> accuracy, we need at most  <img src="https://math.now.sh?inline=%5Cfrac%7B1%7D%7B%5Cvarepsilon%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> bumps per unit length along the domain. For a 2D target function, we need <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28%5Cvarepsilon%5E%7B-2%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. In fact, in general, for a target function with domain n-Dimensions, we need <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28%5Cvarepsilon%5E%7B-n%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> bumps.</p>
<p>As you can see, this exponential growth makes single layer neural networks infeasible for higher dimension problems. The value of deep NNs is that they can provide much better computing power. In 2017, it was shown that DNNs can have the number of nodes <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28n%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> while 2-layer NNs need <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28a%5En%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for Boolean functions in domain <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p>
<p>To show this, we define two classes of functions —<br>
<img src="two_class_fun.png" alt="two_class_fun"></p>
<p>The 2017 theorems:<br>
<img src="thm1.png" alt="thm1"><br>
<img src="thm2.png" alt="thm2"><br>
These theorems essentially show (within the constraints) that shallow networks are exponential with respect to domain dimension and that deep networks are linear with respect to domain dimension.</p>
<p>Since we have covered so many variations on the UAT, you may be wondering, what is the most general variation of the UAT so far?<br>
<img src="pro2.png" alt="pro2"></p>
<p>This activation function must be continuous and not a polynomial. Then, given a target continuous function, you can find a shallow neural network that approximates the target function arbitrarily well.</p>
<p>However, deeper is not always better. Theorems [LPW+17][KL19]  have shown that to maintain the UAT property of arbitrary approximation power, deep networks need around <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> nodes per hidden layer in <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p>
<p><img src="thm13.png" alt="thm13"><br>
However, this is still an active area of research and in practice, the most optimal network is often forgone for a less theoretically optimal but still practically better option.</p>
<h1>Conclusion</h1>
<p>While designing your network, do not try to use these theorems and mathematical results to advise your design. Deep Learning is a very new and volatile field and it is often the case that researchers develop new architectures without knowing why they work, and later on mathematicians try to prove why a certain architecture is optimal.<br>
The reason we covered the UAT is so we get an understanding of why we can just take a neural network to approximate some function. If we have no other understanding of the target function, maybe a neural network would be a good choice.</p>
<h1>Reference</h1>
<p><img src="reference.png" alt="reference"></p>

  </div>
</article>


  <!-- Gitalk start  -->

  <!-- Link Gitalk files  -->
  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"/></script> 
  <div id="gitalk-container"></div>     
  <script type="text/javascript">
      var gitalk = new Gitalk({

        // gitalk's main params
        clientID: `3ce407f9c6ed6aaffdf8`,
        clientSecret: `2c6bc0465d806a6dc4ee20c9b1a0043d7a6101fe`,
        repo: `gaoxiangluo.github.io`,
        owner: 'GaoxiangLuo',
        admin: ['GaoxiangLuo'],
        id: location.pathname.slice(0, 50),
        distractionFreeMode: true,
        enableHotKey: true,
        language: `en`
      });
      gitalk.render('gitalk-container');
  </script> 
  <!-- Gitalk end -->




        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Why should we trust Neural Networks (NNs)?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">Why should UAT hold?</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">UAT in rigorous form</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">From shallow to deep Neural Networks</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">Reference</span></a></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&text=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&is_video=false&description=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)&body=Check out this article: https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&title=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&name=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://gaoxiangluo.github.io/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/&t=Visual and Rigorous Proof of Universal Approximation Theorem (UAT)"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2021
    Gaoxiang Luo
  </div>
  <!-- <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div> -->
  <div class="busuanzi-count">
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span class="site-pv">
      Page View <i class="fa fa-users"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
    <!-- <span class="site-uv">
      Number of Visitors <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuansi_value_site_uv"></span>
    </span> -->
  </div>
  <div class="Word-count">
    <i class="fas fa-chart-area"></i> Total count: </i><span class="post-count">18k</span>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-176745887-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400,"hOffset":5,"vOffset":-38},"mobile":{"show":false,"scale":0.2},"react":{"opacityDefault":0.8,"opacityOnHover":0.2},"log":false});</script></body>
</html>
