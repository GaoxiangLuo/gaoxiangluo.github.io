<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Acknowledgement: This course (CSCI 8980) is being offered by Prof. Ju Sun at the University of Minnesota in Fall 2020. Pictures of slides are from the course. The content of this blog is from one of">
<meta property="og:type" content="article">
<meta property="og:title" content="Applications of CNNs in Computer Vision">
<meta property="og:url" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/index.html">
<meta property="og:site_name" content="Gaoxiang Luo">
<meta property="og:description" content="Acknowledgement: This course (CSCI 8980) is being offered by Prof. Ju Sun at the University of Minnesota in Fall 2020. Pictures of slides are from the course. The content of this blog is from one of">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure1.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure2.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure3.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure4.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure5.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure6.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure7.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure8.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure9.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure10.png">
<meta property="article:published_time" content="2021-01-10T04:02:42.000Z">
<meta property="article:modified_time" content="2021-01-26T23:52:07.000Z">
<meta property="article:author" content="Gaoxiang Luo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/figure1.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Applications of CNNs in Computer Vision</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Gaoxiang Luo" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2021/03/25/I-wrote-an-interview-article-for-our-undergraduate-journal/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2021/01/08/Recurrent-Neural-Network-RNN-Overview/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&text=Applications of CNNs in Computer Vision"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&is_video=false&description=Applications of CNNs in Computer Vision"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Applications of CNNs in Computer Vision&body=Check out this article: https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&name=Applications of CNNs in Computer Vision&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&t=Applications of CNNs in Computer Vision"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Object Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-object-detection"><span class="toc-number">1.1.</span> <span class="toc-text">What is object detection?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Detection-Network"><span class="toc-number">1.2.</span> <span class="toc-text">Object Detection Network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Multiple-Objects"><span class="toc-number">1.2.1.</span> <span class="toc-text">Multiple Objects</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-step-object-detection-framwork"><span class="toc-number">1.2.2.</span> <span class="toc-text">4-step object-detection framwork</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Region-Proposal-indentify-regions-of-interest-RoI-for-potential-locations-of-objects"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">1. Region Proposal: indentify regions of interest (RoI) for potential locations of objects</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Selective-Search"><span class="toc-number">1.2.2.1.1.</span> <span class="toc-text">Selective Search</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Feature-Extraction-extract-visial-features-within-each-RoI-for-classification"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2. Feature Extraction: extract visial features within each RoI for classification</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Non-maximum-Suppression-NMS-avoid-repeated-detections"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">3. Non-maximum Suppression (NMS): avoid repeated detections</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Evaluateion-metrics-evaluate-performance-of-model"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">4. Evaluateion metrics: evaluate performance of model</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#State-of-the-Art-Object-Detection-CNNS"><span class="toc-number">1.2.3.</span> <span class="toc-text">State of the Art Object Detection CNNS</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#R-CNNs-Region-based-CNNs"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">R-CNNs: Region-based CNNs</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Applications of CNNs in Computer Vision
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Gaoxiang Luo</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-01-10T04:02:42.000Z" itemprop="datePublished">2021-01-09</time>
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <blockquote>
<p>Acknowledgement: This course (CSCI 8980) is being offered by <a target="_blank" rel="noopener" href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course. The content of this blog is from one of the grad students in the class, Andrea Walker, who were giving a presentation.</p>
</blockquote>
<h1>Object Detection</h1>
<h2 id="What-is-object-detection">What is object detection?</h2>
<p>There are 2 main tasks:</p>
<ul>
<li>Localizing one or more objects in the image</li>
<li>Classifying each object in the image<br>
<img src="figure1.png" alt="figure1"><br>
Credit: The image above is from <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1809.06849">Islam el al., 2019</a>.</li>
</ul>
<h2 id="Object-Detection-Network">Object Detection Network</h2>
<p><img src="figure2.png" alt="figure2"><br>
The image above is from <a target="_blank" rel="noopener" href="http://vision.stanford.edu/teaching/cs231n/slides/2020/lecture_12.pdf">Stanford CS231N</a>. The inputs here are a image and a bounding box which contains the object, and the outputs here are a classification score of multiclass and a bounding box of the classified object. Since after the CNN conponent, there are two fully connected layers to output two different outcomes respectively. Here the obejctive loss we use is simply add the loss of both tasks together. I believe you’re familair with the softmax loss as it’s used in handwritten digit recognition in MNIST, and notably the localization here can be treated as a regression problem so that we can use the L2 loss.</p>
<h3 id="Multiple-Objects">Multiple Objects</h3>
<p>In the example above, we only have one object (a cat) in the image. What if we have multiple objects in the image? If we have one more object in the images, in the input we will have one more class label with four values to indicate another bounding box, here we see that the program starts to scale once we have multiple obejcts in a image.</p>
<p>A simple solution to multiple obejcts could be a slicing window over the entire image, which means we apply a CNN to many different crops of the image and then CNN classifies each crop as object or background. However, this is very computationally expensive! Most of the object detection application require this to be happened in the real time. So, what can be a good solution to multiple obejcts?</p>
<h3 id="4-step-object-detection-framwork">4-step object-detection framwork</h3>
<h4 id="1-Region-Proposal-indentify-regions-of-interest-RoI-for-potential-locations-of-objects">1. Region Proposal: indentify regions of interest (RoI) for potential locations of objects</h4>
<ul>
<li>General procesures for region proposal:
<ul>
<li>Generate thousands of bouding boxes</li>
<li>Classify them as forground or background based on ‘objectness score’</li>
<li>Pass only foreground through rest of the network<br>
People commonly use <strong>selective search</strong>, which is a fast algorithm, ~200 region proposals in a few seconds on CPU<br>
<img src="figure3.png" alt="figure3"><br>
The images under this entire section are from <a target="_blank" rel="noopener" href="https://www.manning.com/books/deep-learning-for-vision-systems">Elendy, 2020</a>.</li>
</ul>
</li>
</ul>
<h5 id="Selective-Search">Selective Search</h5>
<p>Selective search is a greedy search algorithm. The following are the steps of selective search.</p>
<ol>
<li>Segmentation. It basically defines the ‘blobs’ within the image in the segmentations step that can potentially be objects.<br>
<img src="figure4.png" alt="figure4"></li>
<li>Take these proposed regions that may contain objects as input, and the output will be as the image shown below. Those blue boxes are the regions that may contain a object, and the algorithm combines the two similiar regions into one region. So, after many iteration we’ll find we have less blue boxes now. This step will continue until the entire object is in a bounding box.<br>
<img src="figure5.png" alt="figure5"></li>
</ol>
<h4 id="2-Feature-Extraction-extract-visial-features-within-each-RoI-for-classification">2. Feature Extraction: extract visial features within each RoI for classification</h4>
<ul>
<li>Use a pretrained CNN network, and extract features</li>
<li>Make 2 predictions using additional layers:
<ul>
<li>Bounding box prediction (x, y, width, height) <em>You may be curious why we have to make a prediction of bounding boxes here, since we’ve already identify a region of interest in the previous step. It’s important for the network to predict a bounding box, because we’re interested in having a bounding box that predicts the optimal bounding box for the obejct that we’re detecting. The region of interest may not include the entire obejct, so we don’t want to be limited by that.</em></li>
<li>Class prediction (softmax function predicting the class probability for each object)</li>
</ul>
</li>
</ul>
<h4 id="3-Non-maximum-Suppression-NMS-avoid-repeated-detections">3. Non-maximum Suppression (NMS): avoid repeated detections</h4>
<p>There is a 4-step technique for eliminating duplicate detections of objects.</p>
<ol>
<li>Discard bounding boxes with prediction below a <strong>confident threshold</strong>.</li>
<li>Select the bounding boxes with the highest probability</li>
<li>Calculate the overlap of all remaining boxes with the same class prediction</li>
<li>Supress any box with an IoU smaller than a threshold (NMS threshold, usually 0.5).<br>
<img src="figure6.png" alt="figure6"></li>
</ol>
<h4 id="4-Evaluateion-metrics-evaluate-performance-of-model">4. Evaluateion metrics: evaluate performance of model</h4>
<p>Once an object detector has been developed, it’s typically evaluated using two main metrics:</p>
<ul>
<li>Frames per second (FPS) - detection speed</li>
<li>Mean Average Precision (mAP) - network precision
<ul>
<li>mAP calculated from a bounding box’s object score and the precision-recall curve</li>
</ul>
</li>
</ul>
<h3 id="State-of-the-Art-Object-Detection-CNNS">State of the Art Object Detection CNNS</h3>
<h4 id="R-CNNs-Region-based-CNNs">R-CNNs: Region-based CNNs</h4>
<p>R-CNN family networks:</p>
<ul>
<li>R-CNN</li>
<li>Fast-RCNN</li>
<li>Faster-RCNN (SOTA)<br>
<img src="figure7.png" alt="figure7"><br>
R-CNN starts with a selective search to extract regions of interest (RoI) and wrapped them, then pass through a pretrain CNN to extract featrues. Once the feature extraction has been completed, classification and regression are performed to identify the class within each RoI as well as the bounding box. In order to understand this pipeline better, let’s look at R-CNN in a different angle.<br>
<img src="figure8.png" alt="figure8"><br>
Each region that pass through selective search will be sent to CNN to extract the featuers, and then the features will be passed to two modules – classification module, which is a support vector machine (SVM) and a regression module, which is a regerssor that estimate the bounding box. This is the base level of the family of R-CNNs.</li>
</ul>
<p><img src="figure9.png" alt="figure9"><br>
The image above is Fast-RCNN. The major change is where the CNN appears in the architecture. This time the input image will be directly sent into the CNN, and the region extractor happens after the CNN. This is important, because it speed up the network by only running one CNN instead of runnign ~2000 CNNs on each RoI.</p>
<p>CNN here performs both classification and feature extraction, and the SVM classification module is replaced with a softmax layer.</p>
<p><img src="figure10.png" alt="figure10"><br>
The image above is Faster-RCNN, and it reaches the SOTA performance. Its overal architectural design is similiar with Fast-RCNN, with the exceptionthat a different algorithm is used for region proposal. I used the same base CNN to do the feature extraction, the main change is that they created a region proposal network (PRN), this plays the role of the selective search algorithm. So, it’s really taking out the selective search algorithm from Fast-RCNN and replace it with PRN.</p>
<hr>
<div style="text-align: right"> To be continued... </div>
  </div>
</article>


  <!-- Gitalk start  -->

  <!-- Link Gitalk files  -->
  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"/></script> 
  <div id="gitalk-container"></div>     
  <script type="text/javascript">
      var gitalk = new Gitalk({

        // gitalk's main params
        clientID: `3ce407f9c6ed6aaffdf8`,
        clientSecret: `2c6bc0465d806a6dc4ee20c9b1a0043d7a6101fe`,
        repo: `gaoxiangluo.github.io`,
        owner: 'GaoxiangLuo',
        admin: ['GaoxiangLuo'],
        id: location.pathname.slice(0, 50),
        distractionFreeMode: true,
        enableHotKey: true,
        language: `en`
      });
      gitalk.render('gitalk-container');
  </script> 
  <!-- Gitalk end -->




        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Object Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#What-is-object-detection"><span class="toc-number">1.1.</span> <span class="toc-text">What is object detection?</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Object-Detection-Network"><span class="toc-number">1.2.</span> <span class="toc-text">Object Detection Network</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Multiple-Objects"><span class="toc-number">1.2.1.</span> <span class="toc-text">Multiple Objects</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-step-object-detection-framwork"><span class="toc-number">1.2.2.</span> <span class="toc-text">4-step object-detection framwork</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Region-Proposal-indentify-regions-of-interest-RoI-for-potential-locations-of-objects"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">1. Region Proposal: indentify regions of interest (RoI) for potential locations of objects</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Selective-Search"><span class="toc-number">1.2.2.1.1.</span> <span class="toc-text">Selective Search</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-Feature-Extraction-extract-visial-features-within-each-RoI-for-classification"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2. Feature Extraction: extract visial features within each RoI for classification</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-Non-maximum-Suppression-NMS-avoid-repeated-detections"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">3. Non-maximum Suppression (NMS): avoid repeated detections</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-Evaluateion-metrics-evaluate-performance-of-model"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">4. Evaluateion metrics: evaluate performance of model</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#State-of-the-Art-Object-Detection-CNNS"><span class="toc-number">1.2.3.</span> <span class="toc-text">State of the Art Object Detection CNNS</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#R-CNNs-Region-based-CNNs"><span class="toc-number">1.2.3.1.</span> <span class="toc-text">R-CNNs: Region-based CNNs</span></a></li></ol></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&text=Applications of CNNs in Computer Vision"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&is_video=false&description=Applications of CNNs in Computer Vision"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Applications of CNNs in Computer Vision&body=Check out this article: https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&title=Applications of CNNs in Computer Vision"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&name=Applications of CNNs in Computer Vision&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://gaoxiangluo.github.io/2021/01/09/Applications-of-CNNs-in-Computer-Vision/&t=Applications of CNNs in Computer Vision"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2021
    Gaoxiang Luo
  </div>
  <!-- <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div> -->
  <div class="busuanzi-count">
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span class="site-pv">
      Page View <i class="fa fa-users"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
    <!-- <span class="site-uv">
      Number of Visitors <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuansi_value_site_uv"></span>
    </span> -->
  </div>
  <div class="Word-count">
    <i class="fas fa-chart-area"></i> Total count: </i><span class="post-count">27.8k</span>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-176745887-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400,"hOffset":5,"vOffset":-38},"mobile":{"show":false,"scale":0.2},"react":{"opacityDefault":0.8,"opacityOnHover":0.2},"log":false});</script></body>
</html>
