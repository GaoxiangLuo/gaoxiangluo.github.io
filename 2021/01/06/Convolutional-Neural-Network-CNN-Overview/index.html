<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
    <meta name="description" content="Acknowledgement: This course (CSCI 8980) is being offered by Prof. Ju Sun at the University of Minnesota in Fall 2020. Pictures of slides are from the course.  From Fully Connected to Convolutional N">
<meta property="og:type" content="article">
<meta property="og:title" content="Convolutional Neural Network (CNN): Overview">
<meta property="og:url" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/index.html">
<meta property="og:site_name" content="Leon">
<meta property="og:description" content="Acknowledgement: This course (CSCI 8980) is being offered by Prof. Ju Sun at the University of Minnesota in Fall 2020. Pictures of slides are from the course.  From Fully Connected to Convolutional N">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure1.png">
<meta property="og:image" content="https://math.now.sh?inline=%28%5Cfrac%7Bimage%7D%7B2%5En-1%7D%29">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure2.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure3.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure4.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure5.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure6.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure7.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure8.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure9.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure10.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cast">
<meta property="og:image" content="https://math.now.sh?inline=%5Cstar">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure11.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure12.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure13.png">
<meta property="og:image" content="https://math.now.sh?inline=C_1">
<meta property="og:image" content="https://math.now.sh?inline=C_2">
<meta property="og:image" content="https://math.now.sh?inline=H%20%5Ctimes%20W">
<meta property="og:image" content="https://math.now.sh?inline=0%28C_1C_2H%5E2W%5E2%29">
<meta property="og:image" content="https://math.now.sh?inline=h%20%5Ctimes%20w">
<meta property="og:image" content="https://math.now.sh?inline=O%28C_1C_2hw%29">
<meta property="og:image" content="https://math.now.sh?inline=h%2Cw">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure14.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure15.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure16.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure17.png">
<meta property="og:image" content="https://math.now.sh?inline=%5Cgeq">
<meta property="og:image" content="https://math.now.sh?inline=%5Capprox">
<meta property="og:image" content="https://math.now.sh?inline=%5Cimplies">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure18.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure19.png">
<meta property="og:image" content="https://math.now.sh?from=%5Cmathcal%20F%20%28w%20%5Cast%20x%29%3D%5Cmathcal%20F(w)%20%5Codot%20%5Cmathcal%20%20F(x)%0A">
<meta property="og:image" content="https://math.now.sh?inline=%5Cnabla_x%20max%28x_1%2C%5Cdots%2Cx_n%29">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure20.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure21.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure22.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure23.png">
<meta property="og:image" content="https://math.now.sh?from=a%20%5Cast%20%28b%20%5Cast%20c%29%20%3D%20(a%20%5Cast%20b)%20%5Cast%20c%0A">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure24.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure25.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure26.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure27.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure28.png">
<meta property="og:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure29.png">
<meta property="article:published_time" content="2021-01-07T05:09:17.000Z">
<meta property="article:modified_time" content="2021-01-07T05:12:31.222Z">
<meta property="article:author" content="Gaoxiang Luo">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/figure1.png">
    
    
        
          
              <link rel="shortcut icon" href="/images/favicon.ico">
          
        
        
          
            <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
          
        
        
          
            <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
          
        
    
    <!-- title -->
    <title>Convolutional Neural Network (CNN): Overview</title>
    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
      
<link rel="stylesheet" href="/css/rtl.css">

    
    <!-- rss -->
    
    
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Leon" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#"><i class="fas fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fas fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" href="/2021/01/07/A-Survey-of-Deep-Semantic-Segmentation-on-Computed-Tomography/"><i class="fas fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" href="/2020/11/08/Basic-Clusters-Analysis/"><i class="fas fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" href="#"><i class="fas fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&text=Convolutional Neural Network (CNN): Overview"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&is_video=false&description=Convolutional Neural Network (CNN): Overview"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Convolutional Neural Network (CNN): Overview&body=Check out this article: https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/"><i class="fas fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&name=Convolutional Neural Network (CNN): Overview&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&t=Convolutional Neural Network (CNN): Overview"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    <div id="toc">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">From Fully Connected to Convolutional Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Find-patterns-in-an-image"><span class="toc-number">1.1.</span> <span class="toc-text">Find patterns in an image</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Digital-Images"><span class="toc-number">1.1.1.</span> <span class="toc-text">Digital Images</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#How-to-find-a-pattern-in-images"><span class="toc-number">1.1.2.</span> <span class="toc-text">How to find a pattern in images?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Template-matching-previals-in-classic-image-processing"><span class="toc-number">1.1.3.</span> <span class="toc-text">Template matching previals in classic image processing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-with-template-matching"><span class="toc-number">1.1.4.</span> <span class="toc-text">Problem with template matching</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-based-approach"><span class="toc-number">1.1.5.</span> <span class="toc-text">Feature-based approach</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Problems-with-fully-connected-networks"><span class="toc-number">1.2.</span> <span class="toc-text">Problems with fully connected networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Complexity"><span class="toc-number">1.2.1.</span> <span class="toc-text">Complexity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Locality-and-ordering"><span class="toc-number">1.2.2.</span> <span class="toc-text">Locality and ordering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Invariance"><span class="toc-number">1.2.3.</span> <span class="toc-text">Invariance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ideal-neural-networks-for-spatial-data"><span class="toc-number">1.2.4.</span> <span class="toc-text">Ideal neural networks for spatial data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#A-quick-preview-of-convolutional-neural-network-CNN"><span class="toc-number">1.2.5.</span> <span class="toc-text">A quick preview of convolutional neural network (CNN)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Components-of-CNNs"><span class="toc-number">1.3.</span> <span class="toc-text">Components of CNNs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Convolution-Layer"><span class="toc-number">1.3.1.</span> <span class="toc-text">Convolution Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Convolution-is-misnomer"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">Convolution is misnomer!</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#More-on-conlution-correlation"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">More on conlution&#x2F;correlation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Connection-to-fully-connected-neural-network"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">Connection to fully-connected neural network</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multiple-filters-each-layer"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">Multiple filters each layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Do-we-reduce-the-complexity"><span class="toc-number">1.3.1.5.</span> <span class="toc-text">Do we reduce the complexity?</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pooling-Layer"><span class="toc-number">1.3.2.</span> <span class="toc-text">Pooling Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Why-pooling"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">Why pooling?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Combine-covolution-and-pooling-%E2%80%93-convolution-with-strides"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">Combine covolution and pooling – convolution with strides</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Why-multilayers"><span class="toc-number">1.3.3.</span> <span class="toc-text">Why multilayers?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hierarchical-feature-learning"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">Hierarchical feature learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Computation"><span class="toc-number">1.3.4.</span> <span class="toc-text">Computation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#How-to-compute-convolution"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">How to compute convolution?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#More-on-computation"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">More on computation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Architectures-for-classification"><span class="toc-number">1.4.</span> <span class="toc-text">Architectures for classification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Typical-design-patterns"><span class="toc-number">1.4.1.</span> <span class="toc-text">Typical design patterns</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LeNet-5-1998"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">LeNet-5 (1998)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AlexNet-2012"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">AlexNet (2012)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VGG-Net-2014"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">VGG-Net (2014)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ResNet-2015"><span class="toc-number">1.4.1.4.</span> <span class="toc-text">ResNet (2015)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Dense-2016"><span class="toc-number">1.4.1.5.</span> <span class="toc-text">Dense (2016)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Other-models-to-look-at"><span class="toc-number">1.4.1.6.</span> <span class="toc-text">Other models to look at</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Practicle-tips"><span class="toc-number">1.5.</span> <span class="toc-text">Practicle tips</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transfer-Learning"><span class="toc-number">1.5.1.</span> <span class="toc-text">Transfer Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Are-CNNs-only-for-images"><span class="toc-number">1.5.2.</span> <span class="toc-text">Are CNNs only for images?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transposed-Convolution"><span class="toc-number">1.5.3.</span> <span class="toc-text">Transposed Convolution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normalization"><span class="toc-number">1.5.4.</span> <span class="toc-text">Normalization</span></a></li></ol></li></ol></li></ol>
    </div>
  </span>
</div>

    
    <div class="content index py4">
        
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle" itemprop="name headline">
        Convolutional Neural Network (CNN): Overview
    </h1>



    <div class="meta">
      <span class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span itemprop="name">Leon</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2021-01-07T05:09:17.000Z" itemprop="datePublished">2021-01-06</time>
        
        (Updated: <time datetime="2021-01-07T05:12:31.222Z" itemprop="dateModified">2021-01-06</time>)
        
      
    </div>


      

      

    </div>
  </header>
  

  <div class="content" itemprop="articleBody">
    <blockquote>
<p>Acknowledgement: This course (CSCI 8980) is being offered by <a target="_blank" rel="noopener" href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p>
</blockquote>
<h1>From Fully Connected to Convolutional Neural Networks</h1>
<h2 id="Find-patterns-in-an-image">Find patterns in an image</h2>
<h3 id="Digital-Images">Digital Images</h3>
<p><img src="figure1.png" alt="figure1"><br>
Digit images can be simply looked as matrices, and each entry of matrices (i.e., pixels) is an integer. We call the traditional MNIST images gray scale level images. Color images are 3-dimensional tensors. R,G,B are respectively treated as a gray scale image. We usually normalize the data to alleviate the effect of noise, by</p>
<ul>
<li>dividing the data by its “pixel-depth - 1” <img src="https://math.now.sh?inline=%28%5Cfrac%7Bimage%7D%7B2%5En-1%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li>
<li>zero-mean unit-variance</li>
<li>min-max.</li>
</ul>
<p>This little change can effect performance to an extent. JPEG by default usually throws some details out from the images. If you’re dealing with questions that every pixel is important, maybe you want to use PNG rather than JPEG since PNG is lossless.</p>
<h3 id="How-to-find-a-pattern-in-images">How to find a pattern in images?</h3>
<p><img src="figure2.png" alt="figure2"><br>
Let’s divide it by two questions. We firstly ask whether this object is in this image. Secondly we ask where is the object in the image if this object is in this image. Scan-window method is to take a sample and scan through the entire image to find similarity (distance). Inner product is a measure of similarity, and each time inner product of the original (red) and overlapped (green) patches are taken. If they’re similiar, then the inner product is larger. The output matrix is called the correlation. Now let’s look at the largest magnitude because that will be the canidate match of detection.<br>
Is correlation always reliable? No, a counterexample in this case is that the background is plain white.</p>
<h3 id="Template-matching-previals-in-classic-image-processing">Template matching previals in classic image processing</h3>
<p><img src="figure3.png" alt="figure3"><br>
How do you detect the edge? A typical edge looks like left(white) right(black) middle(gray) as the picture above.</p>
<h3 id="Problem-with-template-matching">Problem with template matching</h3>
<p><img src="figure4.png" alt="figure4"><br>
What are some potential problems? Would scan-window method work here? In practices, there are many variation. This object can be smaller, larger, scaling, rotation, deformation, etc.</p>
<h3 id="Feature-based-approach">Feature-based approach</h3>
<p><img src="figure5.png" alt="figure5"><br>
We may be convinced that the classic template matching slicing window scheme doesn’t work well if there are data augmentation (rotation, scaling, translation, etc). So, is it possible to extract the features first that are invariant to scaling, rotation, deformation? Yes! An era of feature-based methods has begun…</p>
<h2 id="Problems-with-fully-connected-networks">Problems with fully connected networks</h2>
<h3 id="Complexity">Complexity</h3>
<p><img src="figure6.png" alt="figure6"><br>
Fully connected networks are not feasible just looking at the dimension. Images with high-resolution have many pixels, which are the input of neural networks. It’s computational impossible. This is from the complexity and storage point of view.</p>
<h3 id="Locality-and-ordering">Locality and ordering</h3>
<p><img src="figure7.png" alt="figure7"><br>
No many people talk about this argument but it’s very important. An image tends to have some local structure, because adjacent pixels of natural images are highly correlated. Natual images are pixel-wise smooth. Fully connected neural networks (FCNNs) treats the input as vector, and it’s even insensitive to any universal permutation of the coordinates of all inputs.</p>
<h3 id="Invariance">Invariance</h3>
<p>It’s not sensitive to where the object is in the image. You always want to do certain levels of invariance in recognition. For intance, if I move the digit 8 around in the image, the neural network should be invariant to translation. Think about moving a digit from one place to another place in the image, in the image pixel matric what we see is some irregualr movements/changes. In short, fully connected network is not invariant to scaling, rotation, translation, etc.</p>
<h3 id="Ideal-neural-networks-for-spatial-data">Ideal neural networks for spatial data</h3>
<p><img src="figure8.png" alt="figure8"><br>
We hope to acheive learning features locally. For instance, learn the low-level features such as lines, edges, curves, etc, or a bit high-level featuers such as eyes, ears, etc, which are invariant to translation, rotation, local deformation, etc.</p>
<h3 id="A-quick-preview-of-convolutional-neural-network-CNN">A quick preview of convolutional neural network (CNN)</h3>
<p><img src="figure9.png" alt="figure9"><br>
Input -&gt; Convolution Layers (Feature Extraction) -&gt; Fully Connected Layers (Classification) -&gt; Output</p>
<h2 id="Components-of-CNNs">Components of CNNs</h2>
<h3 id="Convolution-Layer">Convolution Layer</h3>
<h4 id="Convolution-is-misnomer">Convolution is misnomer!</h4>
<p><img src="figure10.png" alt="figure10"><br>
Convolution is actually mathematically a wrong name. It’s pretty much correlation. The only difference here is if you flip or not as shown in the image above. People actually implement correlation and call it convolution… In math notation, <img src="https://math.now.sh?inline=%5Cast" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for convolution and <img src="https://math.now.sh?inline=%5Cstar" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for (cross)-correlation.</p>
<h4 id="More-on-conlution-correlation">More on conlution/correlation</h4>
<p><img src="figure11.png" alt="figure11"><br>
In image, people usually call the template in between as filter/kernel. Also, people call the area the filter cover each time in the image as receptive field. Further, people call the output from kernel as feature map.<br>
There are also two concepts, which are padding and stride. Padding is to put 0s outside of the image. People do this in order to catch edge information. Stride is basically meaning step size here. Sometimes if people want to skip one pixel, they will usually set the stride as 2. More information and GIF can be found <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic">here</a>. Typically, people only set stride to at most 2.</p>
<h4 id="Connection-to-fully-connected-neural-network">Connection to fully-connected neural network</h4>
<p><img src="figure12.png" alt="figure12"><br>
Abstractly, you can think of convolution imports local pattern. Think of it in the fully-connected neural network, then convolution makes each neuron connects only to its receptive field, and all neurons share the same weight pattern.<br>
Convolution enforeces local pattern, because each time I only look at local area. By weight sharing, we cut down the number of parameters that we need to learn.</p>
<h4 id="Multiple-filters-each-layer">Multiple filters each layer</h4>
<p><img src="figure13.png" alt="figure13"><br>
For one filter, as image above from input volomn to output volomn there is an important summation, which acts just like flatten the matrix. Btw, 2D covolution is moving in 2D. It’s not 3D convolution because it’s not moving in depth but moving 3D tensor in 2D.</p>
<h4 id="Do-we-reduce-the-complexity">Do we reduce the complexity?</h4>
<p>Suppose <img src="https://math.now.sh?inline=C_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> input channels and <img src="https://math.now.sh?inline=C_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> output channels of size <img src="https://math.now.sh?inline=H%20%5Ctimes%20W" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p>
<ul>
<li>number of parameters if implementing fully connected layer: <img src="https://math.now.sh?inline=0%28C_1C_2H%5E2W%5E2%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li>
<li>number of parameters if implementing convolution of <img src="https://math.now.sh?inline=h%20%5Ctimes%20w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? <img src="https://math.now.sh?inline=O%28C_1C_2hw%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> where <img src="https://math.now.sh?inline=h%2Cw" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> are usually small constants, e.g., 3 in practice</li>
</ul>
<h3 id="Pooling-Layer">Pooling Layer</h3>
<p>Convolution helps to achieve locality, and reduced complexity, what about invariance?<br>
<img src="figure14.png" alt="figure14"><br>
Pooling is not a difficult operation to understand. In the image above, there is a 4x4 image. If the size of pooling receptive field size is 2x2 with a stride of 2. Then I just slide the pooling receptive field over the original image. For max pooling, I select the maximum pixel value of within my pooling receptive field. Other than max pooling, there are also average pooling, i.e., weighed average within the receptive field.</p>
<h4 id="Why-pooling">Why pooling?</h4>
<p><img src="figure15.png" alt="figure15"></p>
<ul>
<li>deep layer: more filters, which makes us end up with many channels (thicker), so we have to subsample to avoid explosion in computation</li>
<li>subsampling keep important features; for imaging processing, most of the time people are doing recognition, so what matters is the general shape but not low-level details. So, subsampling is ok.<br>
<img src="figure16.png" alt="figure16"><br>
Do we really achieve invariance?<br>
<img src="figure17.png" alt="figure17"><br>
Let’s look at the image above as top view and bottom view, where the bottem view can be think of the top view’s detector stage move to the left by 1. What we observe is that even though there are movement in detector stage, but the pooling stage is roughly the same, and that’s roughly what we mean by saying pooling can achieve a certain degree of invariance.</li>
</ul>
<h4 id="Combine-covolution-and-pooling-–-convolution-with-strides">Combine covolution and pooling – convolution with strides</h4>
<p>idea: convolution with stride <img src="https://math.now.sh?inline=%5Cgeq" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> 2 <img src="https://math.now.sh?inline=%5Capprox" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> convolution + subsampling</p>
<p>One can either do a stride 2 pooling after convolution, or simply a convolution with stride 2. The idea of getting rid of pooling layers is more and more popular within Generative Adversial Networks (GANs).</p>
<h3 id="Why-multilayers">Why multilayers?</h3>
<ul>
<li>For efficiency: each object can have different variations, simply using one kernel for each variation of the object is impossible.</li>
<li>For goodness: Kernels can be shared across digits or all object catogories; low-level features likely sharable <img src="https://math.now.sh?inline=%5Cimplies" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> form hierarchy</li>
</ul>
<h4 id="Hierarchical-feature-learning">Hierarchical feature learning</h4>
<p><img src="figure18.png" alt="figure18"><br>
The above are the real output of certain layers of CNNs. Really we see that low-level feature is somewhat similiar.</p>
<h3 id="Computation">Computation</h3>
<h4 id="How-to-compute-convolution">How to compute convolution?</h4>
<p>Convolution layer is locally connected, weight-sharing fully connected layer. If we vetorize both input and output, the operation can be represented as a matrix multiplication.<br>
<img src="figure19.png" alt="figure19"></p>
<h4 id="More-on-computation">More on computation</h4>
<p>To compute the convolution</p>
<ul>
<li>use (sparse) matrix-vector multiplication (early version of cuDNN)</li>
<li>ise fast Fourier transform (introduced in later version of cuDNN)</li>
</ul>
<p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmathcal%20F%20%28w%20%5Cast%20x%29%3D%5Cmathcal%20F(w)%20%5Codot%20%5Cmathcal%20%20F(x)%0A" /></p><p>To compute the max-pooling</p>
<ul>
<li>forward: just try to pick up the maximum</li>
<li>backward? what’s <img src="https://math.now.sh?inline=%5Cnabla_x%20max%28x_1%2C%5Cdots%2Cx_n%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li>
</ul>
<h2 id="Architectures-for-classification">Architectures for classification</h2>
<h3 id="Typical-design-patterns">Typical design patterns</h3>
<p>Feature Extraction (Conv) + Classification (Fully connected)</p>
<ul>
<li>Conv: depth increases (more filters), dimension decreases (subsampling) when moving deeper<br>
<img src="figure20.png" alt="figure20"></li>
<li>one or two fully connected layers for classifaction</li>
</ul>
<h4 id="LeNet-5-1998">LeNet-5 (1998)</h4>
<p><img src="figure21.png" alt="figure21"><br>
At that time, people were stilling using hypertangent, and 5x5 filter, which now has been replaced by ReLU and 3x3 filter.</p>
<h4 id="AlexNet-2012">AlexNet (2012)</h4>
<p><img src="figure22.png" alt="figure22"><br>
Naivly, this can be thought of as a deeper version of LeNet with more convolutional layers and more fully connected layers. This brings a breakthrough on ImageNet competition in 2012, and impressed the computer vision community.</p>
<ul>
<li>ReLU as activation</li>
<li>larger filters: 11x11, 5x5, 3x3</li>
<li>dropout used for regularization (dropout wasn’t proposed by this paper but made popular by this paper)</li>
<li>weight decay/regularization</li>
</ul>
<h4 id="VGG-Net-2014">VGG-Net (2014)</h4>
<p><img src="figure23.png" alt="figure23"><br>
This is a further deeper version of AlexNet. (At that time, people really was trying to go deeper after they see the befinit of more layers.) They have some novel modification, which they perform several convolution in a row and followed by a pooling layer. The intuition comes from the associative law of convolution, which is</p>
<p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=a%20%5Cast%20%28b%20%5Cast%20c%29%20%3D%20(a%20%5Cast%20b)%20%5Cast%20c%0A" /></p><p>This is to say that I can have serveral smaller filter (several convolution layers) and gain a roughly (<strong>not exactly</strong>) the same effect of a single large filter. And you will found the number of parameters reduce significantly.</p>
<h4 id="ResNet-2015">ResNet (2015)</h4>
<p>Sometimes performance get worse when the network is really deep. What’s going wrong? The performance somewhat get degragated during going deeper.<br>
<img src="figure24.png" alt="figure24"></p>
<ul>
<li>skip connection</li>
<li>batch normalization<br>
Intuition for skip connection: If I have a task which has 50 layers to attain optimal performance already, what if I add up to 100 layers? That will bring performance degragation, but if I have skip connection after the 50th layer because I know it doesn’t need 100 layers. If I training algorithm is smart enough, it will make the weights of all the layers after 50th layer to be zeros. Then, without lossing the previous information from eailier layers, even though the latter layers’s weight are zeros, but I can still reach to output layer with skip connection. In addition, skip connection in auto differention package also acts like a skip conenction. Moreoever, skip connection also alleviates vanishing-gradient problem to some extents.</li>
</ul>
<h4 id="Dense-2016">Dense (2016)</h4>
<p>No soon after ResNet, Dense Net was proposed to take full adventage of skip connections.<br>
<img src="figure25.png" alt="figure25"></p>
<h4 id="Other-models-to-look-at">Other models to look at</h4>
<p>on accuracy:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1905.11946">EfficientNet</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1611.05431">ResNeXt</a></li>
</ul>
<p>on compact model:</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1602.07360">SqueezeNet</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1807.11164">ShuffleNet</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1801.04381">MobileNet</a></li>
</ul>
<h2 id="Practicle-tips">Practicle tips</h2>
<h3 id="Transfer-Learning">Transfer Learning</h3>
<p>We recall that CNNS learn increasingly complex and sementically meaningful features, while they have similiar low-level features. So, lower-level tend to learn features that are generic.<br>
<img src="figure26.png" alt="figure26"><br>
The image above you can see that different objects can share similiar low-level features. So, people can take a pretrain model (take both network architecture and <strong>weights</strong>) which has been trained on a very large and diverse dataset, as a starting point. And based on the size of dataset of you task, to select a scheme to perform fine tuning as the image below.<br>
<img src="figure27.png" alt="figure27"></p>
<h3 id="Are-CNNs-only-for-images">Are CNNs only for images?</h3>
<p>No, it’s popular in imaging, but also can be used in speed recognition, text classification, video analysis, and time series analysis.</p>
<h3 id="Transposed-Convolution">Transposed Convolution</h3>
<p>convolution with strides: downsampling<br>
transposed convolution: unsampling<br>
Transposed convolution is often used for segmentation (U-Net), generation, or other regression. The ouputs are structured object such as images, videos, time series, speech, etc.<br>
For unsampling, there are definitely classical way to perform it, which is nearest neighbor/bilinear/bicubic intepolation. In deep learning, people want to learn interpolation with learnable filter, that’s why the transposed convolution come into play. Actually, transposed convolution is also called <strong>fractionally strided convolutions</strong> or deconvolution.<br>
<img src="figure28.png" alt="figure28"><br>
The graph and more details are <a target="_blank" rel="noopener" href="https://github.com/vdumoulin/conv_arithmetic">here</a>.</p>
<h3 id="Normalization">Normalization</h3>
<p><img src="figure29.png" alt="figure29"><br>
normalization in different directions/groups of the data tensors</p>
<ul>
<li>N is the batch size</li>
<li>C is the channel size</li>
<li>WH is the per output dimension (1D for fully connected, but 2D for CNNs)</li>
</ul>
<p>batch normalization is popular, but with layer/group normalization you can have small N (batch size), reach simplicity (training/test normalizations are consistent).</p>
<hr>
<div style="text-align: right"> To be continued... </div>
  </div>
</article>


  <!-- Gitalk start  -->

  <!-- Link Gitalk files  -->
  <link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
  <script src="https://unpkg.com/gitalk@latest/dist/gitalk.min.js"/></script> 
  <div id="gitalk-container"></div>     
  <script type="text/javascript">
      var gitalk = new Gitalk({

        // gitalk's main params
        clientID: `3ce407f9c6ed6aaffdf8`,
        clientSecret: `2c6bc0465d806a6dc4ee20c9b1a0043d7a6101fe`,
        repo: `gaoxiangluo.github.io`,
        owner: 'GaoxiangLuo',
        admin: ['GaoxiangLuo'],
        id: location.pathname.slice(0, 50),
        distractionFreeMode: true,
        enableHotKey: true,
        language: `en`
      });
      gitalk.render('gitalk-container');
  </script> 
  <!-- Gitalk end -->




        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    <div id="toc-footer" style="display: none">
      <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">From Fully Connected to Convolutional Neural Networks</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Find-patterns-in-an-image"><span class="toc-number">1.1.</span> <span class="toc-text">Find patterns in an image</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Digital-Images"><span class="toc-number">1.1.1.</span> <span class="toc-text">Digital Images</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#How-to-find-a-pattern-in-images"><span class="toc-number">1.1.2.</span> <span class="toc-text">How to find a pattern in images?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Template-matching-previals-in-classic-image-processing"><span class="toc-number">1.1.3.</span> <span class="toc-text">Template matching previals in classic image processing</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Problem-with-template-matching"><span class="toc-number">1.1.4.</span> <span class="toc-text">Problem with template matching</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Feature-based-approach"><span class="toc-number">1.1.5.</span> <span class="toc-text">Feature-based approach</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Problems-with-fully-connected-networks"><span class="toc-number">1.2.</span> <span class="toc-text">Problems with fully connected networks</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Complexity"><span class="toc-number">1.2.1.</span> <span class="toc-text">Complexity</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Locality-and-ordering"><span class="toc-number">1.2.2.</span> <span class="toc-text">Locality and ordering</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Invariance"><span class="toc-number">1.2.3.</span> <span class="toc-text">Invariance</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Ideal-neural-networks-for-spatial-data"><span class="toc-number">1.2.4.</span> <span class="toc-text">Ideal neural networks for spatial data</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#A-quick-preview-of-convolutional-neural-network-CNN"><span class="toc-number">1.2.5.</span> <span class="toc-text">A quick preview of convolutional neural network (CNN)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Components-of-CNNs"><span class="toc-number">1.3.</span> <span class="toc-text">Components of CNNs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Convolution-Layer"><span class="toc-number">1.3.1.</span> <span class="toc-text">Convolution Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Convolution-is-misnomer"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">Convolution is misnomer!</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#More-on-conlution-correlation"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">More on conlution&#x2F;correlation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Connection-to-fully-connected-neural-network"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">Connection to fully-connected neural network</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multiple-filters-each-layer"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">Multiple filters each layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Do-we-reduce-the-complexity"><span class="toc-number">1.3.1.5.</span> <span class="toc-text">Do we reduce the complexity?</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pooling-Layer"><span class="toc-number">1.3.2.</span> <span class="toc-text">Pooling Layer</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Why-pooling"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">Why pooling?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Combine-covolution-and-pooling-%E2%80%93-convolution-with-strides"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">Combine covolution and pooling – convolution with strides</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Why-multilayers"><span class="toc-number">1.3.3.</span> <span class="toc-text">Why multilayers?</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Hierarchical-feature-learning"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">Hierarchical feature learning</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Computation"><span class="toc-number">1.3.4.</span> <span class="toc-text">Computation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#How-to-compute-convolution"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">How to compute convolution?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#More-on-computation"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">More on computation</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Architectures-for-classification"><span class="toc-number">1.4.</span> <span class="toc-text">Architectures for classification</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Typical-design-patterns"><span class="toc-number">1.4.1.</span> <span class="toc-text">Typical design patterns</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#LeNet-5-1998"><span class="toc-number">1.4.1.1.</span> <span class="toc-text">LeNet-5 (1998)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#AlexNet-2012"><span class="toc-number">1.4.1.2.</span> <span class="toc-text">AlexNet (2012)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#VGG-Net-2014"><span class="toc-number">1.4.1.3.</span> <span class="toc-text">VGG-Net (2014)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ResNet-2015"><span class="toc-number">1.4.1.4.</span> <span class="toc-text">ResNet (2015)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Dense-2016"><span class="toc-number">1.4.1.5.</span> <span class="toc-text">Dense (2016)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Other-models-to-look-at"><span class="toc-number">1.4.1.6.</span> <span class="toc-text">Other models to look at</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Practicle-tips"><span class="toc-number">1.5.</span> <span class="toc-text">Practicle tips</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Transfer-Learning"><span class="toc-number">1.5.1.</span> <span class="toc-text">Transfer Learning</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Are-CNNs-only-for-images"><span class="toc-number">1.5.2.</span> <span class="toc-text">Are CNNs only for images?</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Transposed-Convolution"><span class="toc-number">1.5.3.</span> <span class="toc-text">Transposed Convolution</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Normalization"><span class="toc-number">1.5.4.</span> <span class="toc-text">Normalization</span></a></li></ol></li></ol></li></ol>
    </div>

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&text=Convolutional Neural Network (CNN): Overview"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&is_video=false&description=Convolutional Neural Network (CNN): Overview"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=Convolutional Neural Network (CNN): Overview&body=Check out this article: https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/"><i class="fas fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&title=Convolutional Neural Network (CNN): Overview"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&name=Convolutional Neural Network (CNN): Overview&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://gaoxiangluo.github.io/2021/01/06/Convolutional-Neural-Network-CNN-Overview/&t=Convolutional Neural Network (CNN): Overview"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fas fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fas fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fas fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fas fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2020-2021
    Gaoxiang Luo
  </div>
  <!-- <div class="footer-right">
    <nav>
      <ul>
         
          <li><a href="/">Home</a></li>
         
          <li><a href="/about/">About</a></li>
         
          <li><a href="/archives/">Writing</a></li>
         
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </nav>
  </div> -->
  <div class="busuanzi-count">
    <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span class="site-pv">
      Page View <i class="fa fa-users"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
    <!-- <span class="site-uv">
      Number of Visitors <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuansi_value_site_uv"></span>
    </span> -->
  </div>
  <div class="Word-count">
    <i class="fas fa-chart-area"></i> Total count: </i><span class="post-count">23k</span>
  </div>
</footer>

    </div>
    <!-- styles -->

<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">


<link rel="stylesheet" href="/lib/justified-gallery/css/justifiedGallery.min.css">


    <!-- jquery -->

<script src="/lib/jquery/jquery.min.js"></script>


<script src="/lib/justified-gallery/js/jquery.justifiedGallery.min.js"></script>

<!-- clipboard -->

  
<script src="/lib/clipboard/clipboard.min.js"></script>

  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="far fa-clone"></i>';
    btn += '</span>'; 
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Google Analytics -->

    <script type="text/javascript">
        (function(i,s,o,g,r,a,m) {i['GoogleAnalyticsObject']=r;i[r]=i[r]||function() {
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-176745887-1', 'auto');
        ga('send', 'pageview');
    </script>

<!-- Baidu Analytics -->

<!-- Disqus Comments -->


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"debug":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":200,"height":400,"hOffset":5,"vOffset":-38},"mobile":{"show":false,"scale":0.2},"react":{"opacityDefault":0.8,"opacityOnHover":0.2},"log":false});</script></body>
</html>
