<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>I was featured on our CS&amp;E department website</title>
      <link href="/2021/05/15/I-was-featured-on-our-CS-E-department-website/"/>
      <url>/2021/05/15/I-was-featured-on-our-CS-E-department-website/</url>
      
        <content type="html"><![CDATA[<p>Recently, I was interviewed to share my experience as an undergrad researcher by our CS&amp;E department.<br>For more information: <a href="https://cse.umn.edu/cs/news/cspotlight-experiencing-research-undergrad">CSpotlight: Experiencing research as an undergrad</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>I have been selected to be a volunteer of ICLR 2021</title>
      <link href="/2021/04/18/I-have-been-selected-to-be-a-volunteer-of-ICLR-2021/"/>
      <url>/2021/04/18/I-have-been-selected-to-be-a-volunteer-of-ICLR-2021/</url>
      
        <content type="html"><![CDATA[<p>The first time I came across with Learning Presentation this phrase is from a paper that we were reviewing in the group, which talks about Causal Representation Learning <a href="https://arxiv.org/abs/2102.11107">arXiv</a>, and later I realized learning good representation is important to the success of machine learning algorithms including deep neural networks. It yields the possibility of solving the issue of out-of-distribution (OOD) data where i.i.d hypothesis doesn’t hold, as well as the interpretability of AI. It didn’t take me too long to find out there is a conference specifically set for Learning Representation, and I’m very happy that I could be part of the volunteer team in <a href="https://iclr.cc/Conferences/2021/Volunteers">ICLR 2021</a>.</p>]]></content>
      
      
      
        <tags>
            
            <tag> ICLR </tag>
            
            <tag> Conference </tag>
            
            <tag> Learning Representation </tag>
            
            <tag> Volunteer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>I had an oral presentation at UMN Undergrad Research Symposium</title>
      <link href="/2021/04/16/I-had-an-oral-presentation-at-UMN-Undergrad-Research-Symposium/"/>
      <url>/2021/04/16/I-had-an-oral-presentation-at-UMN-Undergrad-Research-Symposium/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Gaoxiang: This is my <a href="https://gaoxiangluo.github.io/2020/12/15/I-received-Undergraduate-Research-Scholarship/">UROP</a> project with <a href="https://www-users.cs.umn.edu/~gupta423/index.html">Jayant Gupta</a> and Professor <a href="https://www-users.cs.umn.edu/~shekhar/">Shashi Shekhar</a> in Spring 2021. I’m grad that I had a chance to present this work on <a href="https://ugresearch.umn.edu/symposium/presenters2021">2021 Virtual Undergraduate Research Symposium</a>. This video is recorded half-way through the semester, and we’re still working on improving the overall accuracies of this apporach.</p></blockquote><h1>Title: Wetland Mapping Using Spatial Variability Aware Neural Networks (SVANN)</h1><h2 id="Abstract">Abstract</h2><p>We perform the wetland mapping task using deep convolutional neural networks on high spatial resolution drone imagery in this work. As one of the largest ecosystems, wetlands have essential value to the earth’s environment and human society (e.g., flood reduction, water quality improvement, etc.). Thus, due to climate change and urbanization, there is a need to update wetland inventory frequently with accurate boundaries and improved delineation of smaller wetlands. However, wetland mapping is expensive, and the classification is affected by spatial heterogeneity in data. For example, last nationwide wetland mapping took 40 years and 300 million dollars to complete and required a separate rule-set for each wetland type. Hence, the procedure of wetland mapping has changed from costly manual photo interpretation to multi-fusion semi-automated approaches. Previous work is based on a random forest approach, which can effectively separate two distinct classes through stair-case boundaries in feature space. In contrast, our deep neural network approach can separate classes with limited distinction using complex non-linear boundaries. Our results show that the deep neural network outperforms the random forest based approach before applying any post-processing techniques. Additionally, we show that applying SVANN adjusts spatial heterogeneity and improves the overall accuracy of wetland mapping.</p><h2 id="Link-to-the-presentation-https-ugresearch-umn-edu-symposium-presenters2021-Gaoxiang-Luo">Link to the presentation: <a href="https://ugresearch.umn.edu/symposium/presenters2021/Gaoxiang-Luo">https://ugresearch.umn.edu/symposium/presenters2021/Gaoxiang-Luo</a></h2>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Presentation </tag>
            
            <tag> Symposium </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>I wrote an interview article for our undergraduate journal</title>
      <link href="/2021/03/25/I-wrote-an-interview-article-for-our-undergraduate-journal/"/>
      <url>/2021/03/25/I-wrote-an-interview-article-for-our-undergraduate-journal/</url>
      
        <content type="html"><![CDATA[<p><img src="figure1.png" alt="figure1"></p><p>The link to the publication (Vol. 4 No. 3 (2021)): <a href="https://pubs.lib.umn.edu/index.php/muraj/issue/view/231">https://pubs.lib.umn.edu/index.php/muraj/issue/view/231</a></p><h2 id="What-is-MURAJ">What is MURAJ</h2><p>The Minnesota Undergraduate Research &amp; Academic Journal (MURAJ) engages undergraduate students across the University of Minnesota - Twin Cities in the collaborative and educational process of assembling an academic journal that celebrates the breadth and depth of innovative thinking among undergraduate students.</p><h2 id="What-is-MURAJ-In-Focus">What is MURAJ: In Focus</h2><p>MURAJ: In Focus is a project that highlights the diversity of research at the University of Minnesota through a profile series that supplements our annual spring publication of student research. Our readers, like our authors, come from a wide array of backgrounds, and we believe that it is educational for students, faculty, and the University community to hear about the discoveries made and innovations happening on our campus.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Publication </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Applications of CNNs in Computer Vision</title>
      <link href="/2021/01/09/Applications-of-CNNs-in-Computer-Vision/"/>
      <url>/2021/01/09/Applications-of-CNNs-in-Computer-Vision/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course. The content of this blog is from one of the grad students in the class, Andrea Walker, who were giving a presentation.</p></blockquote><h1>Object Detection</h1><h2 id="What-is-object-detection">What is object detection?</h2><p>There are 2 main tasks:</p><ul><li>Localizing one or more objects in the image</li><li>Classifying each object in the image<br><img src="figure1.png" alt="figure1"><br>Credit: The image above is from <a href="https://arxiv.org/abs/1809.06849">Islam el al., 2019</a>.</li></ul><h2 id="Object-Detection-Network">Object Detection Network</h2><p><img src="figure2.png" alt="figure2"><br>The image above is from <a href="http://vision.stanford.edu/teaching/cs231n/slides/2020/lecture_12.pdf">Stanford CS231N</a>. The inputs here are a image and a bounding box which contains the object, and the outputs here are a classification score of multiclass and a bounding box of the classified object. Since after the CNN conponent, there are two fully connected layers to output two different outcomes respectively. Here the obejctive loss we use is simply add the loss of both tasks together. I believe you’re familair with the softmax loss as it’s used in handwritten digit recognition in MNIST, and notably the localization here can be treated as a regression problem so that we can use the L2 loss.</p><h3 id="Multiple-Objects">Multiple Objects</h3><p>In the example above, we only have one object (a cat) in the image. What if we have multiple objects in the image? If we have one more object in the images, in the input we will have one more class label with four values to indicate another bounding box, here we see that the program starts to scale once we have multiple obejcts in a image.</p><p>A simple solution to multiple obejcts could be a slicing window over the entire image, which means we apply a CNN to many different crops of the image and then CNN classifies each crop as object or background. However, this is very computationally expensive! Most of the object detection application require this to be happened in the real time. So, what can be a good solution to multiple obejcts?</p><h3 id="4-step-object-detection-framwork">4-step object-detection framwork</h3><h4 id="1-Region-Proposal-indentify-regions-of-interest-RoI-for-potential-locations-of-objects">1. Region Proposal: indentify regions of interest (RoI) for potential locations of objects</h4><ul><li>General procesures for region proposal:<ul><li>Generate thousands of bouding boxes</li><li>Classify them as forground or background based on ‘objectness score’</li><li>Pass only foreground through rest of the network<br>People commonly use <strong>selective search</strong>, which is a fast algorithm, ~200 region proposals in a few seconds on CPU<br><img src="figure3.png" alt="figure3"><br>The images under this entire section are from <a href="https://www.manning.com/books/deep-learning-for-vision-systems">Elendy, 2020</a>.</li></ul></li></ul><h5 id="Selective-Search">Selective Search</h5><p>Selective search is a greedy search algorithm. The following are the steps of selective search.</p><ol><li>Segmentation. It basically defines the ‘blobs’ within the image in the segmentations step that can potentially be objects.<br><img src="figure4.png" alt="figure4"></li><li>Take these proposed regions that may contain objects as input, and the output will be as the image shown below. Those blue boxes are the regions that may contain a object, and the algorithm combines the two similiar regions into one region. So, after many iteration we’ll find we have less blue boxes now. This step will continue until the entire object is in a bounding box.<br><img src="figure5.png" alt="figure5"></li></ol><h4 id="2-Feature-Extraction-extract-visial-features-within-each-RoI-for-classification">2. Feature Extraction: extract visial features within each RoI for classification</h4><ul><li>Use a pretrained CNN network, and extract features</li><li>Make 2 predictions using additional layers:<ul><li>Bounding box prediction (x, y, width, height) <em>You may be curious why we have to make a prediction of bounding boxes here, since we’ve already identify a region of interest in the previous step. It’s important for the network to predict a bounding box, because we’re interested in having a bounding box that predicts the optimal bounding box for the obejct that we’re detecting. The region of interest may not include the entire obejct, so we don’t want to be limited by that.</em></li><li>Class prediction (softmax function predicting the class probability for each object)</li></ul></li></ul><h4 id="3-Non-maximum-Suppression-NMS-avoid-repeated-detections">3. Non-maximum Suppression (NMS): avoid repeated detections</h4><p>There is a 4-step technique for eliminating duplicate detections of objects.</p><ol><li>Discard bounding boxes with prediction below a <strong>confident threshold</strong>.</li><li>Select the bounding boxes with the highest probability</li><li>Calculate the overlap of all remaining boxes with the same class prediction</li><li>Supress any box with an IoU smaller than a threshold (NMS threshold, usually 0.5).<br><img src="figure6.png" alt="figure6"></li></ol><h4 id="4-Evaluateion-metrics-evaluate-performance-of-model">4. Evaluateion metrics: evaluate performance of model</h4><p>Once an object detector has been developed, it’s typically evaluated using two main metrics:</p><ul><li>Frames per second (FPS) - detection speed</li><li>Mean Average Precision (mAP) - network precision<ul><li>mAP calculated from a bounding box’s object score and the precision-recall curve</li></ul></li></ul><h3 id="State-of-the-Art-Object-Detection-CNNS">State of the Art Object Detection CNNS</h3><h4 id="R-CNNs-Region-based-CNNs">R-CNNs: Region-based CNNs</h4><p>R-CNN family networks:</p><ul><li>R-CNN</li><li>Fast-RCNN</li><li>Faster-RCNN (SOTA)<br><img src="figure7.png" alt="figure7"><br>R-CNN starts with a selective search to extract regions of interest (RoI) and wrapped them, then pass through a pretrain CNN to extract featrues. Once the feature extraction has been completed, classification and regression are performed to identify the class within each RoI as well as the bounding box. In order to understand this pipeline better, let’s look at R-CNN in a different angle.<br><img src="figure8.png" alt="figure8"><br>Each region that pass through selective search will be sent to CNN to extract the featuers, and then the features will be passed to two modules – classification module, which is a support vector machine (SVM) and a regression module, which is a regerssor that estimate the bounding box. This is the base level of the family of R-CNNs.</li></ul><p><img src="figure9.png" alt="figure9"><br>The image above is Fast-RCNN. The major change is where the CNN appears in the architecture. This time the input image will be directly sent into the CNN, and the region extractor happens after the CNN. This is important, because it speed up the network by only running one CNN instead of runnign ~2000 CNNs on each RoI.</p><p>CNN here performs both classification and feature extraction, and the SVM classification module is replaced with a softmax layer.</p><p><img src="figure10.png" alt="figure10"><br>The image above is Faster-RCNN, and it reaches the SOTA performance. Its overal architectural design is similiar with Fast-RCNN, with the exceptionthat a different algorithm is used for region proposal. I used the same base CNN to do the feature extraction, the main change is that they created a region proposal network (PRN), this plays the role of the selective search algorithm. So, it’s really taking out the selective search algorithm from Fast-RCNN and replace it with PRN.</p><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Recurrent Neural Network (RNN): Overview</title>
      <link href="/2021/01/08/Recurrent-Neural-Network-RNN-Overview/"/>
      <url>/2021/01/08/Recurrent-Neural-Network-RNN-Overview/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) was offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><h1>Recap of CNN</h1><p>We didn’t talk about scattering transform conlutional network. It is also a deep neural network but it is not trainable; instead, it’s a deterministic deep learning neural network. The weights of the network are from a kind of mathematical transoform. While CNN is a blackbox, scattering transform is more rigorous and provable.</p><p>CNNs are not only for images. Ideally, it’s for tensors where <strong>axis directions</strong> do/should not matter. For instance, if I flip the image, it won’t influce my detection performance so its axis directions don’t matter, which implies that CNN will work. A counterexample is video. In video, timeflame is a meaningful direction. Playing forward and playing backward are different if my task is to analysis the moment of filling a swimming pool with water. Playing forward is the water level increasing but backward is another totally different event.</p><p>For applications that directions do matter, what really matters is usually the <strong>temporal sequences</strong>, such as disease prognosis (development from day 1 to day 500 for instance), video generation, speech to text, etc.<br><img src="figure7.png" alt="figure7"></p><p>Another sequence is <strong>lexical sequence</strong>, which includes today’s Natual Language Processing (NLP), such as machine translation (English and Chinese), typing prediction (Gmail smart compose), semantic classification, etc.</p><h1>Basic RNNs</h1><h2 id="Basic-setup">Basic setup</h2><p>A sequence: <img src="https://math.now.sh?inline=x_0%20%5Crightarrow%20x_1%20%5Crightarrow%20x_2%20%5Crightarrow%20%5Cdots%20%5Crightarrow%20x_%7Bn-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>A <strong>state-space</strong> model: <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> denotes the state, and state translation modeled by the <strong>recurrence</strong> formula</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=h_t%20%3D%20f_W%28h_%7Bt-1%7D%2Cx_t%29%20%5Cquad%20%5Ctext%7Bwhere%20we'll%20replace%20W%20with%20a%20neural%20network%7D%0A" /></p><p>with optional output</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=y_t%3Dg_V%28h_t%29%20%5Cquad%20%5Ctext%7Bwhere%20we'll%20replace%20V%20with%20a%20neural%20network%7D%0A" /></p><p><img src="figure1.png" alt="figure1"><br>The image above is from Stanford CS231N. Let’s look at an very simple example:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=h_t%20%3Dtanh%28W_hh_%7Bt-1%7D%2BW_xx_t%29%20%5C%5C%20y_t%3DV_yh_t%0A" /></p><p>where <img src="https://math.now.sh?inline=W_h%2CW_x%2CV_y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> are shared across the sequence, and <img src="https://math.now.sh?inline=h_%7Bt-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is my past state and <img src="https://math.now.sh?inline=x_t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is my current input.</p><h3 id="Example-a-statistical-language-modeling">Example: a statistical language modeling</h3><ul><li><strong>Language modeling</strong> is a task of predicting future words.</li><li>Statical formalism: given a sequence of words <img src="https://math.now.sh?inline=x%5E%7B%281%29%7D%2C%5Cdots%2Cx%5E%7B(t)%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, compute the next possible word after a sequence of words given</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmathbb%20P%20%5Clbrack%20x%5E%7B%28t%2B1%29%7D%20%7C%20x%5E%7B(t)%7D%2C%20%5Cdots%2C%20x%5E%7B(1)%7D%20%5Crbrack%0A" /></p><p>where <img src="https://math.now.sh?inline=x%5E%7Bt%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> can be any word from a vocabulary <img src="https://math.now.sh?inline=%5C%7Bw_1%2C%5Cdots%2C%20w_N%20%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, or sometimes given some text<img src="https://math.now.sh?inline=x%5E%7B%281%29%7D%2C%5Cdots%2Cx%5E%7B(T)%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>,</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmathbb%20P%20%5Clbrack%20x%5E%7B%281%29%7D%2C%20%5Cdots%2C%20x%5E%7B(T)%7D%20%5Crbrack%20%3D%20%5Cprod_%7Bt%3D1%7D%5ET%20%5Cmathbb%20P%20%5Clbrack%20x%5E%7B(t)%7D%7C%20x%5E%7B(t-1)%7D%2C%20%5Cdots%2C%20x%5E%7B(1)%7D%20%5Crbrack%20%0A" /></p><ul><li>Applications: Google smart search (fill out what you want to search for you, before you hit enter), and Gmail smart compose (where you can tab and have the computer finish your sentences).</li></ul><h3 id="Representing-words-word-embedding">Representing words: word embedding</h3><p>How to represent words?</p><ul><li>One hot encoding</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=I%20%5Crightarrow%20%5B1%2C0%2C0%2C0%2C...%5D%2C%20you%20%5Crightarrow%20%5B0%2C1%2C0%2C0%2C...%5D%2Cwe%20%5Crightarrow%20%5B0%2C0%2C1%2C0%2C...%5D%2C...%0A" /></p><p>This may work, but it’s really inefficient, because the dimension would be very high. Think about that, some words may be similiar meaning (distance), and some words may have meaning falling between two words. If you image a hyper-cube, one-hot encoding makes all words to be the corner of the hyper-cude, and it’s hard to represent a word that has a meaning falling between two words.</p><ul><li>word-to-vector embedding: map words into dense vectors centain arthmetic operations are consistent with semantics.<br><img src="figure8.png" alt="figure8"></li></ul><h3 id="A-simple-RNN-language-model">A simple RNN language model</h3><p><img src="figure3.png" alt="figure3"><br>In NLP, people usually use hypertangent function as the activation function. Our training data could be any trunk of text. It could be a paper, a book, a paragraph, etc, and that’s my corpus/collection of words. First you will encode each word into a vector and then pass into the RNN, what you will get as a output is a probability. I will compare the output with my one-hot encoding groud truth then I will get the loss. When we sum up all the loss and divide by the training example, now we have the loss of the model as shown below.<br><img src="figure4.png" alt="figure4"></p><h3 id="Training-the-model">Training the model</h3><ul><li>Step 1: collect a large corpus of text, i.e., a long sequence</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmathcal%20T%20%3D%20x%5E%7B%281%29%7D%20%5Crightarrow%20%5Ccdots%20%5Crightarrow%20x%5E%7B(T)%7D%20%5Cquad%20%5Ctext%7B(e.g.%2C%20a%20sentence%2C%20a%20document%2C%20etc)%7D%0A" /></p><ul><li>Step 2: feed <img src="https://math.now.sh?inline=T" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> into the model, and compute ouput distribution <img src="https://math.now.sh?inline=%5Chat%7By%7D%5E%7B%28t%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for each <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Step 3: define loss, e.g., cross entropy between <img src="https://math.now.sh?inline=%5Chat%7By%7D%5E%7B%28t%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=y%5E%7B%28t%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (one-hot encoding of <img src="https://math.now.sh?inline=x%5E%7B%28t%2B1%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>)<br><img src="figure5.png" alt="figure5"></li><li>Step 4: gather and average all losses:<br><img src="figure6.png" alt="figure6"></li><li>Step 5: optimization: SGD<br>Note that people are using SGD in common practices, but there are some confusion of implication. Because for SGD we assume all summation terms are independent and identically distributed (iid) in the objective, but here each term is determined by the previous term. It’s definitely not iid but probably because some other unknown reasons/implications that makes it work.<br><img src="figure9.png" alt="figure9"></li></ul><h3 id="Generate-texts">Generate texts</h3><p><img src="figure10.png" alt="figure10"><br>starting from <img src="https://math.now.sh?inline=h%5E%7B%280%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and the word “my”, repeat</p><ul><li>compute <img src="https://math.now.sh?inline=y%5E%7B%28t%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and sample a word from the distribution</li><li>feed the word as input to the next step</li></ul><h2 id="Vanishing-exploding-gradient">Vanishing/exploding gradient</h2><h3 id="How-to-compute-gradients">How to compute gradients?</h3><p>The vanishing gradient problems are not significant in CNNs but they are still there and many CNNs people ignore it. But what we’re emphaszing here is that it’s very significant in RNNs.<br>Can we use auto differentiation in RNNs? Yes! Because it’s firstly sharing the weights and secondly the computational graph is acyclic directed graph (no loops) as image below.<br><img src="figure11.png" alt="figure11"></p><h3 id="Look-into-the-gradient">Look into the gradient</h3><p><img src="figure12.png" alt="figure12"><br>In the image above, we don’t have to worry about <img src="https://math.now.sh?inline=x_t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> because that’s the given value and we know the gradient of a given value is always zero. The variables are <img src="https://math.now.sh?inline=h_%7Bt-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=h_t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and optimization variable is <img src="https://math.now.sh?inline=W" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Let’s look at the computation graph above again. The total loss <img src="https://math.now.sh?inline=L" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is equal with the summation of the loss (<img src="https://math.now.sh?inline=L_1%2C%20L_2%2C%20%5Cdots%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> of each state. Since we know the derivative of the summation is the same as the summation of the derivative, so we have the following:<br><img src="figure13.png" alt="figure13"></p><h3 id="What’s-wrong-with-the-gradient">What’s wrong with the gradient?</h3><p>Consider <img src="https://math.now.sh?inline=%5Cprod_%7Bk%3D2%7D%5Et%20%5Ctext%7Bdiag%7D%28%5Ctanh'(W_hh_%7Bk-1%7D%2BW_xx_k%29)W_h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> above</p><ul><li><p>For intuition, consider identity activation (could be hypertangent, but we just assume it’s identity here) at this moment, i.e, <img src="https://math.now.sh?inline=%5Cprod_%7Bk%3D2%7D%5Et%20W_h%20%3D%20W_h%5E%7Bt-1%7D%20%5Ccdot%20%5C%7CW_h%5E%7Bt-1%7D%5C%7C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, i.e., the largest singular value of <img src="https://math.now.sh?inline=W_h%5E%7Bt-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, scale as <img src="https://math.now.sh?inline=%5C%7CW_h%5C%7C%5E%7Bt-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><ul><li>When <img src="https://math.now.sh?inline=%5C%7CW_h%5C%7C%20%3E%201" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, gradient explodes if <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> large.</li><li>When <img src="https://math.now.sh?inline=%5C%7CW_h%5C%7C%20%3C%201" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, gradient vanishes if <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> small.</li></ul></li><li><p>What happens with the tanh activation?</p><ul><li><img src="https://math.now.sh?inline=%5Ctanh'%28x%29%3D1-%5Ctanh%5E2(x)%20%5Cleq%201" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> – effectively always smaller</li><li>We have</li></ul></li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5C%7C%5Cprod_%7Bk%3D2%7D%5Et%20%5Ctext%7Bdiag%7D%28%5Ctanh'(W_hh_%7Bk-1%7D%2BW_xx_k%29)W_h%5C%7C%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cleq%20%5Cprod_%7Bk%3D2%7D%5Et%20%5C%7C%5Ctext%7Bdiag%7D%28%5Ctanh'(W_hh_%7Bk-1%7D%2BW_xx_k%29)%5C%7C%20%5C%7CW_h%5C%7C%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cleq%20%5Cunderbrace%7B%5Cprod_%7Bk%3D2%7D%5Et%20%5C%7C%5Ctext%7Bdiag%7D%28%5Ctanh'(W_hh_%7Bk-1%7D%2BW_xx_k%29)%5C%7C%7D_%5Ctext%7Bproduct%20of%20many%20numbers%20%3C%201%20when%20t%20large%7D%20%5C%7CW_h%5C%7C%5E%7Bt-1%7D%0A" /></p><p>In this case of using hypertangent, gradient vanishing is more common.</p><h3 id="Gradient-clipping">Gradient clipping</h3><p>When the gradient is too large (exploding), rescale (i.e., clip) it. Let <img src="https://math.now.sh?inline=g" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> be the gradient and <img src="https://math.now.sh?inline=%5Cxi%20%3C%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> be a threshold, because when we’re doing gradient descent, what we’re really caring about is more the direction rather than the magnitude.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Chat%7Bg%7D%3D%5Cxi%5Cfrac%7Bg%7D%7B%5C%7Cg%5C%7C%7D%0A" /></p><p><img src="figure14.png" alt="figure14"><br>You just normalize the direction and rescale by the factor <img src="https://math.now.sh?inline=%5Cxi" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, by clipping large gradient you can avoid the very large movement as the left graph above.</p><h3 id="Problem-with-gradient-Vanishing">Problem with gradient Vanishing</h3><p><img src="figure15.png" alt="figuer15"><br>If we look at the image above, when I evaluate the value of the current node with earlier node, the gradient can be exponentially small such as <img src="https://math.now.sh?inline=%5Cfrac%7B%5Cpartial%20h_t%7D%7B%5Cpartial%20h_1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> when <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is large, which implies ealier states have little impact on latter states. However, what we want in sequential modeling is that we want to make sure what we’ve seen have reasonable influence on the current state.</p><p>The problem is that we hope RNN can encode reasonably long-term historial/contextual information.</p><h2 id="Long-Short-Term-Memory-LSTM">Long Short-Term Memory (LSTM)</h2><p>The key idea of LSTM is to introduce a cell state <img src="https://math.now.sh?inline=c" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to explicitly store history, beside the hidden state <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. It build a universal storage. No matter how far you’re concerning the time step, you can access to the information on the “universal storage”.<br><img src="figure16.png" alt="figure16"><br>All the four gates in the images are a vector, and every step we not only update the state now but also write new things into the universal storage (i.e., cell).</p><h2 id="Gated-Recurrent-Unit-GRU">Gated Recurrent Unit (GRU)</h2><p><img src="figure17.png" alt="figure17"><br>There is a simplified version of LSTM. GRU doesn’t have the universal storage (i.e., cell), but a state with two gates. Each time we write some new content and make it as a linear combination to update the current state <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Both of LSTM and GRU are popular in the field, but LSTM is more powerful but slower in training.</p><h3 id="Do-they-save-the-vanishing-gradient">Do they save the vanishing gradient?</h3><p><img src="figure18.png" alt="figure18"><br>If we ask ourselves what is the Jacobian of the cell state <img src="https://math.now.sh?inline=c" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, it’s simply the diagonal matrix of <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. There is no multiplication by <img src="https://math.now.sh?inline=W" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, so it’s not computational complicated. If we track the flow backward, the dependency between <img src="https://math.now.sh?inline=c_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=c_3" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is only <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><p><img src="figure19.png" alt="figure19"><br>If this looks familiar to you, it’s actually somewhat similiar to ResNet (they’re all skip-connections! Skip-connection allows long-distance dependency), as well as a extreme version of ResNet, which is DenseNet. But there is not a solid understanding that if we really solve the gradient vanishing/exploding problem.</p><h3 id="Do-we-need-to-modify-the-architecture">Do we need to modify the architecture?</h3><p>The problem here is that <img src="https://math.now.sh?inline=W_h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> can have singular values other than 1, becaues greater than 1 leading to explosion while smaller than 1 leading to vanishing gradient. So, a natual solution is to keep all singular values to be 1, but <img src="https://math.now.sh?inline=W_h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is square, which implies that <img src="https://math.now.sh?inline=W_h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is orthogonal.<br>So we can formulate the problem as:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmin_%7BW_h%2CW_x%7D%20L%28W%29%20%5Cquad%20s.t.%20%5Cquad%20W_h%20%5Cquad%20%5Ctext%7Borthogonal%7D%0A" /></p><p>an instance of Riemannian optimization. This is a constrainted optimization problem, which is still largely unexplored in deep neural networks.</p><h1>Modern RNNs</h1><h2 id="Bidirectional-RNNs">Bidirectional RNNs</h2><p>This is to deal with situation such as “… terribly exciting …”. The RNN always tryes to keep the historical information but not utilize the future information, once it reaches to the word “terribly” it may guess the sentence is negative. However, if you read “terribly exciting” together it’s actually expressing positive meaning. So, people have developped a RNN reads both forward and backward – Bidirectional RNNs.<br><img src="figure20.png" alt="figure20"><br>It’s only useful whenever you have the full setences, and it cannot be used in language modeling because you don’t know the future information (user hasn’t typed yet).</p><h2 id="Deep-RNNs">Deep RNNs</h2><p>Hidden state <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> can be thought of representation, and so far we only have one layer, how about going deeper for more powerful representation learning.<br><img src="figure21.png" alt="figure21"><br>Typically, people only have only a few layers (no more than 20), because there is a price to pay – computational intensive.</p><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
            <tag> RNN </tag>
            
            <tag> Gradient Explosion </tag>
            
            <tag> Vanishing Gradient </tag>
            
            <tag> Language Model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>A Survey of Deep Semantic Segmentation on Computed Tomography</title>
      <link href="/2021/01/07/A-Survey-of-Deep-Semantic-Segmentation-on-Computed-Tomography/"/>
      <url>/2021/01/07/A-Survey-of-Deep-Semantic-Segmentation-on-Computed-Tomography/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This survey is one of the assignments I’ve done in the course CSCI 8980 offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020.</p></blockquote><h1>Abstract</h1><p>In this survey, we aim to provide a thorough overview of recent studies in semantic segmentation on medical imaging analysis, especially on Computed Tomography (CT). We mainly point out the intuitive novelty of architectural design of each neural network popular in the field, as well as the loss functions used in mainstream researches. Further, we introduce the particular image format in CT, discuss some challenges and present potential future directions that are promising for semantic segmentation in medical imaging.</p><h1>Introduction</h1><p>Semantic Segmentation has been one of the most important tasks within deep learning community, and many papers have shown that Deep Neural Networks (DNNs) are sufficient to gain a relatively good performance based on natural images. Lateef and Ruichek (2019) in their survey summarized many neural network designs, datasets, and methods for semantic segmentation of natural images. Guo et al. (2017) provided a review on deep-learning-based semantic segmentation and mainly focused on literature of fully convolutional networks (FCNs) and weakly supervised methods.</p><p>In recent years, medical computer vision has been one of the most critical areas in active scientific research. Within medical domain, medical imaging analysis with semantic segmentation can be used to improve radiological diagnostics by human-machine interaction, radiotherapy, etc. Taghannaki et al. (2019) provided a high-level review of the adoption of methods and architectural networks for medical imaging segmentation from natural imaging segmentation. Hesamian et al. (2019) listed out the state-of-the-art (SOTA) architectural designs of DNNs in medical imaging segmentation, and covered some practical training tricks. In this survey, we’re contributing to explain the intuitive of architectural design of each novel component module to the existing convolutional neural networks (CNNs), as well as the basic understanding of most commonly used loss functions.</p><h1>CT Imaging Data</h1><p>Before we dive into deep learning techniques, we have to be familiar with the coordinate systems that are being used in medical imaging including CT scans, and how to prepare them to fit into DNNs as inputs.</p><h2 id="Coordinate-Systems">Coordinate Systems</h2><p>In most of the medical imaging applications, there are three commonly used coordinate systems, which are world, anatomical and medical image coordinate systems (see Figure 1). The world coordinate system is the cartesian coordinate system in which the medical imaging modality is positioned. Each modality has its own world coordinate system, including different CT scanners.<br><img src="figure1.png" alt="figure1"></p><p>The most frequent coordinate system involving in medical imaging conversation among doctors, radiologists, and deep learning scientists is the anatomical coordinate system, which is also called patient coordinate system. It includes axial, sagittal, coronal planes to describe the standard anatomical position of a human. Furthermore, the 3D position is defined along anatomical axes of anterior-posterior (front-back), left-right and inferior-superior. For example, the axial plane practically refers to the slices you can see along with inferior-superior axis when looking down. For clinical consistency, a slice near to the head is as superior, while a slice near to the feet is as inferior. The sagittal plane is what you see from left to right, from which you can see the ears of patients, and coronal plane travers from anterior to posterior of the patients, or vice versa. In practice, there are two  different anatomical coordinate system named LPS and RAS, where LPS is used by DICOM and ITK toolkit of Python, and RAS is used by other medical softwares such as 3D slicer.<br><img src="table1.png" alt="table1"><br>The medical image coordinate system is what we’re familiar with as voxel space, which is also the coordinate system of ideal input for most of the deep neural networks. Notably, the pixel depth of each slice can fall in the range of 0 to <img src="https://math.now.sh?inline=2%5E%7B16%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, compared with 0 to <img src="https://math.now.sh?inline=2%5E8" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> in many natural imaging datasets.</p><h2 id="DICOM">DICOM</h2><p>DICOM is a medical format which is successfully integrated in medical imaging modalities manufactured by different vendors, and it has been naturally becoming the industry standard. It not only stores the medical image data but also meta-data of a patient, which includes demographic information (e.g., name, age, gender), acquisition data (e.g., type of modality used and its setting) and the context of imaging study (e.g., patient’s historical record) according to the article posted by Adaloglou (2020). DICOM is meanwhile a network protocol, which makes it easier to share information within hospital networks, but that’s out of the scope of this survey. We’re mostly interested in knowing our data and how to process them in order to fit into the training model.</p><p>Currently, due to variety of modalities there is not a universal tool that can load the imaging part of DICOM into an 3D Numpy array. However, there are two Python tools named dcm2nixx and Pydicom that can help us to manipulate DICOM folders and convert DICOM files into Nifty (.nii) data, from which we can use a Python library called Nibabel to load nifty data into 3D Numpy array. Nifty format is also used in the dataset of many medical imaging challenges nowadays. However, the preprocessing requires lots of labors because the real-world medical data are often messy. For instance, each folder may only contain one DICOM file which is only a 2D CT slice of a CT volume, and exams of different modalities are likely to fall into different folders.</p><h1>Network Architecture Progression</h1><h2 id="Fully-Convolutional-Network-FCN">Fully Convolutional Network (FCN)</h2><p>Long et al. (2014) proposed the Fully Convolutional Network (FCN), which was one of the first neural networks that brought out a new way of looking at semantic segmentation problems. Before FCN, people generally used combining convolutional layers and fully connected layers to construct the network, but apparently it doesn’t fully make use of contextual spatial information of images. Long et al. (2014) proposed replacing fully connected layers with all convolutional layers (see Figure 2), with the strategies of up-sampling (transposed convolution) and feature fusion. The outputs of FCNs are directly predicted masks, and it greatly improves both testing accuracy and training efficiency in semantic segmentation problems. Christ et al. (2016) achieves Dice score over 94% for liver with computation time below 100 second per CT volume with a Cascaded FCN in MICCAI 2016.<br><img src="figure2.png" alt="figure2"></p><h2 id="Encoder-decoder-Network">Encoder-decoder Network</h2><h3 id="SegNet">SegNet</h3><p>SegNet proposed by Badrinarayanan et al. (2015) is similar with FCN in design, but is different in up-sampling techniques. FCNs perform feature fusion in the output after transposed convolution in decoder with the corresponding feature map with the same size in encoder, while the decoder of SegNet uses the pooling indices (see Figure 3) computed during max-pooling of encoder to perform non-linear up-sampling. SegNet was adopted by Almotairi et al. (2020) in liver tumor CT scans, and the work detects most part of the tumor, with an accuracy  above 86%.<br><img src="figure3.png" alt="figure3"></p><h3 id="U-Net-V-Net">U-Net/V-Net</h3><p>U-Net proposed by Ronneberger et al. (2015) were designed for biomedical image segmentation. Today, U-Net and its variations have been widely used within computer vision community for segmentation tasks, due to its outstanding performance. The novelty of U-Net is the skip-connection design (see Figure 4), which performs feature concatenation comparing to FCNs with feature fusion (feature addition). Skip-connections increases the accuracy of the model and resolves some gradient vanishing problems. A recent work of 3D variant of U-net named FracNet by Jin et al. (2020) achieves 92.9% sensitivity and an average false positive of 5.27 on rib fracture detection on CT volumes directly. Notably, the architectural design of V-Net proposed by Milletari et al. (2016) is merely the 3D version of U-Net with more skip-connections, usage of volumetric image as input, and optimization of Dice metrics.<br><img src="figure4.png" alt="figure4"></p><h3 id="FC-DenseNet">FC-DenseNet</h3><p>Jegou et al. (2016) proposed Fully Convolutional DenseNet, which is also called Tiramisu by the author. The overall network architecture is based on U-Net, but with dense blocks used in DenseNet by Huang et al. (2016). By replacing convolution operations with dense blocks, it further deals with vanishing-gradient problem, strengthens feature propagation, and encourages feature reuse (see Figure 5). Even though the input of a dense block is not concatenated with its output in up-sampling path due to computational constraints, some information that is lost due to pooling operation can be passed by skip-connections from the down-sampling path. To my best knowledge, there hasn’t been much work of using FC-DenseNet on medical imaging segmentation of CT except Kolarik et al. (2019), but the experiment they performed was only on a small dataset with 10 CT scans.<br><img src="figure5.png" alt="figure5"></p><h3 id="DeepLabs">DeepLabs</h3><p>DeepLabV1 by Chen et al. (2016) used deep convolutional neural network followed by a fully connected Conditional Random Field (CRF) as post-processing to refine the segmentation result. DeepLabV2 by the same group proposed atrous spatial pyramid pooling (ASPP) to capture the image context at multiple scales. DeepLabV3 added convolution of kernel size of 1x1 and employed global average pooling in order to avoid losing spatial dimensions during down-sampling. DeepLabV3+ (see Figure 6), as the latest version, added encoder-decoder architecture to expend DeepLabV3. Notably, DeepLabV3/V3+ gives up CRF because deep neural network has refined the segmentation result along object boundary. Since DeepLabV3+ reached SOTA performance, today people like to use it as comparison for segmentation tasks. Zhou et al. (2020) has come up with a variant of atrous convolution and achieved improved accuracy and less trainable parameters than DeepLabV3+ on right ventricle, left ventricle and aorta segmentation in CT imaging.<br><img src="figure6.png" alt="figure6"></p><h3 id="PSPNet">PSPNet</h3><p>Zhao et al. (2016) proposed Pyramid Scene Parsing Network (PSPNet), and its novel pyramid pooling module (see Figure 7) can effectively generate sub-region feature maps on multiple scales in order to capture global context. Yang et al. (2018) combined pyramid pooling model and FCN in kidney and renal tumor segmentation of CT imaging, and their 3D_FCN_PPM network outperformed 2D PSPNet and 3D U-Net.<br><img src="figure7.png" alt="figure7"></p><h3 id="DRINet">DRINet</h3><p>To revolve vanishing-gradient problem existing in 3D U-Net and meanwhile make the network deep and wide, Chen et al. (2018) proposed Dense Residual Inception Net (DRINet). The gradient propagation was improved by both dense connections and residual connections, where residual blocks can aggregate feature maps from different branches and dense blocks can reuse previous feature maps and alleviate vanishing-gradient problems. In experiment, DRINet outperformed 3D FCNs in 2D CT slices of Cerebrospinal Fluid (CSF) segmentation.<br><img src="figure8.png" alt="figure8"></p><p><strong>More Network Architectures</strong> Other than the basic architectural designs mentioned earlier in imaging segmentation domain, there are other innovative designs to improve performance as well. A good amount of papers in recent years such as Lian et al. (2018), Li et al. (2019), Nie et al. (2018) have attempted the attention-based medical imaging segmentation models. Furthermore, Khosravan et al. (2019) and Jin et al. (2018) have leveraged the concept of Generative Adversarial Network (GAN) to medical imaging segmentation in CT scans.</p><h1>Loss Function Progession</h1><h2 id="Based-on-Distance">Based on Distance</h2><h3 id="Weight-Cross-Entropy-WCE">Weight Cross Entropy (WCE)</h3><p>Cross Entropy is pixel-wise and examines each pixel individually, but it could be problematic when it comes to medical imaging due to class imbalanced problems. Therefore, Weight Cross Entropy was born to counteract a class imbalanced by introducing weights to loss function.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=WCE%28p%2C%5Chat%7Bp%7D%29%3D-(%5Cbeta%20p%20%5Clog(%5Chat%7Bp%7D)%2B(1-p)%5Clog(1-%5Chat%7Bp%7D))%0A" /></p><h3 id="Balanced-Cross-Entropy-BCE">Balanced Cross Entropy (BCE)</h3><p>In WCE, we can set <img src="https://math.now.sh?inline=%5Cbeta%20%3E%201" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to decrease false negative, or set <img src="https://math.now.sh?inline=%5Cbeta%20%3C%201" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to decrease false positive. In order to weight negative pixels as well, BCE discussed by Xie and Tu (2015) can be used.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=BCE%28p%2C%5Chat%7Bp%7D%29%3D-(%5Cbeta%20p%20%5Clog(%5Chat%7Bp%7D)%2B(1-%5Cbeta)(1-p)%5Clog(1-%5Chat%7Bp%7D))%0A" /></p><p>In the U-Net paper by Ronneberger et al. (2015), they added a distance learning function into BCE, to enforce the model to pick up the notion of distance, so that it has a better segmentation behavior even though two objects are close in images.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=BCE%28p%2C%5Chat%7Bp%7D%29%2Bw_0%20%5Ccdot%20exp%5Cleft(-%5Cfrac%7B((d_1(x)%2Bd_2(x))%5E2%7D%7B2%20%5Csigma%5E2%7D%5Cright)%0A" /></p><h3 id="Focal-Loss">Focal Loss</h3><p>To decrease the contribution of easily-segmented example and have the model focus on difficultly-segmented example, Lin et al. (2017) introduced Focal Loss by further improving BCE with additional term <img src="https://math.now.sh?inline=%281-%5Chat%7Bp%7D%29%5E%7B%5Cgamma%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=FL%28p%2C%5Chat%7Bp%7D%29%3D-(%5Calpha(1-%5Chat%7Bp%7D)%5E%7B%5Cgamma%7Dp%5Clog(%5Chat%7Bp%7D)%2B(1-%5Calpha)%5Chat%7Bp%7D%5E%7B%5Cgamma%7D(1-p)%5Clog(1-%5Chat%7Bp%7D))%0A" /></p><p>With larger <img src="https://math.now.sh?inline=%5Calpha" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, the contribution of the number of corresponding class to the loss function is higher; with larger <img src="https://math.now.sh?inline=%5Cgamma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, the contribution of difficultly-segmented samples to the loss function is higher. When <img src="https://math.now.sh?inline=%5Cgamma%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, it’s equivalent to BCE. When <img src="https://math.now.sh?inline=%5Cgamma%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Calpha%20%3D%200.5" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, it’s equivalent to CE.</p><h2 id="Based-on-Overlap-Measure">Based on Overlap Measure</h2><p>The most common way to measure overlap is by Intersection over Union (IoU).</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=IoU%3D%5Cfrac%7BTP%7D%7BTP%2BFP%2BFN%7D%3D%5Cfrac%7B%7CX%20%5Cbigcap%20Y%7C%7D%7B%7CX%7C%2B%7CY%7C-%7CX%20%5Cbigcap%20Y%7C%7D%0A" /></p><p>where <img src="https://math.now.sh?inline=X" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=Y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> stand for predicted voxel-wise predicted label and groud truth respectively. This is the most straightforward overlap measure, and it has a range of <img src="https://math.now.sh?inline=%5Clbrack%200%2C1%20%5Crbrack" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. If the <img src="https://math.now.sh?inline=IoU" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is closer to 1, then our prediction is closer to ground truth.</p><h2 id="Dice-Loss-DL">Dice Loss (DL)</h2><p>In order to understand Dice Loss, one firstly have to understand Dice Coefficient (DC). DC is equivalent to F1-Score, and can be understood as adding <img src="https://math.now.sh?inline=%7CX%20%5Cbigcap%20Y%7C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to both denominator and numerator of Iou, so <img src="https://math.now.sh?inline=DC%20%5Cgeq%20IoU" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and they’re positively correlated. Similarly, the range of DC is also <img src="https://math.now.sh?inline=%5Clbrack%200%2C1%20%5Crbrack" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Its expression is</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=DC%20%3D%20%5Cfrac%7B2TP%7D%7B2TP%2BFP%2BFN%7D%3D%5Cfrac%7B2%7CX%20%5Cbigcap%20Y%7C%7D%7B%7CX%7C%20%2B%20%7CY%7C%7D%0A" /></p><p>So, it can be used to design DL as</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=DL%20%3D%201%20-%20DC%20%3D%201%20-%20%5Cfrac%7B2%7CX%20%5Cbigcap%20Y%7C%7D%7B%7CX%7C%20%2B%20%7CY%7C%7D%20%3D%201%20-%20%5Cfrac%7B2%20%5Clangle%20p%2C%20%5Chat%7Bp%7D%20%5Crangle%7D%7B%5C%7Cp%5C%7C_1%2B%5C%7C%5Chat%7Bp%7D%5C%7C_1%7D%0A" /></p><p><img src="https://math.now.sh?inline=%5Clangle%20p%2C%20%5Chat%7Bp%7D%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> represents the dot product between prediction volume and groud truth volume of each channel, which can effectively reset all voxels that are not in target mask to <img src="https://math.now.sh?inline=0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> due to binary segmentation; <img src="https://math.now.sh?inline=%5C%7C%5Ccdot%5C%7C_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is L1 norm, which is the sum of absolute value of each element in tensor. In order to simplify computation, it can be replaced by L2 norm <img src="https://math.now.sh?inline=%5C%7C%5Ccdot%5C%7C_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Dice Loss were proposed in V-Net by Milletari et al. (2016), and it worked well for imbalanced class problem.</p><h2 id="Tversky-Loss-TL">Tversky Loss (TL)</h2><p>Tversky Loss by Salehi et al. (2017) is the generalization version of Dice Loss. In order to balance the influence of FP and FN toward loss function, TL added weights as following</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=TL%28p%2C%5Chat%7Bp%7D%29%3D%5Cfrac%7B%5Clangle%20p%20%2C%20%5Chat%7Bp%7D%5Crangle%7D%7B%5Clangle%20p%20%2C%20%5Chat%7Bp%7D%5Crangle%20%2B%20%5Cbeta(1-p%2C%20%5Chat%7Bp%7D)%2B(1-%5Cbeta)(p%2C1-%5Chat%7Bp%7D)%7D%0A" /></p><p>Notably, if <img src="https://math.now.sh?inline=%5Cbeta%20%3D%200.5" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then it’s equivalent to Dice Loss.</p><h2 id="Combo-Loss">Combo Loss</h2><p>Taghanaki et al. (2018) found the risk of using solely distance-based or IoU-based loss function, and introduced Combo Loss. In practices of CT imaging segmentation, it’s commonly seen that people like to use combo loss, because it’s more stable. If the foreground (object in medical domain) is too small and the background is dominating, then using focal loss or combo loss is more likely to guarantee good performance (see Figure 9), because as the IoU decreases (more false positives and false negatives) only focal loss and combo loss  are monotone increasing, compared to the wave curves on other loss functions.<br><img src="figure9.png" alt="figure9"></p><p><strong>More Optimization Functions</strong> Other than the most commonly seen loss functions above for segmentation, there also are some other optimization functions for particular needs. Wong et al. (2018) introduced Exponential Logarithmic Loss which combines Exponential Logarithmic Dice Loss and Weight Exponential Cross Entropy to handle object-size imbalanced problems. Zhu et al. (2018) introduced Conservative Loss which aims to penalize the extreme cases and embrace the moderate cases in order to achieve good generalization. In short, there are three categories to optimize loss functions, which can be adapted to particular segmentation tasks depending on the needs. They’re weighting the objective loss function, optimizing the segmentation metrics, and adding regularization terms to the loss function.</p><h1>Challenges and Future Directions</h1><p>Since there are different imaging modalities and each may involves different levels of artifacts, as well as the fact that datasets of medical imaging are very limited, a promising direction is to work on transfer learning of pre-trained model in natural images and apply it in medical imaging segmentation. Raghu et al. (2019) in Google are proactively putting effort on this.</p><p>One can aim to creating large medical imaging datasets for segmentation benchmarks, so that researchers can accurately compare performance over different models. Yang et al. (2020) created MedMNIST that covers the primary data modalities in medical imaging analysis, which has great educational value and more accessible to general public; however, the size of each image (28 x 28) is doubtful for machines to learn the patterns of various diseases.</p><p>Many convolution-based neural networks are capable to extract features, but often miss small objects or edge information of big objects. If one tends to improve architectural design, this may be a promising direction; however, due to the improvement of Elsken et al. (2018), even the architectural designs might be carried out by the machines in the future.</p><p>Many studies including Drozdzal et al. (2017) have shown that pre-processing could be a key to improve the performance of segmentation network. In practices, most of the time deep learning scientist are trying to enhance the characteristics of the lesion areas according to the goal of the segmentation task. Moreover, the pre-processing could even be achieved by another neural network to build a multitask model (i.e., first detect then segment), and this is shown by Ke et al. (2019) and He et al. (2018).</p><p><strong>More Directions</strong> It’s known that there are always class imbalanced problem and shortage of data in medical imaging domain, so one could focus on the Generative Adversarial Networks (GANs) for image synthesis, in order to fill out the dataset, and the studies of Chartsias et al. (2017) and Zhang et al. (2019) have shown that with the Magnetic Resonance Imaging (MRI) data synthesized from CT data it improve the segmentation performance of the models. There are also many times we may only have a few labels or annotated data, because having several radiologists to create an excellently annotated dataset with voting is not feasible in many cases, so one can develop a weakly supervised model like Amyar et al. (2020) and Kervadec et al. (2019)'s work. Notably, this direction is more likely to propose a good generalization over various segmentation targets.</p><h1>Conclusion</h1><p>This paper summarizes most of the intuitive useful modules/blocks of network architecture using in semantic segmentation, and for each of them provides a recent deployment in 3D CT imaging segmentation studies. Also, it gives a bird’s-eye view of some potential promising future directions to address certain challenges existing in medical imaging relatde to CT scans.</p><h1>References</h1><blockquote><p>The paper was written in LaTex, so here are some screenshots of the references.<br><img src="reference1.png" alt="reference1"><br><img src="reference2.png" alt="reference2"><br><img src="reference3.png" alt="reference3"></p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
            <tag> Segmentation </tag>
            
            <tag> Computed Tomography (CT) </tag>
            
            <tag> Loss Function </tag>
            
            <tag> Survey </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Convolutional Neural Network (CNN): Overview</title>
      <link href="/2021/01/06/Convolutional-Neural-Network-CNN-Overview/"/>
      <url>/2021/01/06/Convolutional-Neural-Network-CNN-Overview/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) was offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><h1>From Fully Connected to Convolutional Neural Networks</h1><h2 id="Find-patterns-in-an-image">Find patterns in an image</h2><h3 id="Digital-Images">Digital Images</h3><p><img src="figure1.png" alt="figure1"><br>Digit images can be simply looked as matrices, and each entry of matrices (i.e., pixels) is an integer. We call the traditional MNIST images gray scale level images. Color images are 3-dimensional tensors. R,G,B are respectively treated as a gray scale image. We usually normalize the data to alleviate the effect of noise, by</p><ul><li>dividing the data by its “pixel-depth - 1” <img src="https://math.now.sh?inline=%28%5Cfrac%7Bimage%7D%7B2%5En-1%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>zero-mean unit-variance</li><li>min-max.</li></ul><p>This little change can effect performance to an extent. JPEG by default usually throws some details out from the images. If you’re dealing with questions that every pixel is important, maybe you want to use PNG rather than JPEG since PNG is lossless.</p><h3 id="How-to-find-a-pattern-in-images">How to find a pattern in images?</h3><p><img src="figure2.png" alt="figure2"><br>Let’s divide it by two questions. We firstly ask whether this object is in this image. Secondly we ask where is the object in the image if this object is in this image. Scan-window method is to take a sample and scan through the entire image to find similarity (distance). Inner product is a measure of similarity, and each time inner product of the original (red) and overlapped (green) patches are taken. If they’re similiar, then the inner product is larger. The output matrix is called the correlation. Now let’s look at the largest magnitude because that will be the canidate match of detection.<br>Is correlation always reliable? No, a counterexample in this case is that the background is plain white.</p><h3 id="Template-matching-previals-in-classic-image-processing">Template matching previals in classic image processing</h3><p><img src="figure3.png" alt="figure3"><br>How do you detect the edge? A typical edge looks like left(white) right(black) middle(gray) as the picture above.</p><h3 id="Problem-with-template-matching">Problem with template matching</h3><p><img src="figure4.png" alt="figure4"><br>What are some potential problems? Would scan-window method work here? In practices, there are many variation. This object can be smaller, larger, scaling, rotation, deformation, etc.</p><h3 id="Feature-based-approach">Feature-based approach</h3><p><img src="figure5.png" alt="figure5"><br>We may be convinced that the classic template matching slicing window scheme doesn’t work well if there are data augmentation (rotation, scaling, translation, etc). So, is it possible to extract the features first that are invariant to scaling, rotation, deformation? Yes! An era of feature-based methods has begun…</p><h2 id="Problems-with-fully-connected-networks">Problems with fully connected networks</h2><h3 id="Complexity">Complexity</h3><p><img src="figure6.png" alt="figure6"><br>Fully connected networks are not feasible just looking at the dimension. Images with high-resolution have many pixels, which are the input of neural networks. It’s computational impossible. This is from the complexity and storage point of view.</p><h3 id="Locality-and-ordering">Locality and ordering</h3><p><img src="figure7.png" alt="figure7"><br>No many people talk about this argument but it’s very important. An image tends to have some local structure, because adjacent pixels of natural images are highly correlated. Natual images are pixel-wise smooth. Fully connected neural networks (FCNNs) treats the input as vector, and it’s even insensitive to any universal permutation of the coordinates of all inputs.</p><h3 id="Invariance">Invariance</h3><p>It’s not sensitive to where the object is in the image. You always want to do certain levels of invariance in recognition. For intance, if I move the digit 8 around in the image, the neural network should be invariant to translation. Think about moving a digit from one place to another place in the image, in the image pixel matric what we see is some irregualr movements/changes. In short, fully connected network is not invariant to scaling, rotation, translation, etc.</p><h3 id="Ideal-neural-networks-for-spatial-data">Ideal neural networks for spatial data</h3><p><img src="figure8.png" alt="figure8"><br>We hope to acheive learning features locally. For instance, learn the low-level features such as lines, edges, curves, etc, or a bit high-level featuers such as eyes, ears, etc, which are invariant to translation, rotation, local deformation, etc.</p><h3 id="A-quick-preview-of-convolutional-neural-network-CNN">A quick preview of convolutional neural network (CNN)</h3><p><img src="figure9.png" alt="figure9"><br>Input -&gt; Convolution Layers (Feature Extraction) -&gt; Fully Connected Layers (Classification) -&gt; Output</p><h2 id="Components-of-CNNs">Components of CNNs</h2><h3 id="Convolution-Layer">Convolution Layer</h3><h4 id="Convolution-is-misnomer">Convolution is misnomer!</h4><p><img src="figure10.png" alt="figure10"><br>Convolution is actually mathematically a wrong name. It’s pretty much correlation. The only difference here is if you flip or not as shown in the image above. People actually implement correlation and call it convolution… In math notation, <img src="https://math.now.sh?inline=%5Cast" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for convolution and <img src="https://math.now.sh?inline=%5Cstar" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for (cross)-correlation.</p><h4 id="More-on-conlution-correlation">More on conlution/correlation</h4><p><img src="figure11.png" alt="figure11"><br>In image, people usually call the template in between as filter/kernel. Also, people call the area the filter cover each time in the image as receptive field. Further, people call the output from kernel as feature map.<br>There are also two concepts, which are padding and stride. Padding is to put 0s outside of the image. People do this in order to catch edge information. Stride is basically meaning step size here. Sometimes if people want to skip one pixel, they will usually set the stride as 2. More information and GIF can be found <a href="https://github.com/vdumoulin/conv_arithmetic">here</a>. Typically, people only set stride to at most 2.</p><h4 id="Connection-to-fully-connected-neural-network">Connection to fully-connected neural network</h4><p><img src="figure12.png" alt="figure12"><br>Abstractly, you can think of convolution imports local pattern. Think of it in the fully-connected neural network, then convolution makes each neuron connects only to its receptive field, and all neurons share the same weight pattern.<br>Convolution enforeces local pattern, because each time I only look at local area. By weight sharing, we cut down the number of parameters that we need to learn.</p><h4 id="Multiple-filters-each-layer">Multiple filters each layer</h4><p><img src="figure13.png" alt="figure13"><br>For one filter, as image above from input volomn to output volomn there is an important summation, which acts just like flatten the matrix. Btw, 2D covolution is moving in 2D. It’s not 3D convolution because it’s not moving in depth but moving 3D tensor in 2D.</p><h4 id="Do-we-reduce-the-complexity">Do we reduce the complexity?</h4><p>Suppose <img src="https://math.now.sh?inline=C_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> input channels and <img src="https://math.now.sh?inline=C_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> output channels of size <img src="https://math.now.sh?inline=H%20%5Ctimes%20W" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li>number of parameters if implementing fully connected layer: <img src="https://math.now.sh?inline=0%28C_1C_2H%5E2W%5E2%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>number of parameters if implementing convolution of <img src="https://math.now.sh?inline=h%20%5Ctimes%20w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? <img src="https://math.now.sh?inline=O%28C_1C_2hw%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> where <img src="https://math.now.sh?inline=h%2Cw" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> are usually small constants, e.g., 3 in practice</li></ul><h3 id="Pooling-Layer">Pooling Layer</h3><p>Convolution helps to achieve locality, and reduced complexity, what about invariance?<br><img src="figure14.png" alt="figure14"><br>Pooling is not a difficult operation to understand. In the image above, there is a 4x4 image. If the size of pooling receptive field size is 2x2 with a stride of 2. Then I just slide the pooling receptive field over the original image. For max pooling, I select the maximum pixel value of within my pooling receptive field. Other than max pooling, there are also average pooling, i.e., weighed average within the receptive field.</p><h4 id="Why-pooling">Why pooling?</h4><p><img src="figure15.png" alt="figure15"></p><ul><li>deep layer: more filters, which makes us end up with many channels (thicker), so we have to subsample to avoid explosion in computation</li><li>subsampling keep important features; for imaging processing, most of the time people are doing recognition, so what matters is the general shape but not low-level details. So, subsampling is ok.<br><img src="figure16.png" alt="figure16"><br>Do we really achieve invariance?<br><img src="figure17.png" alt="figure17"><br>Let’s look at the image above as top view and bottom view, where the bottem view can be think of the top view’s detector stage move to the left by 1. What we observe is that even though there are movement in detector stage, but the pooling stage is roughly the same, and that’s roughly what we mean by saying pooling can achieve a certain degree of invariance.</li></ul><h4 id="Combine-covolution-and-pooling-–-convolution-with-strides">Combine covolution and pooling – convolution with strides</h4><p>idea: convolution with stride <img src="https://math.now.sh?inline=%5Cgeq" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> 2 <img src="https://math.now.sh?inline=%5Capprox" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> convolution + subsampling</p><p>One can either do a stride 2 pooling after convolution, or simply a convolution with stride 2. The idea of getting rid of pooling layers is more and more popular within Generative Adversial Networks (GANs).</p><h3 id="Why-multilayers">Why multilayers?</h3><ul><li>For efficiency: each object can have different variations, simply using one kernel for each variation of the object is impossible.</li><li>For goodness: Kernels can be shared across digits or all object catogories; low-level features likely sharable <img src="https://math.now.sh?inline=%5Cimplies" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> form hierarchy</li></ul><h4 id="Hierarchical-feature-learning">Hierarchical feature learning</h4><p><img src="figure18.png" alt="figure18"><br>The above are the real output of certain layers of CNNs. Really we see that low-level feature is somewhat similiar.</p><h3 id="Computation">Computation</h3><h4 id="How-to-compute-convolution">How to compute convolution?</h4><p>Convolution layer is locally connected, weight-sharing fully connected layer. If we vetorize both input and output, the operation can be represented as a matrix multiplication.<br><img src="figure19.png" alt="figure19"></p><h4 id="More-on-computation">More on computation</h4><p>To compute the convolution</p><ul><li>use (sparse) matrix-vector multiplication (early version of cuDNN)</li><li>ise fast Fourier transform (introduced in later version of cuDNN)</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmathcal%20F%20%28w%20%5Cast%20x%29%3D%5Cmathcal%20F(w)%20%5Codot%20%5Cmathcal%20%20F(x)%0A" /></p><p>To compute the max-pooling</p><ul><li>forward: just try to pick up the maximum</li><li>backward? what’s <img src="https://math.now.sh?inline=%5Cnabla_x%20max%28x_1%2C%5Cdots%2Cx_n%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><h2 id="Architectures-for-classification">Architectures for classification</h2><h3 id="Typical-design-patterns">Typical design patterns</h3><p>Feature Extraction (Conv) + Classification (Fully connected)</p><ul><li>Conv: depth increases (more filters), dimension decreases (subsampling) when moving deeper<br><img src="figure20.png" alt="figure20"></li><li>one or two fully connected layers for classifaction</li></ul><h4 id="LeNet-5-1998">LeNet-5 (1998)</h4><p><img src="figure21.png" alt="figure21"><br>At that time, people were stilling using hypertangent, and 5x5 filter, which now has been replaced by ReLU and 3x3 filter.</p><h4 id="AlexNet-2012">AlexNet (2012)</h4><p><img src="figure22.png" alt="figure22"><br>Naivly, this can be thought of as a deeper version of LeNet with more convolutional layers and more fully connected layers. This brings a breakthrough on ImageNet competition in 2012, and impressed the computer vision community.</p><ul><li>ReLU as activation</li><li>larger filters: 11x11, 5x5, 3x3</li><li>dropout used for regularization (dropout wasn’t proposed by this paper but made popular by this paper)</li><li>weight decay/regularization</li></ul><h4 id="VGG-Net-2014">VGG-Net (2014)</h4><p><img src="figure23.png" alt="figure23"><br>This is a further deeper version of AlexNet. (At that time, people really was trying to go deeper after they see the befinit of more layers.) They have some novel modification, which they perform several convolution in a row and followed by a pooling layer. The intuition comes from the associative law of convolution, which is</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=a%20%5Cast%20%28b%20%5Cast%20c%29%20%3D%20(a%20%5Cast%20b)%20%5Cast%20c%0A" /></p><p>This is to say that I can have serveral smaller filter (several convolution layers) and gain a roughly (<strong>not exactly</strong>) the same effect of a single large filter. And you will found the number of parameters reduce significantly.</p><h4 id="ResNet-2015">ResNet (2015)</h4><p>Sometimes performance get worse when the network is really deep. What’s going wrong? The performance somewhat get degragated during going deeper.<br><img src="figure24.png" alt="figure24"></p><ul><li>skip connection</li><li>batch normalization<br>Intuition for skip connection: If I have a task which has 50 layers to attain optimal performance already, what if I add up to 100 layers? That will bring performance degragation, but if I have skip connection after the 50th layer because I know it doesn’t need 100 layers. If I training algorithm is smart enough, it will make the weights of all the layers after 50th layer to be zeros. Then, without lossing the previous information from eailier layers, even though the latter layers’s weight are zeros, but I can still reach to output layer with skip connection. In addition, skip connection in auto differention package also acts like a skip conenction. Moreoever, skip connection also alleviates vanishing-gradient problem to some extents.</li></ul><h4 id="Dense-2016">Dense (2016)</h4><p>No soon after ResNet, Dense Net was proposed to take full adventage of skip connections.<br><img src="figure25.png" alt="figure25"></p><h4 id="Other-models-to-look-at">Other models to look at</h4><p>on accuracy:</p><ul><li><a href="https://arxiv.org/abs/1905.11946">EfficientNet</a></li><li><a href="https://arxiv.org/abs/1611.05431">ResNeXt</a></li></ul><p>on compact model:</p><ul><li><a href="https://arxiv.org/abs/1602.07360">SqueezeNet</a></li><li><a href="https://arxiv.org/abs/1807.11164">ShuffleNet</a></li><li><a href="https://arxiv.org/abs/1801.04381">MobileNet</a></li></ul><h2 id="Practicle-tips">Practicle tips</h2><h3 id="Transfer-Learning">Transfer Learning</h3><p>We recall that CNNS learn increasingly complex and sementically meaningful features, while they have similiar low-level features. So, lower-level tend to learn features that are generic.<br><img src="figure26.png" alt="figure26"><br>The image above you can see that different objects can share similiar low-level features. So, people can take a pretrain model (take both network architecture and <strong>weights</strong>) which has been trained on a very large and diverse dataset, as a starting point. And based on the size of dataset of you task, to select a scheme to perform fine tuning as the image below.<br><img src="figure27.png" alt="figure27"></p><h3 id="Are-CNNs-only-for-images">Are CNNs only for images?</h3><p>No, it’s popular in imaging, but also can be used in speed recognition, text classification, video analysis, and time series analysis.</p><h3 id="Transposed-Convolution">Transposed Convolution</h3><p>convolution with strides: downsampling<br>transposed convolution: unsampling<br>Transposed convolution is often used for segmentation (U-Net), generation, or other regression. The ouputs are structured object such as images, videos, time series, speech, etc.<br>For unsampling, there are definitely classical way to perform it, which is nearest neighbor/bilinear/bicubic intepolation. In deep learning, people want to learn interpolation with learnable filter, that’s why the transposed convolution come into play. Actually, transposed convolution is also called <strong>fractionally strided convolutions</strong> or deconvolution.<br><img src="figure28.png" alt="figure28"><br>The graph and more details are <a href="https://github.com/vdumoulin/conv_arithmetic">here</a>.</p><h3 id="Normalization">Normalization</h3><p><img src="figure29.png" alt="figure29"><br>normalization in different directions/groups of the data tensors</p><ul><li>N is the batch size</li><li>C is the channel size</li><li>WH is the per output dimension (1D for fully connected, but 2D for CNNs)</li></ul><p>batch normalization is popular, but with layer/group normalization you can have small N (batch size), reach simplicity (training/test normalizations are consistent).</p><h1>Applications of CNNs in Computer Vision</h1><blockquote><p>Acknowledgement: The content of the following slides is from one of the grad students in the class, Andrea Walker, who were giving a presentation.</p></blockquote><h2 id="Object-Detection">Object Detection</h2><h3 id="What-is-object-detection">What is object detection?</h3><p>There are 2 main tasks:</p><ul><li>Localizing one or more objects in the image</li><li>Classifying each object in the image<br><img src="figure31.png" alt="figure1"><br>Credit: The image above is from <a href="https://arxiv.org/abs/1809.06849">Islam el al., 2019</a>.</li></ul><h3 id="Object-Detection-Network">Object Detection Network</h3><p><img src="figure32.png" alt="figure2"><br>The image above is from <a href="http://vision.stanford.edu/teaching/cs231n/slides/2020/lecture_12.pdf">Stanford CS231N</a>. The inputs here are a image and a bounding box which contains the object, and the outputs here are a classification score of multiclass and a bounding box of the classified object. Since after the CNN conponent, there are two fully connected layers to output two different outcomes respectively. Here the obejctive loss we use is simply add the loss of both tasks together. I believe you’re familair with the softmax loss as it’s used in handwritten digit recognition in MNIST, and notably the localization here can be treated as a regression problem so that we can use the L2 loss.</p><h4 id="Multiple-Objects">Multiple Objects</h4><p>In the example above, we only have one object (a cat) in the image. What if we have multiple objects in the image? If we have one more object in the images, in the input we will have one more class label with four values to indicate another bounding box, here we see that the program starts to scale once we have multiple obejcts in a image.</p><p>A simple solution to multiple obejcts could be a slicing window over the entire image, which means we apply a CNN to many different crops of the image and then CNN classifies each crop as object or background. However, this is very computationally expensive! Most of the object detection application require this to be happened in the real time. So, what can be a good solution to multiple obejcts?</p><h4 id="4-step-object-detection-framwork">4-step object-detection framwork</h4><h5 id="1-Region-Proposal-indentify-regions-of-interest-RoI-for-potential-locations-of-objects">1. Region Proposal: indentify regions of interest (RoI) for potential locations of objects</h5><ul><li>General procesures for region proposal:<ul><li>Generate thousands of bouding boxes</li><li>Classify them as forground or background based on ‘objectness score’</li><li>Pass only foreground through rest of the network<br>People commonly use <strong>selective search</strong>, which is a fast algorithm, ~200 region proposals in a few seconds on CPU<br><img src="figure33.png" alt="figure3"><br>The images under this entire section are from <a href="https://www.manning.com/books/deep-learning-for-vision-systems">Elendy, 2020</a>.</li></ul></li></ul><h6 id="Selective-Search">Selective Search</h6><p>Selective search is a greedy search algorithm. The following are the steps of selective search.</p><ol><li>Segmentation. It basically defines the ‘blobs’ within the image in the segmentations step that can potentially be objects.<br><img src="figure34.png" alt="figure4"></li><li>Take these proposed regions that may contain objects as input, and the output will be as the image shown below. Those blue boxes are the regions that may contain a object, and the algorithm combines the two similiar regions into one region. So, after many iteration we’ll find we have less blue boxes now. This step will continue until the entire object is in a bounding box.<br><img src="figure35.png" alt="figure5"></li></ol><h5 id="2-Feature-Extraction-extract-visial-features-within-each-RoI-for-classification">2. Feature Extraction: extract visial features within each RoI for classification</h5><ul><li>Use a pretrained CNN network, and extract features</li><li>Make 2 predictions using additional layers:<ul><li>Bounding box prediction (x, y, width, height) <em>You may be curious why we have to make a prediction of bounding boxes here, since we’ve already identify a region of interest in the previous step. It’s important for the network to predict a bounding box, because we’re interested in having a bounding box that predicts the optimal bounding box for the obejct that we’re detecting. The region of interest may not include the entire obejct, so we don’t want to be limited by that.</em></li><li>Class prediction (softmax function predicting the class probability for each object)</li></ul></li></ul><h5 id="3-Non-maximum-Suppression-NMS-avoid-repeated-detections">3. Non-maximum Suppression (NMS): avoid repeated detections</h5><p>There is a 4-step technique for eliminating duplicate detections of objects.</p><ol><li>Discard bounding boxes with prediction below a <strong>confident threshold</strong>.</li><li>Select the bounding boxes with the highest probability</li><li>Calculate the overlap of all remaining boxes with the same class prediction</li><li>Supress any box with an IoU smaller than a threshold (NMS threshold, usually 0.5).<br><img src="figure36.png" alt="figure6"></li></ol><h5 id="4-Evaluateion-metrics-evaluate-performance-of-model">4. Evaluateion metrics: evaluate performance of model</h5><p>Once an object detector has been developed, it’s typically evaluated using two main metrics:</p><ul><li>Frames per second (FPS) - detection speed</li><li>Mean Average Precision (mAP) - network precision<ul><li>mAP calculated from a bounding box’s object score and the precision-recall curve</li></ul></li></ul><h4 id="State-of-the-Art-Object-Detection-CNNS">State of the Art Object Detection CNNS</h4><h5 id="R-CNNs-Region-based-CNNs">R-CNNs: Region-based CNNs</h5><p>R-CNN family networks:</p><ul><li>R-CNN</li><li>Fast-RCNN</li><li>Faster-RCNN (SOTA)<br><img src="figure37.png" alt="figure7"><br>R-CNN starts with a selective search to extract regions of interest (RoI) and wrapped them, then pass through a pretrain CNN to extract featrues. Once the feature extraction has been completed, classification and regression are performed to identify the class within each RoI as well as the bounding box. In order to understand this pipeline better, let’s look at R-CNN in a different angle.<br><img src="figure38.png" alt="figure8"><br>Each region that pass through selective search will be sent to CNN to extract the featuers, and then the features will be passed to two modules – classification module, which is a support vector machine (SVM) and a regression module, which is a regerssor that estimate the bounding box. This is the base level of the family of R-CNNs.</li></ul><p><img src="figure39.png" alt="figure9"><br>The image above is Fast-RCNN. The major change is where the CNN appears in the architecture. This time the input image will be directly sent into the CNN, and the region extractor happens after the CNN. This is important, because it speed up the network by only running one CNN instead of runnign ~2000 CNNs on each RoI.</p><p>CNN here performs both classification and feature extraction, and the SVM classification module is replaced with a softmax layer.</p><p><img src="figure40.png" alt="figure10"><br>The image above is Faster-RCNN, and it reaches the SOTA performance. Its overal architectural design is similiar with Fast-RCNN, with the exceptionthat a different algorithm is used for region proposal. I used the same base CNN to do the feature extraction, the main change is that they created a region proposal network (PRN), this plays the role of the selective search algorithm. So, it’s really taking out the selective search algorithm from Fast-RCNN and replace it with PRN.</p><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> Neural Network </tag>
            
            <tag> CNN </tag>
            
            <tag> Convolution </tag>
            
            <tag> Pooling </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>I received undergraduate research scholarship</title>
      <link href="/2020/12/15/I-received-Undergraduate-Research-Scholarship/"/>
      <url>/2020/12/15/I-received-Undergraduate-Research-Scholarship/</url>
      
        <content type="html"><![CDATA[<p>I got my research proposal accepted for the spring! I’ll be working on wetland mapping with deep learning techniques on high-resolution aerial imagery, and trying to accommodate spatial variability in geolocation compared with current one-size-fit-all neural networks. And I’m exicited to work with Professor <a href="https://www-users.cs.umn.edu/~shekhar/">Shashi Shekhar</a> and his PhD student <a href="https://www-users.cs.umn.edu/~gupta423/index.html">Jayant Gupta</a>. I’d like to thank the <a href="https://ugresearch.umn.edu/opportunities/urop">Undergraduate Research Opportunities Program</a> for providing this oppotunity.</p><p>As one of the largest ecosystems, wetlands have important value to the earth environment and human society. However, much value of wetlands has been reduced due to the degradation and loss of wetlands. Minnesota has lost about half of its original wetlands since 1850. Although historically wetlands were drained to support agricultural production and reduced for mining and road construction, in recent decades people have come to appreciate the many benefits they provide including flood reduction and water quality improvement. In order to provide information for the protection and restoration of wetlands, there is a need to update wetland inventory frequently with accurate boundary and improved delineation of smaller wetlands. As the Department of Natural Resources (DNR) claimed, the original National Wetland Inventory (NWI) was completed for Minnesota in the mid-1980s, and the recent statewide update took 9 years to complete (2010-2019), which is costly. So, we try to come up with a more efficient and economical way for future wetland mapping.<br><img src="figure1.png" alt="Scholarship"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Scholarship </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Basic Clusters Analysis</title>
      <link href="/2020/11/08/Basic-Clusters-Analysis/"/>
      <url>/2020/11/08/Basic-Clusters-Analysis/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><p>Cluter Analyusis is to find groups of objects such that the objects in a group will be similiar to one another and different from the objects in other groups. It’s often used to understanding data sets by grouping related data together, or reduce the size of large data sets. Note that simple segmentation such as sorting by last name, results of a query and supervised classification are not cluster analysis.</p><p>A clustering is a set of clusters. In general, there are two types of clusterings – Partitional Clustering and Hierarchical Clustering as following shown:<br><img src="figure1.png" alt="figure1"><br><img src="figure2.png" alt="figure2"><br>Not only this, there are also other distrinction between sets of clusters.</p><ul><li>Exclusive vs Non-exclusive<br>In non-exclusive clusterings, points may belong to multiple clusters.</li><li>Fuzzy vs Non-fuzzy<br>In fuzzy clustring, a point belongs to every cluster with some weight between 0 and 1; weight must sum to 1.</li><li>Partial vs Complete<br>In some cases, we only want cluster some of the data.</li><li>Heterogeneous vs Homogeneous<br>Cluters of widely different sizes, shapes, and densities.</li></ul><h2 id="Type-of-clusters">Type of clusters</h2><ul><li>Well-separated Clusters: a cluster is a set of points such that any point in a cluster is closer (or more similiar) to every other point in the cluster than to any point not in the cluster.</li><li>Center-based Clusters: A cluster is a set of objects such that an object in a cluster is closer to the “center” of a cluster, than to the center of any other cluster. Often, the center of a cluster is a <strong>centroid</strong>, the average of all the points in the cluster, or a <strong>medoid</strong>, the most “representative” point of a cluster.</li><li>Contiguous Clusters (Nearest neighbor or Transitive): a cluster is a set of points such that a point in a cluster is closer (or more similiar) to one or more other points in the cluster than to any point not in the cluster.<br><img src="figure4.png" alt="figure4"></li><li>Density-based Clusters: a cluster is a dense region of points, which is separated by low-density regions, from other regions of high density. It’s used when the clusters are irregular or intertwined, and when noise and outliers are present.<br><img src="figure5.png" alt="figure5"></li></ul><h2 id="Clustering-Algorithms">Clustering Algorithms</h2><h3 id="K-means-and-its-variant">K-means and its variant</h3><p><img src="figure6.png" alt="figure6"><br>The idea of K-means is not difficult to understand. First, we pick randomly K points as initial center and assign all points to their closest center respectively. Then recompute the center of each cluster since we have more than a single initial point in a cluster now.  We repeat this process until the centers don’t change. K-means is a partitional clustering approach, and intially K must be specified.</p><p>Furthermore, the initial centroids are oftren chosen randomly and if you choose a different intial centroid, you might end up with a different set of clusters. The centroid is (typically) the mean of the points in the cluster. How close each data point to a centroid can be measured by Euclidean distance, cosine similarity, correlation, etc. K-means will converge for common similarity measures mentioned above. Most of the convergence happens in the first few iterations, and often the stopping condition is changed to “Util relatively few points change clusters” rather than “no change…” Note that the complexity of K-means is <img src="https://math.now.sh?inline=O%28n*K*I*d%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> where <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of points, <img src="https://math.now.sh?inline=K" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of clusters, <img src="https://math.now.sh?inline=I" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of iterations, and <img src="https://math.now.sh?inline=d" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of attributes.</p><h4 id="How-to-evaluate-K-means-Cluster">How to evaluate K-means Cluster?</h4><p>The most common measure is Sum of Squared Error (SSE), which is summing up the error - the distance to the neareast cluster at each point.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=SSE%3D%5Csum_%7Bi%3D1%7D%5EK%5Csum_%7BX%5Cin%20C_i%7Ddist%5E2%28m_i%2Cx%29%0A" /></p><p>where <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is a data point in cluster <img src="https://math.now.sh?inline=C_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=m_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is a representative point for cluster <img src="https://math.now.sh?inline=C_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (can show that <img src="https://math.now.sh?inline=m_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> corresponds to the center (mean) of the cluster). If we’re given two sets of clusters, we prefer the one with the smallest error. Note that a way to reduce SSE is to increase K, the number of cluster, but a good clustering with smaller K can have a lower SSE than a poor clustering with higher K.</p><h4 id="How-to-optimize-K-means-Cluster">How to optimize K-means Cluster?</h4><p>The choice of initial points are important. If there are K ‘real’ clusters then the chance of selecting one centroid from each cluster is relatively small. If the clusters are the same size with ‘real’ clusters, then</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=P%3D%5Cfrac%7B%5Ctext%7Bnumber%20of%20ways%20to%20select%20one%20centroid%20from%20each%20cluster%7D%7D%7B%5Ctext%7Bnumber%20of%20ways%20to%20select%20K%20centroids%7D%7D%3D%20%5Cfrac%7BK!n%5EK%7D%7B%28Kn%29%5EK%7D%3D%5Cfrac%7BK!%7D%7BK%5EK%7D%0A" /></p><p>For example, if <img src="https://math.now.sh?inline=K%3D10" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, the probability is around <img src="https://math.now.sh?inline=%5Cfrac%7B10!%7D%7B10%5E%7B10%7D%7D%3D0.00036" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Sometimes the initial centroids will readjust themselves in ‘right’ way but sometimes they don’t. Let’s take a look at some bad clutering examples with K-means:<br><img src="figure7.png" alt="figure7"><br>The 1st, 3rd, 4th colomn have two clusters (black plus sign) with two ‘real’ clusters, so they perform normally. However, the 2nd colomn has only one cluster and the 5th colomn has three clusters when they both have two ‘real’ clusters. From iteration 1-4, we can see that it stops at a akward position and doesn’t correctly classify. So what do people normally do to solve initial centroids probloms?</p><ul><li>Multiple runs: helps, but probability is not in your side, so not helpful in the scenario above.</li><li>Sample and use hierarchical clustering to determine initial centroids.</li><li>Use some strategy to select the k initial centroids and then select among these initial centroids.<br>Example: select most widely separated</li><li>Bisecting K-means: Not as susceptible to initilization issues.</li></ul><p>Since this is an intro class, we didn’t go into details of above solutions.<br>Additioanlly, people also perform pre-processing and post processing to improve the performance of K-means.</p><ul><li><p>Pre-processing</p><ul><li>Normalize the data</li><li>Eliminate outliers</li></ul></li><li><p>Post-processing</p><ul><li>Eliminate empty clusters and small clusters that may represent outliers</li><li>Split ‘loose’ clusters, i.e., clusters with relatively high SSE</li><li>Merge clusters that are ‘close’ and that have relatively low SSE</li><li>These steps can be used multiple times duiring the clustering process</li></ul></li></ul><h4 id="How-to-handle-empty-cluster">How to handle empty cluster?</h4><p>Let’s see an example that empty cluster can happen:<br><img src="figure8.png" alt="figure8"><br>Basic K-means algorithm can yield empty clusters, then how can we handle it?</p><ul><li>Choose the point that contributes most to SSE, and make it a new centroid.</li><li>Choose a point from the cluster with the highest SSE, and make it a new centroid.</li><li>If there are several empty clusters, the above can be repeated several times.</li></ul><h4 id="How-to-update-centers-incrementally">How to update centers incrementally?</h4><p>In the basic K-means algorithm, centroids are updated after all points are assigned to a centroid. An alternative way is to update the centroid after each assignment (incremental approach), then each assignment updates zero or two centroids. It’s more expensive, and introduces an order dependency, but it never get an empty cluster.</p><h4 id="Limitations-of-K-means">Limitations of K-means</h4><p>K means has problems when clusters are of differing sizes, densities or non-globular shapes. Also, K-means has problems when the data contains outliers.</p><ul><li>Differing sizes<br><img src="figure9.png" alt="figure9"><br>One solution is to use many clusters, but eventually need to put some clusters together to match ground truth.<br><img src="figure12.png" alt="figure12"></li><li>Differing densities<br><img src="figure10.png" alt="figure10"><br>Again, increasing number of clusters can solve this situation.<br><img src="figure13.png" alt="figure13"></li><li>Non-globular shapes<br><img src="figure11.png" alt="figure11"><br>Same solution: use more clusters<br><img src="figure14.png" alt="figure14"></li></ul><h3 id="Hierarchical-Clustering">Hierarchical Clustering</h3><p>It produces a set of nested clusters organized as a hierarchical tree, and it can be visualized as a dendrogram, which is a tree like diagram below that records the sequences of merges or splits.<br><img src="figure15.png" alt="figure15"><br>The stengths of Hierarchical Clustering is that we do not have to assume any particular number of clusters because any desired number of clusters can be obtained by ‘cutting’ the dendrogram at the proper level. Also, those clusters gained may correspond to meaningful taxnomies such as animal kingdom, phylogeny reconstruction in biological sciences.<br>It’s not difficult to image there are two mian types of hierarchical clustering. The first one is agglomerative, which is starting with the points as individual clusters, then at each step merge the closest pair of cluster until only one cluster (or k clusters) left. The second one is divisive, which starts with an all-inclusive cluster, then at each step split a cluster until each cluster contains an individual point (or there are k clusters). The basic algorithm is straightforward as below:<br><img src="figure16.png" alt="figure16"></p><h4 id="How-to-define-Inter-Cluster-Similarity">How to define Inter-Cluster Similarity?</h4><p>There are in general 4 ways to do it, which are MIN, MAX, Group Average Distance Between Centroids and other methods driven by an objective function.</p><h5 id="MIN">MIN</h5><p>The proximity of two Cluster is based on the two closest points in the different clusters. It’s determined by one pair of points, i.e., by one link in the proximity graph.<br><img src="figure17.png" alt="figure17"><br>The stength of MIN is that it can handle non-elliptical shapes.<br><img src="figure18.png" alt="figure18"><br>The limitation of MIN is that it’s sensetive to noise and outliers.<br><img src="figure19.png" alt="figure18"></p><h5 id="MAX">MAX</h5><p>The proximity of two clusters is based on the two most distant points in the different clusters.<br><img src="figure20.png" alt="figuer20"><br>The stength of MAX is that it’s less susceptible to noise and ouliers. The limitation of MAX is that it tends to break large clusters and biased towards globular clusters as following:<br><img src="figure21.png" alt="figure21"><br>If you’re looking for a globular clusters, MAX is a good choice; but if you’re looking at arbitrary shape clusters, mean is a better choice.</p><h5 id="Group-Average">Group Average</h5><p>The proximity of two clusters is the average of pairwise proximity between points in the two clusters.<br><img src="figure22.png" alt="figure22"><br>The stength of Group Average is that it’s also less susceptible to noise and outliers, while its limitation is that is biased towards glubular clusters. Group Average is more robust than single link like MIN and MAX.</p><h5 id="Ward’s-Method">Ward’s Method</h5><p>Similarity of two clusters is based on the increase in squared error when two clusters are merged. This is similiar to Group Average if distance between points is distance squared. Its strength is that it’s less susceptible to noise and outliers and its limitation is that it biased towards globular clusters. One of its applciation is to initialize K-means in Hierarchical analogue of K-means.</p><h4 id="Summary-of-Hierarchical-Clustering">Summary of Hierarchical Clustering</h4><p>Time and Space Requirements</p><ul><li><img src="https://math.now.sh?inline=O%28N%5E2%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> space since it uses the proximity matrix. <img src="https://math.now.sh?inline=N" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of points.</li><li><img src="https://math.now.sh?inline=O%28N%5E3%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> time in many cases. There are <img src="https://math.now.sh?inline=N" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> steps and at each step the size, <img src="https://math.now.sh?inline=N%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, proximity matrix must be updated and searched. The Complexity can be reduce to <img src="https://math.now.sh?inline=O%28Nlog(N%29)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> time with some cleverness.</li></ul><p>Problems and Limitations:</p><ul><li>Once a decision is made to combine two clusters, it cannot be undone.</li><li>No global objective function is directly minimized.</li><li>Different schemes have problems with one or more of the following:<ul><li>Sensitive to noise and outliers</li><li>Difficulty handing clusters of diferent sizes and non-globular shapes</li><li>Breaking large clusters</li></ul></li></ul><h3 id="Density-Based-Clustering-DBSCAN">Density Based Clustering (DBSCAN)</h3><p>Clusters are regions of high density that are separated from one another by regions on low density.</p><p>DBSCAN is a density-based algorithm. We define density as number of points within a specified radius (Eps). If a point has at least a specified number of points (MinPts) within Eps, then it’s a <strong>core point</strong>. If a point is not a core point but is in the neighborhood of a core point, then it’s a <strong>border point</strong>. If a point is neither a core point or a border point, then it’s a noise point.</p><p>There is a verbal DBSCAN algorithm:</p><ol><li>Label all points as core, border, or noise points.</li><li>Eliminate noise points.</li><li>Put an edge between all core points within a distance Eps of each other.</li><li>Make each group of connected core points into a separate cluster.</li><li>Assign each border point to one of the clusters of its associated core points.</li></ol><p>DBSCAN works well since it’s resistant to noise and can handle clusters of different shapes and sizes as the image following:<br><img src="figure23.png" alt="figure23"><br>DBSCAN doesn’t work well if the situation is as following:<br><img src="figure24.png" alt="fiture24"></p><h4 id="How-to-determine-Eps-and-MinPts">How to determine Eps and MinPts?</h4><p><img src="figure25.png" alt="figure25"><br>The idea is to plot a graph of sorted distance of every point to its kth nearest neighbors. In the graph above, we can see that Eps=10 might be a good choice, because that’s where the “elbow” happens. For instance, as in the graph, ask the question of how far is your 4th neighbor for each point among 3000 points, and plot a graph</p><h2 id="Cluster-Validity">Cluster Validity</h2><p>How to evaluate the “goodness” of the resulting clusters? “Clusters are in the eye of beholder”, then why do we want to evaluate them while we can tell just by looking at them?</p><ul><li>To avoid finding patterns in noise</li><li>To compare clustering algorithms</li><li>To compare two sets of clusters</li><li>To compare two clusters</li></ul><h3 id="Different-aspects-of-cluster-validation">Different aspects of cluster validation</h3><ol><li>Determing the clustering tendency of a set of data, i.e., distinguishing whether non-random structure actually exists in the data.</li><li>Comparing the results of a cluster analysis to externally knonw results, e.g., to externally given class labels.</li><li>Ecaluating how well the results of a cluster analysis fit the data without reference to external information, i.e., use only the data.</li><li>Comparing the results of two different sets of clusters (generated for the same data) to determine which is better.</li></ol><h3 id="Measure-cluster-validity-via-correlation">Measure cluster validity via correlation</h3><p>Suppose we have two matrices. One is proximity matrix and another is ideal similarity matrix, where one row and one colomn for each data point, and an entry is 1 if the associated pair of points belong to the same cluster; otherwise, an entry is 0. Now we need to compute the correlation between the two matrices. Since the matrices are symmetric, only the correlation between <img src="https://math.now.sh?inline=%5Cfrac%7Bn%28n-1%29%7D%7B2%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> entries needs to be calculated. High magnitude of correlation indicates that points that belong to the same cluster are close to each other.</p><p>There is a example as following:<br><img src="figure26.png" alt="figure26"><br>The left one is much more clustered than the right one, so the Correlation of the left one is close to -1.</p><h3 id="Use-similarity-matrix-for-cluster-validation">Use similarity matrix for cluster validation</h3><p>First, let’s look at the similarity matrix of a good clustering example:<br><img src="figure27.png" alt="figure27"></p><p>Second, let’s look at how three clusters behave differently on random data that are not so crisp.<br><img src="figure28.png" alt="figure28"><br><img src="figure29.png" alt="figure29"><br><img src="figure30.png" alt="figure30"><br>Intuitively, from the three images above we can see that they’re not performing well and K-means performs slightly better than the other two. Now let’s look at a visual proof of DBSCAN working well at density cluster with arbitrary shapes.<br><img src="figure31.png" alt="figure31"></p><h3 id="Internal-Measures-SSE-Sum-of-Square-Error">Internal Measures: SSE (Sum of Square Error)</h3><p>Internal Index is used to measure the goodness of a clustering structure without respects to external information. SSE is good for comparing two clusterings or two clusters, and it can be used to estimate the number of clusters. For instance, as the images below, we know that the groud truth of clusters shall be 10. On the curve, after K &gt; 10, the graph becomes very flat, which implies that K=10 is a good choice for the number of clusters because the ‘elbow’ happens here.<br><img src="figure32.png" alt="figure32"></p><h3 id="Stastical-Framework-of-Cluster-Validity">Stastical Framework of Cluster Validity</h3><p><img src="figure33.png" alt="figure33"><br>Let’s look at the image above. We assume that we know the SSE on the left-hand side of the image is 0.005, then on the right-hand side of the image is a plot of a random distribution, which has a SSE around 0.022, so we know any clusterings that has a SSE lower than 0.022 is better, because 0.022 is the SSE of random data points.</p><hr><p>I will make some GIF to visually illustrate clusterings during the winter break.</p><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> K-means </tag>
            
            <tag> Hierarchical Clustering </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>I got admitted to B.S./M.S. Integrated Program</title>
      <link href="/2020/11/06/I-got-admitted-to-B-S-M-S-Integrated-Program/"/>
      <url>/2020/11/06/I-got-admitted-to-B-S-M-S-Integrated-Program/</url>
      
        <content type="html"><![CDATA[<p>I’m happy to announce that I got admitted to Computer Science <a href="https://cse.umn.edu/cs/integrated">B.S./M.S. Integrated Program</a> in my junior year at the University of Minnesota. I’m planning on option A which is thesis option, and I’m exicted to take advanced and research-oritented computer science courses. Despite the fact that it’s typically a 4+1 program, I will still be graduating in the Spring of 2022 (3+1).<br><img src="figure1.png" alt="offer"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Education </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Association Rules: Advanced Concept</title>
      <link href="/2020/11/01/Association-Rules-Advanced-Concept/"/>
      <url>/2020/11/01/Association-Rules-Advanced-Concept/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><h1>Data Mining: Advance Concepts of Association Analysis</h1><h2 id="Sequential-Patterns">Sequential Patterns</h2><p>Example of sequence:</p><ul><li>Sequence of different transaction by a customer at an online store<br>&lt;{Digital Camera, iPad} {Memory card} {headphone, iPad cover}&gt;</li><li>Sequence of book checked out at a library:<br>&lt;{Fellowship of the Ring} {The Two Towers} {Return of the King}&gt;</li><li>more on the table below<br><img src="figure1.png" alt="figure1"></li></ul><p>How does the sequence data look like in database?<br><img src="figure2.png" alt="figure2"></p><p>What does sequence data differ from market-basket data?<br><img src="figure3.png" alt="figure3"><br>From Sequence data, we can tell people who bought item {2} would be likely to buy item {1} afterward on the next purchase. And Market-basket data tells us that people who bought item {1,8} would be likely to buy item {7} on the same purchase.</p><h3 id="Formal-def-of-sequence">Formal def of sequence</h3><p>A sequence is an ordered list of elements <img src="https://math.now.sh?inline=s%20%3D%20%3Ce_1%20e_2%20e_3%20%5Cdots%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, when each element contains a collection of events(items) <img src="https://math.now.sh?inline=e_i%20%3D%20%5Clbrace%20i_1%2C%20i_2%2C%20%5Cdots%2C%20i_k%20%5Crbrace" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Length of a sequence <img src="https://math.now.sh?inline=%7Cs%7C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is given by the number of elements in the sequence. A k-sequence is a sequence that contains k events (items).</p><h3 id="Visual-def-of-subsequence">Visual def of subsequence</h3><p><img src="figure4.png" alt="figure4"><br>A subsequence is contained in another data sequence if each element of subsuence is a subset of a corresponding element of the data sequence. For the second row of the table, element {1} of subsuquence is a subset of element {1,2} of data sequence. Since {2} is a element in subsequence but it doesn’t have a corresponding element in data sequence, it’s not contained. Note that the order in subsequence doesn’t matter.</p><h3 id="Sequential-Pattern-Mining">Sequential Pattern Mining</h3><p>Now let’s talk about support again. The support of a subsequence <img src="https://math.now.sh?inline=w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is defined as the fraction of data sequences that contain <img src="https://math.now.sh?inline=w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. A sequential pattern is a frequent subsequence (i.e., a subsequence where <img src="https://math.now.sh?inline=support%20%5Cgeq%20minsup" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>). Suppose we’re given a database of sequences and a user-specified minimum support threshold (i.e., minsup), the task is to find all subsuquences with support greater than or equal to minsup. There is an example of frequent subsequences:<br><img src="figure5.png" alt="figure5"><br>Here are only examples but not all the frequent subsequences. For instance, if we look at subsuquence &lt;{1,2}&gt;, since it’s a subset of sequence A B C out of A B C D E, the support of it is 60% which is higher than our specified minsup, so it’s a frequent subsequence.</p><p>After talking about support, let’s talk about confidence. The calculation of confidence here is different from normal transaction database (market-basket data).<br><img src="figure6.png" alt="figure6"></p><p>How can we extract sequential patterns?</p><ul><li>Given <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> events: <img src="https://math.now.sh?inline=i_1%2C%20i_2%2C%20%5Cdots%2C%20i_n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate 1-subsequences:<br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%2C%20%3C%5C%7Bi_n%5C%7D%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate 2-subsequences:<br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_3%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%20%3C%5C%7Bi_n%5C%7D%2C%5C%7Bi_n%5C%7D%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate 3-subquences:<br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%2C%20i_3%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_2%2C%20i_4%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%20%3C%5C%7Bi_n%5C%7D%2C%5C%7Bi_n%5C%7D%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p>A 2 events example:<br><img src="figure7.png" alt="figure7"><br>As you can see, the idea seems to be computational expensive here if we have many events. So we introduce a method called Generalized Sequential Pattern (GSP) to deal with it.</p><ol><li>Make the first pass over the sequence database D to yield all the 1-element frequent sequences</li><li>Repeat until no new frequent sequences are found<ul><li>Candidate Generation: Merge pairs of frequent subsequences found in the (k-1)th pass to generate candidate sequences that contain k items</li><li>Candidate Pruning: Prune candidate k-sequences that contain infrequent (k-1)-subsequences</li><li>Support Counting: Make a new pass over the sequence database D to find the support for these candidate sequences</li><li>Candidate Elimination: Eliminate candidate k-sequences whose actual support is less than minsup</li></ul></li></ol><p>What does “merge” mean above? Some example below:<br><img src="figure8.png" alt="figure8"><br>A visual walk-through of candidate generation:<br><img src="figure8.png" alt="figure9"><br><img src="figure10.png" alt="figure10"><br>No matter which item I cross out in &lt;{1} {2 5} {3}&gt;, I can always find it in the frequent 3-sequences. For instance, if I cross out {1}, check if &lt;{2 5} {3}&gt; is in the frequent 3-sequences. If I cross out {2}, check if &lt;{1} {5} {3}&gt; is in the frequent 3-sequences. If I cross out {3}, check if &lt;{1} {2 5}&gt; is in the frequent 3-sequences. Do it for all cadidate generation and you will find only &lt;{1} {2 5} {3}&gt; survives, the others have been pruned.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Sequential Rules Mining </tag>
            
            <tag> Association Rule </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Basic Methods of Training Deep Neural Networks (DNNs)</title>
      <link href="/2020/10/27/Basic-Methods-of-Training-Deep-Neural-Networks-DNNs/"/>
      <url>/2020/10/27/Basic-Methods-of-Training-Deep-Neural-Networks-DNNs/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><h1>Training DNNs: Basic Methods and Tricks</h1><h2 id="Three-Design-Choices">Three Design Choices</h2><p><img src="figure1.png" alt="figure1"></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=min_W%5Csum_i%20%5Cmathbb%20%5Cell%28y_i%2C%20DNN_W(x_i%29)%20%2B%20%5COmega(W)%0A" /></p><ul><li>Which activation at the hidden nodes?</li><li>Which activation at the output node (Identity function is ok)?</li><li>Which <img src="https://math.now.sh?inline=%5Cell" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>?</li></ul><h3 id="Which-activation-at-the-hidden-nodes">Which activation at the hidden nodes?</h3><p><img src="figure2.png" alt="figure2"><br>Is the sign(<img src="https://math.now.sh?inline=%5Ccdot" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) activation good for derivative-based optimization?<br>No, for following two reasons:</p><ul><li>derivative of sign activation in anywhere is 0<p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cnabla_w%5Cell%28sign(w%5ETx%29%2Cy)%3D%5Cell'(sign(w%5ETx)%2Cy)sign'(w%5ETx)x%3D0%0A" /></p></li><li>not differentiable at origin</li></ul><p>But why the classic Perceptron algorithm converges?<br>Because perceptron algorithm is not a gradiaent descent algorithm.</p><p>What we want for activation:</p><ul><li>Differentiable or almost everywhere differentiabkle</li><li>Nonzero derivatives (almost everywhere)</li><li>Cheap to compute</li></ul><p>A positive example:<br><img src="figure3.png" alt="figure3"></p><p>What about <img src="https://math.now.sh?inline=tanh%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>?<br><img src="figure4.png" alt="figure4"></p><ul><li>It’s differentiable.</li><li>The gradient is similiar to sigmoid.</li></ul><p>How about ReLU and ReLU’s variation?<br><img src="figure5.png" alt="figure5"><br><img src="figure6.png" alt="figure6"></p><ul><li>ReLU and Leaky ReLU are the most popular</li><li><img src="https://math.now.sh?inline=tanh" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> less preferred but okay; hypertan and sigmoid should be avoided<br>What do you think of <img src="https://math.now.sh?inline=%7C%5Ccdot%7C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> as activation, i.e, absulute value function? Acceptable.</li></ul><h3 id="Which-activation-at-the-output-nodes">Which activation at the output nodes?</h3><p>Depending on the desired output:</p><ul><li>unbounded scalar/vector output (e.g., regression): <strong>identity activation</strong></li><li>binary classification with 0 or 1 output: e.g., sigmoid <img src="https://math.now.sh?inline=%5Csigma%28x%29%3D%5Cfrac%7B1%7D%7B1%2Be%5E%7B-x%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>multiclass classification: labels into vectors via <strong>one-hot encoding</strong></li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=L_k%20%5Cimplies%20%5B%5Cunderbrace%7B0%2C%5Cdots%2C0%7D_%7Bk-1%5Cquad%200's%7D%2C1%2C%5Cunderbrace%7B0%2C%5Cdots%2C0%7D_%7Bn-k%5Cquad0's%7D%5D%5ET%0A" /></p><p>Softmax activation:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=z%20%5Cmapsto%20%5Clbrack%20%5Cfrac%7Be%5Ez1%7D%7B%5Csum_je%5Ezj%7D%2C%5Ccdots%2C%5Cfrac%7Be%5Ezp%7D%7B%5Csum_je%5Ezj%7D%20%5Crbrack%5ET%0A" /></p><h3 id="Which-loss">Which loss?</h3><p><img src="figure7.png" alt="figure7"><br>In multiclass classification label smoothing section and in one-hot encoding, we normally get the a vector with <img src="https://math.now.sh?inline=1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and all other entries <img src="https://math.now.sh?inline=0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, but if we want to further turn our parameters, <img src="https://math.now.sh?inline=0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is not likely to be helpful. So, we will use a small <img src="https://math.now.sh?inline=%5Cmathcal%7BE%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> instead of <img src="https://math.now.sh?inline=0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> so that information can be used later.</p><h2 id="Training-Algorithms">Training Algorithms</h2><p>Recall our optimization problem:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=min_W%5Csum_i%20%5Cmathbb%20%5Cell%28y_i%2C%20DNN_W(x_i%29)%20%2B%20%5COmega(W)%0A" /></p><p>What happens when <img src="https://math.now.sh?inline=m" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is large, i.e., in the “big data” regime?<br><img src="figure8.png" alt="figure8"><br>There is a intersting graph above. The GPU listed above is RTX 8000, which has 48G VRAM and around $5000 by the time of this blog. However, comparing to large dataset like MIMIC and ImageNet, it’s still really tiny little small.</p><p>How to get around the storage and computation bottleneck when <img src="https://math.now.sh?inline=m" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is large?</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Ctext%7Bstochastic%20optimization%20%28stochastic%20%3D%20random%29%7D%0A" /></p><p>Idea: use a small batch of data samples to approxiamate quantities of interest</p><ul><li>gradient: <img src="https://math.now.sh?inline=%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Em%5Cnabla%5E2_W%5Cell%28y_i%2CDNN_W(x_i%29)%20%5Crightarrow%20%5Cmathbb%20E_%7Bx%2Cy%7D%5Cnabla_W%5Cell(y%2CDNN_W(x))" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>approximated by stochastic gradient:</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7B1%7D%7B%7CJ%7C%7D%5Csum_%7Bj%20%5Cin%20J%7D%20%5Cnabla_W%5Cell%28y_i%EF%BC%8CDNN_w(x_j%29)%0A" /></p><p>for a random subset <img src="https://math.now.sh?inline=J%20%5Csubset%20%5C%7B1%2C%5Cdots%2Cm%20%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, where <img src="https://math.now.sh?inline=%7CJ%7C%20%5Cll%20m" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><h3 id="Stochastic-Gradient-Descent-SGD">Stochastic Gradient Descent (SGD)</h3><p>In general, suppose we want to solve</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=min_wF%28w%29%5Cdoteq%20%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D1%7D%5Emf(m%3B%5Cxi_i)%20%5Cquad%20%5Cxi_i%20%5Ctext%7B's%20are%20data%20samples%7D%0A" /></p><p>Idea: replace gradient with a stochastic gradient in each step of GD<br><img src="figure12.png" alt="figure12"><br><img src="https://math.now.sh?inline=J_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is a redrawn in each iteration. In traiditional SGD <img src="https://math.now.sh?inline=%7CJ_k%7C%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and the version presented is also called <strong>mini-batch gradient descent</strong>.</p><h4 id="What’s-an-epoch">What’s an epoch?</h4><ul><li>Canonical SGD: sample a random subset <img src="https://math.now.sh?inline=J_k%20%5Csubset%20%5C%7B1%2C%5Cdots%2Cm%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> each iteration–sampling with replacement.</li><li>Practical SGD: shuffle the trainng set, and take a conscutive batch of size B (called batch size) each iteration–sampling without replacement one pass of the shuffled training set is called on epoch<br><img src="figure9.png" alt="figure9"></li></ul><h3 id="GD-vs-SGD">GD vs SGD</h3><p>Consider <img src="https://math.now.sh?inline=min_w%20%5C%7Cy-Xw%5C%7C_2%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, where <img src="https://math.now.sh?inline=X%5Cin%20%5Cmathbb%20R%5E%7B10000%5Ctimes500%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=y%5Cin%20R%5E%7B10000%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=w%5Cin%20R%5E%7B500%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="figure10.png" alt="figure10"><br>Having observed that SGD converges to the same value as GD, but why it seems like left graph SGD is slower than GD? That’s just a illusion, we should look at the right graph, because the right graph is about each epoch. For SGD, going through the entire dateset is going through one epoch.</p><ul><li>By iteration: GD is faster</li><li>By iter(GD)/Epoch(SGD): SGD is faster</li><li>Remember, cost of one epoch of SGD <img src="https://math.now.sh?inline=%5Capprox" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> cost of one iteration of GD!</li></ul><p>Overall, SGD could be quicker to find a medium-accuracy solution with lower cost, which suffices for most purposes in machine. More on the reference below:<br><img src="figure13.png" alt="figure13"></p><h3 id="Step-Size-Learning-Rate-LR-for-SGD">Step Size (Learning Rate (LR)) for SGD</h3><p>Classical theory for SGD on convex problems requires</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Csum_%7Bk%7Dt_k%3D%5Cinfty%2C%20%5Cquad%20%5Csum_%7Bk%7Dt_k%5E2%3C%5Cinfty%0A" /></p><p>Practical implementation: diminishing <img src="https://math.now.sh?inline=%5Cfrac%7Bstep%20size%7D%7BLR%20%5Ctext%7B%28learning%20rate%29%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, e.g.:</p><ul><li><img src="https://math.now.sh?inline=%5Cfrac%7B1%7D%7Bt%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> delay: <img src="https://math.now.sh?inline=t_k%3D%5Cfrac%7B%5Calpha%7D%7B1%2B%5Cbeta%20k%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=%5Calpha%2C%5Cbeta" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: tunable parameters, <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: iteration index</li><li>exponential delay: <img src="https://math.now.sh?inline=t_k%20%3D%20%5Calpha%20e%5E%7B-%5Cbeta%20k%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=%5Calpha%2C%5Cbeta" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: tunable parameters, <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: iteration index</li><li>staircase delay: start from <img src="https://math.now.sh?inline=t_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, divide it by a factor (e.g., 5 or 10) every <img src="https://math.now.sh?inline=L" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (say, 10) epochs–<strong>popular in practice</strong>. Some heuristic variants:<ul><li>Watch the validation error and decrease the LR when it stagnates</li><li>Watch the objective and descrease of LR when it stagnates</li></ul></li></ul><p>There are around 10 ways of choosing the step size (learning rate) in Pytorch, and Pytorch call them scheduler. Check it out <a href="https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate">torch.optim.lr_scheduler</a></p><h3 id="Why-SGD-with-adaptive-learning-rate">Why SGD with adaptive learning rate?</h3><p>One great complain of SGD is that if the conditioning of the function is not good, i.e., if you have a coutour plot that every time you take a step the direction is almost orthogonal with last step, SGD is sturggling a lot in moving.<br><img src="figure14.png" alt="figure14"><br>Even if we can deal with it by Newton’s method, Quasi-Newton’s method and momentum methods, it’s still expensive. Here is a idea: if decompiosing your gradient direction to coordinate directions, e.g., x-direction and y-direction, if the magnitude of coordinate directions have very different values, it will have really bad effect on optimization. The solution is that if the gradient toward a certian coordinate direction is always large, I can divide the component of that direction by a large number, so that I can reduce the magnitude toward that direction. In other words, I want to amplify coordinate direction where gradient is always small, and I want to surpress cooprdinate direction where gradient is always large. How to do that?</p><h4 id="Method-1-Adagrad">Method 1: Adagrad</h4><p>Adagrad: divide <img src="https://math.now.sh?inline=g_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> by historic gradient magnitudes in the <img src="https://math.now.sh?inline=i%5E%7Bth%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> coordinate. If the historic gradient is small, then I divide <img src="https://math.now.sh?inline=g_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> by it I will get a larger value; vice versa.</p><p>At the <img src="https://math.now.sh?inline=%28k%2B1%29%5E%7Bth%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> iteration, for all <img src="https://math.now.sh?inline=i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bi%2Ck%2B1%7D%3Dx_%7Bi%2Ck%7D%20-%20t_k%20%5Cfrac%7Bg_%7Bi%2Ck%7D%7D%7B%5Csqrt%7B%5Csum_%7Bj%3D1%7D%5Ekg_%7Bi%2Cj%7D%5E2%7D%2B%5Cepsilon%7D%0A" /></p><p>or in elementwise notation</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%3Dx_%7Bk%7D%20-%20t_k%20%5Cfrac%7Bg_%7Bk%7D%7D%7B%5Csqrt%7B%5Csum_%7Bj%3D1%7D%5Ekg_%7Bj%7D%5E2%7D%2B%5Cepsilon%7D%0A" /></p><p>Write <img src="https://math.now.sh?inline=s_k%5Cdoteq%5Csum_%7Bj%3D1%7D%5Ekg_j%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Note that <img src="https://math.now.sh?inline=s_k%3Ds_%7Bk-1%7D%2Bg_k%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. So only need to incrementally update the <img src="https://math.now.sh?inline=s_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> sequence, which is cheap.</p><p>In PyTorch, check out <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adagrad">torch.optim.Adagrad</a><br>But Adagrad have a problem in the way of its accumulating, after a great number of iterations, the step will turn out to be super small. In fact, it stops doing the gradient descent, that’s also why we introduce Method 2 below.</p><h4 id="Method-2-RMSprop">Method 2: RMSprop</h4><p>The idea of RMSprop comparing to Adagrad is that we won’t accumulate all the historic gradients, but only using recent historic gradient. It will gradually phase out the histroy.<br>For some <img src="https://math.now.sh?inline=%5Cbeta%20%5Cin%20%280%2C1%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=s_k%3D%5Cbeta%20s_%7Bk-1%7D%2B%281-%5Cbeta%29g_k%5E2%20%5CLeftrightarrow%20s_k%3D(1-%5Cbeta)(g_k%5E2%2B%5Cbeta%20g_%7Bk-1%7D%5E2%2B%5Cbeta%5E2%20g_%7Bk-2%7D%5E2%20%2B%20%5Cdots)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>Obvisouly, even though we’re summing up all historic gradient magnitude squares coordinatewise, but due to the value of <img src="https://math.now.sh?inline=%5Cbeta" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is between 0 and 1, the previsou history will become less and less important to the current gradient.</p><h4 id="Method-3-Adam">Method 3: Adam</h4><p>Two most popular SGD methods:</p><ul><li>SGD with momentum</li><li>Adam</li></ul><p>The idea of Adam is to combine RMSprop with momentum methods:</p><ul><li><img src="https://math.now.sh?inline=m_k%3D%5Cbeta_1m_%7Bk-1%7D%2B%281-%5Cbeta_1%29g_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (combine mumentum and SGD)</li><li><img src="https://math.now.sh?inline=s_k%3D%5Cbeta_2%20s_%7Bk-1%7D%2B%281-%5Cbeta_2%29g_k%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (scaling factor update as in RMSprop)</li><li>Combination: <img src="https://math.now.sh?inline=x_%7Bk%2B1%7D%20%3D%20x_k-t_k%5Cfrac%7Bm_k%7D%7B%5Csqrt%7Bs_k%2B%5Cepsilon%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p>Good to know:<br>Typical parameters: <img src="https://math.now.sh?inline=%5Cbeta_1%3D0.9%2C%20%5Cbeta_2%3D0.999%2C%20%5Cepsilon%3D1e-8" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>Check out <a href="https://pytorch.org/docs/stable/optim.html#torch.optim.Adam">torch.optim.Adam</a></p><h3 id="Diagnosis-of-LR">Diagnosis of LR</h3><p><img src="figure15.png" alt="figure15"><br>If you loss function blows up, it means you shall descress your learning rate. Low LR always leads to convergence, but takes forever. Permature flatten is a sign of large LR; permature sloping is a sign of early stopping–increase the number of epochs! Remember the starecase LR schedule.</p><p>Why adaptive methods relevant for DL?<br><img src="figure16.png" alt="figure16"><br>The gradients have really different magniture across layers, and the trend is consistent. See more discussion adn explanation in <a href="http://neuralnetworksanddeeplearning.com/chap5.html">http://neuralnetworksanddeeplearning.com/chap5.html</a></p><h3 id="Where-to-initialize-for-DNNs">Where to initialize for DNNs?</h3><p><img src="figure17.png" alt="figure17"></p><ul><li>What about <img src="https://math.now.sh?inline=W%3D0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? <img src="https://math.now.sh?inline=%5Cnabla_%7BW_1%7DF%3D0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> – no movement on <img src="https://math.now.sh?inline=W_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>What about very large (small) <img src="https://math.now.sh?inline=W" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? Large (small) value &amp; gradient – the problem becomes significant when ther are more layers.</li></ul><p>There are some principled ways of initialization</p><ol><li>torch.nn.init.xavier_uniform_</li><li>torch.nn.init.kaiming_uniform_</li><li>torch.nn.init.orthogonal_</li></ol><h3 id="When-to-stop">When to stop?</h3><p>Recall that a natrual stopping criterion for general GD is <img src="https://math.now.sh?inline=%5C%7C%5Cnabla%20f%28w%29%5C%7C%20%5Cleq%20%5Cepsilon" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for a small <img src="https://math.now.sh?inline=%5Cepsilon" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Is this good when training DNNs?<br>No, the gradient in DNNs is always SGD, so it doesn’t make sense to use norm of gradient or Hessian as a stopping value. Also, computing <img src="https://math.now.sh?inline=%5Cnabla%20f%28w%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> each iteration is expensive.</p><p>A practical\pragmatic stopping strategy for classification: early stopping<br><img src="figure18.png" alt="figure18"><br>periodically check the validation error and stop when it doesn’t improve, because people believe that after this point it starts to be overfitting</p><!-- ### Why scaling matters?Consider the loss function we've discussed and their Gradient/Hessian:- Least-squares (LS): $\min_{\mb w} \; \frac{1}{m}\sum_{i=1}^m \norm{ y_i - \mb w^\T \mb x_i}{2}^2$- Logistic regression: $\min_{\mb w}\; -\frac{1}{m}\sum_{i=1}^m \brac{y_i \mb w^\T \mb x_i - \log \paren{1+e^{\mb w^\T \mb x_i}}}$- Shallow NN prediction: $\min_{\mb w} \; \frac{1}{m}\sum_{i=1}^m \norm{y_i - \sigma\paren{\mb w^\T \mb x_i}}_{2}^2$Gradient: $\nabla_{\mb w} f = \frac{1}{m}\sum_{i=1}^m \ell'\paren{\mb w^\T \mb x_i; y_i}\mb x_i$Hessian: $\nabla^2_{\mb w} f = \frac{1}{m}\sum_{i=1}^m \ell''\paren{\mb w^\T \mb x_i; y_i}\mb x_i \mb x_i^\T$Consider the linear model $\mb W^T\mb x_{i} \leftrightarrow \mb y_{i}$ with coordinate $\mb x_{i}$. If you multiply $x_{i}$ by a scale value, it is equivalent to multipling $\mb W^T$ by the value one over the scale value. Hence, we can linearly scale $x_{i}$ without effects on model capacity. However, if we have very different values on coordinates, their weighted sum of derivative tend to have very large values, which is bad for optimization. Therefore, we should minimize this effect from data itself instead of relying on optimization algorithms. The Hessian also has this problem. Because Hessian depends on $\mathbb{E}({x_{i}x_{i}^T})$,  distribution of curvature along different coordinate direction will be very different with very large/small $x_{i}$. --><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Neural Network </tag>
            
            <tag> Stochastic Gradient Descent </tag>
            
            <tag> Adagrad </tag>
            
            <tag> RMSprop </tag>
            
            <tag> Adam </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Numerical Optimization: Computing Derivatives</title>
      <link href="/2020/10/25/Numerical-Optimization-Computing-Derivatives/"/>
      <url>/2020/10/25/Numerical-Optimization-Computing-Derivatives/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><h1>Numerical Optimization: Computing Derivatives</h1><p>No matter which iterative methods you choose to use in order to do numerical optimization, you almost have to entail low-order derivatives (i.e., gradient and/or Hessian) to proceed. In other words, <strong>numerical derivatives</strong> (i.e., numbers) needed for the iterations.</p><p>In genreal, there are four kinds of computing techniques:<br><img src="figure1.png" alt="figure1"><br>The main topic of this blog is about Auto Differentiation.</p><h2 id="Analytic-Derivatives">Analytic Derivatives</h2><p>The idea is to derive the analytic derivatives first, then make numerical substitution.</p><p>To derive the analytic derivatives by hand, we usually apply the chain rule (vector version) method.<br>Let <img src="https://math.now.sh?inline=f%3A%5Cmathbb%20R%5Em%20%5Crightarrow%20%5Cmathbb%20R%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=h%3A%20%5Cmathbb%20R%5En%20%5Crightarrow%20%5Cmathbb%20R%5Ek" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=z%3Dh%28y%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=y%3Df%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Then <img src="https://math.now.sh?inline=z%3Dh%20%5Ccirc%20f%28x%29%3A%20%5Cmathbb%20R%5En%20%5Crightarrow%20%5Cmathbb%20R%5Ek" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=J_%7B%5Bh%20%5Ccirc%20f%5D%7D%28x%29%3DJ_h(f(x))J_f(x)%2C%20or%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20x%7D%20%3D%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20y%7D%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20x%7D%0A" /></p><p>when <img src="https://math.now.sh?inline=k%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cnabla%20%5Bh%5Ccirc%20f%5D%28x%29%3DJ_f%5ET(x)%5Cnabla%20h(f(x))%0A" /></p><p>And another method we usually use is Taylor expansion method, it’s a bit uncommon but it’s convinient for certain functions and high-dimensional functions.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28x%2B%5Cdelta%29%3Df(x)%2B%5Clangle%20%5Cnabla%20f(x)%2C%20%5Cdelta%20%5Crangle%20%2B%20o(%5C%7C%5Cdelta%5C%7C_2)%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28x%2B%5Cdelta%29%3Df(x)%2B%5Clangle%20%5Cnabla%20f(x)%2C%20%5Cdelta%20%5Crangle%20%2B%20%5Cfrac%7B1%7D%7B2%7D%5Clangle%20%5Cdelta%2C%20%5Cnabla%5E2%20f(x)%20%5Cdelta%20%5Crangle%20%2B%20o(%5C%7C%5Cdelta%5C%7C_2%5E2)%0A" /></p><h3 id="Symbolic-Differentiation">Symbolic Differentiation</h3><p>Idea: derive the analytic derivatives first, then make numerical substitution. Usually, software can derive the analytic derivatives for us, such as Matlab (Symbolic Math Toolbox, diff), Python (SymPy, diff), and Mathematica (D)<br><img src="figure2.png" alt="figure2"></p><h3 id="Limitation-of-analytic-diferentiation">Limitation of analytic diferentiation</h3><p><img src="figure3.png" alt="figure3"><br>What is the gradient and/or Hessian of</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28W%29%3D%5Csum_i%5C%7Cy_i-%5Csigma(W_k%5Csigma(W_%7Bk-1%7D%5Cdots(W_1x_i)))%5C%7C_F%5E2%0A" /></p><p>Applying the chain rule is boring and error-prone, and performing Taylor expansion is also tedious. The lession we learn from tech history is to leave boring jobs to computers.</p><h3 id="Approxiamte-the-gradient">Approxiamte the gradient</h3><p><img src="figure4.png" alt="figure4"><br>Similiarly, to approximate the Jacobian for <img src="https://math.now.sh?inline=f%28x%29%3A%20%5Cmathbb%20R%5En%20%5Crightarrow%20%5Cmathbb%20R%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20f_j%7D%7B%5Cpartial%20x_i%7D%5Capprox%20%5Cfrac%7Bf_j%28x%2B%5Cdelta%20e_i%29-f_j(x)%7D%7B%5Cdelta%20%7D%20%5Cquad%20%5Ctext%7B(one%20element%20each%20time)%7D%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x_i%7D%5Capprox%20%5Cfrac%7Bf%28x%2B%5Cdelta%20e_i%29-f_j(x)%7D%7B%5Cdelta%20%7D%20%5Cquad%20%5Ctext%7B(one%20column%20each%20time)%7D%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=J_f%28x%29p%5Capprox%20%5Cfrac%7Bf_j(x%2B%5Cdelta%20p)-f_j(x)%7D%7B%5Cdelta%20%7D%20%5Cquad%20%5Ctext%7B(directional)%7D%0A" /></p><p>Why people prefer the <strong>central</strong> version?<br><img src="figure5.png" alt="figure5"><br>If you want to get a error rate of <img src="https://math.now.sh?inline=10%5E%7B-6%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, in forward scheme you have to set <img src="https://math.now.sh?inline=%5Cdelta" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to be <img src="https://math.now.sh?inline=10%5E%7B-6%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. But in central scheme, you only need to set <img src="https://math.now.sh?inline=%5Cdelta" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to be <img src="https://math.now.sh?inline=10%5E%7B-3%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><p><img src="figure6.png" alt="figure6"><br>Second-order methods are expensive storage-wise and computation-wise. In fact, what you need in all second-order methods are approximations of Hessian but not exact Hessian. Typically, what you need is <img src="https://math.now.sh?inline=%5Cnabla%5E2f%28x%29v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and this is not Hessian itself but Hessian multiplying with a vector.</p><h2 id="Auto-Differentiation">Auto Differentiation</h2><h3 id="Auto-Differentiation-in-1D">Auto Differentiation in 1D</h3><p>Consider a univaiate function <img src="https://math.now.sh?inline=f_k%20%5Ccirc%20f_%7Bk-1%7D%20%5Ccirc%20%5Ccdots%20%5Ccirc%20f_2%20%5Ccirc%20f_1%28x%29%3A%20%5Cmathbb%20R%20%5Crightarrow%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Write <img src="https://math.now.sh?inline=y_0%3Dx%2C%20y_1%3Df_1%28x%29%2Cy_2%3Df(y_1)%2C%5Cdots%2Cy_k%3Df(y_%7Bk-1%7D)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, or in <strong>computational graph</strong> form:<br><img src="figure7.png" alt="figure7"><br>Also, we represent chain rule in Leibniz form:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7B%5Cpartial%20f%7D%7B%5Cpartial%20x%7D%20%3D%20%5Cfrac%7B%5Cpartial%20y_k%7D%7B%5Cpartial%20y_0%7D%3D%5Cfrac%7B%5Cpartial%20y_k%7D%7B%5Cpartial%20y_%7Bk-1%7D%7D%5Cfrac%7B%5Cpartial%20y_%7Bk-1%7D%7D%7B%5Cpartial%20y_%7Bk-2%7D%7D%20%5Cdots%20%5Cfrac%7B%5Cpartial%20y_1%7D%7B%5Cpartial%20y_0%7D%0A" /></p><p>How to evaluate the product?</p><ul><li>From left to right in the chain (follow the arrow): <strong>forward mode auto diff</strong></li><li>From right to left in the chain: <strong>backward/reverse mode auto diff</strong></li><li>Hybrid: mixed mode</li></ul><h4 id="Forward-mode-in-1D">Forward mode in 1D</h4><p><img src="figure8.png" alt="figure8"></p><h4 id="Reverse-mode-in-1D">Reverse mode in 1D</h4><p><img src="figure9.png" alt="figure9"><br>The remarkable difference is firstly you need the forward part (traveling following the arrow) and calculate all the numerical values, and secondly move backward.</p><h4 id="Forward-vs-Reverse">Forward vs Reverse</h4><ul><li>Forward mode AD: one forward pass, compute <img src="https://math.now.sh?inline=y_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>’s and <img src="https://math.now.sh?inline=%5Cfrac%7Bdy_i%7D%7Bdy_0%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>'s together</li><li>Reverse mode AD: one forward pass to compute <img src="https://math.now.sh?inline=y_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>’s, one backward pass to compute <img src="https://math.now.sh?inline=%5Cfrac%7Bdy_k%7D%7Bdy_i%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>'s<br><img src="figure10.png" alt="figure10"></li></ul><h3 id="Auto-Differentiation-in-High-Dimension">Auto Differentiation in High Dimension</h3><p>Let <img src="https://math.now.sh?inline=f%3A%5Cmathbb%20R%5Em%20%5Crightarrow%20%5Cmathbb%20R%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=h%3A%20%5Cmathbb%20R%5En%20%5Crightarrow%20%5Cmathbb%20R%5Ek" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=z%3Dh%28y%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=y%3Df%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Then <img src="https://math.now.sh?inline=z%3Dh%20%5Ccirc%20f%28x%29%3A%20%5Cmathbb%20R%5En%20%5Crightarrow%20%5Cmathbb%20R%5Ek" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=J_%7B%5Bh%20%5Ccirc%20f%5D%7D%28x%29%3DJ_h(f(x))J_f(x)%2C%20or%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20x%7D%20%3D%20%5Cfrac%7B%5Cpartial%20z%7D%7B%5Cpartial%20y%7D%5Cfrac%7B%5Cpartial%20y%7D%7B%5Cpartial%20x%7D%20%5CLeftrightarrow%20%5Cfrac%7B%5Cpartial%20z_j%7D%7B%5Cpartial%20x_i%7D%3D%5Csum_%7Bl%3D1%7D%5Em%5Cfrac%7B%5Cpartial%20z_j%7D%7B%5Cpartial%20y_l%7D%5Cfrac%7B%5Cpartial%20y_l%7D%7B%5Cpartial%20x_i%7D%20%5Cforall%20i%2Cj%0A" /></p><p><img src="figure11.png" alt="figure11"></p><h4 id="A-multivariate-example-–-forward-mode">A multivariate example – forward mode</h4><p><img src="figure12.png" alt="figure12"><br>Forward mode auto differentiation depends on the input dimension.</p><h4 id="A-multivatiate-example-–-reserve-mode">A multivatiate example – reserve mode</h4><p><img src="figure13.png" alt="figure13"><br>Note: <img src="https://math.now.sh?inline=%5Cbar%20v_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> means <img src="https://math.now.sh?inline=%5Cfrac%7B%5Ctext%7Bpartial%20of%20output%20%7D%7D%7B%5Ctext%7Bpartial%20of%20%7D%20v_i%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. There is a name for this variable in auto differentiation community, which is caleld adjoint variable.<br>Reverse mode auto differentiation depends on the output dimension, which is exactly why nowadays netral networks prefer reverse mode because the ouput dimension is usually one dimension. This is also what people call <strong>backprop</strong> (back propagation) in deep learning.</p><h4 id="Forward-vs-Reserve">Forward vs Reserve</h4><p>Both of them cannot deal with loops in computational graph, i.e., acyclic graph.<br><img src="figure14.png" alt="figure14"><br>The forward mode starts with roots, while reverse mode starts with leaves.</p><h3 id="Implementation-Trick-–-Tensor-Abstration">Implementation Trick – Tensor Abstration</h3><p>On previous images, those nodes in the computational graph are scalar, which is fine when we only have 1 or 2 variables. However, if the dimension grows to be very large but we still use scalar representation, it’s going to be really messy. But today we have a wonderful idea of tensor, and lots of useful packages already implemented. Now we’re able to represent each node in computational graph as a vector, matrix, 3-D tensor, …<br><img src="figure16.png" alt="figure16"><br>Now the difference is that we have to apply chain rule in tensors rather than scalars.</p><h3 id="Implementation-Trick-–-Vector-Jacobian-Product-VJP">Implementation Trick – Vector Jacobian Product (VJP)</h3><p>Interested in <img src="https://math.now.sh?inline=J_f%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for <img src="https://math.now.sh?inline=f%3A%20R%5En%20%5Crightarrow%20R%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Implement <img src="https://math.now.sh?inline=v%5ETJ_f%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for any <img src="https://math.now.sh?inline=v%20%5Cin%20R%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p>Why VJP is interesting? Why is it a stardard practice in lots of auto differentiation packages?<br>The idea is that if you just give me the <img src="https://math.now.sh?inline=v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> then I can retain the value. Even if you want the Jacobian at this point, if you just set the <img src="https://math.now.sh?inline=v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> in <img src="https://math.now.sh?inline=v_TJ_f%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to be <img src="https://math.now.sh?inline=v%3De_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (elementary vector/matrix) for <img src="https://math.now.sh?inline=i%3D1%2C%5Cdots%2Cm" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> then you recover rows of <img src="https://math.now.sh?inline=J_f%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Another benefit is that it’s often enough for application, e.g., calculate <img src="https://math.now.sh?inline=%5Cnabla%20%28g%20%5Ccirc%20f%29%20%3D%20(%5Cnabla%20f%5ETJ_f)%5ET" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with known <img src="https://math.now.sh?inline=%5Cnabla%20f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p>Why possible?<br><img src="figure17.png" alt="figure17"></p><p>Good to know:</p><ul><li>In practice, graph are built automatically by software</li><li>Higher-order derivatives can also be done, particularly Hessian-vector product <img src="https://math.now.sh?inline=%5Cnabla%5E2f%28x%29v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (check out <a href="https://github.com/google/jax">Jax</a>!)</li><li>Auto-diff in Tensorflow and <a href="https://pytorch.org/docs/stable/autograd.html">Pytorch</a> are spacialized to DNNs, whereas Jax (in Python) is full fledged and more general</li><li>General resources for <a href="http://www.autodiff.org">autodiff</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Numerical Optimization </tag>
            
            <tag> Backprop </tag>
            
            <tag> Auto Diff </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Numerical Optimization: Iterative Methods</title>
      <link href="/2020/10/17/Numerical-Optimization-Iterative-Methods/"/>
      <url>/2020/10/17/Numerical-Optimization-Iterative-Methods/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><p>Many deep learning techniques are about solving optimization problems.</p><h2 id="Find-global-minimum">Find global minimum</h2><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=min_xf%28x%29%0A" /></p><ul><li>Grid search: incurs <img src="https://math.now.sh?inline=O%28%5Cepsilon%5E%7B-n%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> cost</li><li>Smarter search (using properties):<ul><li>1st-order necessary condition: Assume <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is 1st-order differentiable at <img src="https://math.now.sh?inline=x_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. If <img src="https://math.now.sh?inline=x_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is a local minimizer, then <img src="https://math.now.sh?inline=%5Cnabla%20f%28x_0%29%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with <img src="https://math.now.sh?inline=%5Cnabla%20f%28x%29%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: 1st-order stationary point (1OSP)</li><li>2nd-order necessary condition: Assume <img src="https://math.now.sh?inline=f%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is 2-order differentiable at <img src="https://math.now.sh?inline=x_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. If <img src="https://math.now.sh?inline=x_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is a local min, <img src="https://math.now.sh?inline=%5Cnabla%20f%28x_0%29%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Cnabla%5E2f%28x_0%29%5Csucceq%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with <img src="https://math.now.sh?inline=%5Cnabla%20f%28x%29%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Cnabla%5E2f%28x_0%29%5Csucceq%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: 2st-order stationary point (2OSP)</li></ul></li></ul><p>How to find 1OSP and 2OSP?</p><ul><li>Analytic method: find 1OSP’s using gradient first, then study them using Hessian, but this is only for simple functions. e.g.:</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28x%29%3D%5C%7Cy-Ax%5C%7C_2%5E2%5Ctext%7B%2C%20or%20%7Df(x%2Cy)%3Dx%5E2y%5E2-x%5E3y%2By%5E2-1)%0A" /></p><ul><li>Iterative methods: find 1OSP’s/2OSP’s by making consecutive small movements</li></ul><p><img src="figure3.png" alt="figure3"><br>Making consecutive small movements to reach the minimum is as the image above,but there are two questions:</p><ul><li>What direction to move?</li><li>How far to move?</li></ul><p>Based on these two questions, there are two possibilities:</p><ul><li>Line-search methods: direction first, size second</li><li>Trust-region mothods: size first, direction second</li></ul><h2 id="Classic-line-search-methods">Classic line-search methods</h2><p><img src="figure1.png" alt="figuer1"><br>Four questions:</p><ul><li>How to choose direction <img src="https://math.now.sh?inline=d_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>?</li><li>How to choose step size <img src="https://math.now.sh?inline=t_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>?</li><li>Where to initialize?</li><li>When to stop?</li></ul><h3 id="How-to-choose-a-search-direction">How to choose a search direction?</h3><p>We want to decrease the function value toward global minimum. The intuitive way is to find a direction to decrease most rapidly, which is the gradient.<br>for any fixed <img src="https://math.now.sh?inline=t%3E0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, using 1st order Taylor expansion<br><img src="https://math.now.sh?inline=f%28x_k%2Btd_%7Bk%2B1%7D%29-f(x_k)%5Capprox%20t%20%5Clangle%20%5Cnabla%20f(x_k)%2Cd_%7Bk%2B1%7D%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="figure2.png" alt="figure2"><br>If we set <img src="https://math.now.sh?inline=d_k%20%3D%20-%5Cnabla%20f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then we get gradient/steepest descent: <img src="https://math.now.sh?inline=x_%7Bk%2B1%7D%20%3D%20x_k%20-%20t%5Cnabla%20f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p>For gradient descent, the convergence or the speed of movement depends on the shape of contour plot. That’s also what people call the conditioning (condition number) problem.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Ctext%7Bcondition%20number%7D%3D%5Cfrac%7B%5Csigma_%7Bmax%7D%28A%29%7D%7B%5Csigma_%7Bmin%7D(A)%7D%0A" /></p><p><img src="figure4.png" alt="figure4"><br>Curvature is related to Hessian, which is the direction that the gradient changes the fast. In graph, curvature is greater if the 3D graph is more squeezed in that area. Image putting a ball on a valley, the direction that it intends to fall toward has the largest curvature.</p><p>In short, find a direction to descrease most rapidly is shortsighted, because it finds a direction which is best locally but not neccesarily globally. Therefore, to find a direction based on both gradient and Hessian is a better solution.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28x_k%2Btv%29-f(v)%20%5Capprox%20t%20%5Clangle%20%5Cnabla%20f(x_k)%2Cv%20%5Crangle%20%2B%20%5Cfrac%7B1%7D%7B2%7Dt%5E2%5Clangle%20v%2C%20%5Cnabla%5E2%20f(x_k)v%20%5Crangle%0A" /></p><p>minimizing the right side</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=v%20%3D%20-t%5E%7B-1%7D%20%5Cleft%5B%20%5Cnabla%5E2%20f%28x_k%29%20%5Cright%5D%5E%7B-1%7D%5Cnabla%20f(x_k)%0A" /></p><p>If we set <img src="https://math.now.sh?inline=d_k%3D%5Cleft%5B%5Cnabla%5E2%20f%28x_k%29%20%5Cright%5D%5E%7B-1%7D%20%5Cnabla%20f(x_k)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then we get the <strong>Newton’s method</strong>:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%20%3D%20x_k%20-t%5Cleft%5B%5Cnabla%5E2%20f%28x_k%29%20%5Cright%5D%5E%7B-1%7D%20%5Cnabla%20f(x_k)%0A" /></p><p>where <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> can set to be 1.<br>From the image below, I hope you can be convinced that this is faster than gradient descient.<br><img src="figure5.png" alt="figure5"></p><h3 id="Why-called-Newton’s-method">Why called Newton’s method</h3><p>Recall Newton’s method for root-finding in calculus:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%3Dx_k-f'%28x_n%29f(x_n)%0A" /></p><p>Newton’s method for solving nonlinear system <img src="https://math.now.sh?inline=f%28x%29%3D0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%3Dx_k-%5Cleft%5B%20J_f%28x_n%29%5E%5Cdag%20f(x_n)%20%5Cright%5D%0A" /></p><p>Newton’s method for solving <img src="https://math.now.sh?inline=%5Cnabla%20f%28x%29%3D0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%3Dx_k-%5Cleft%5B%5Cnabla%5E2%20f%28x_n%29%20%5Cright%5D%5E%7B-1%7D%20%5Cnabla%20f(x_n)%0A" /></p><p>Even though it seems like Newton’s method is faster just looking at the image above, but it costs <img src="https://math.now.sh?inline=O%28n%5E3%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> per step while gradient costs <img src="https://math.now.sh?inline=O%28n%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> per step. That’s why plain Newton never used for large-scale problem.</p><p>There are also other problems with Newton’s method. For example, in</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=v%20%3D%20-t%5E%7B-1%7D%20%5Cleft%5B%20%5Cnabla%5E2%20f%28x_k%29%20%5Cright%5D%5E%7B-1%7D%5Cnabla%20f(x_k)%0A" /></p><ul><li><img src="https://math.now.sh?inline=%5Cnabla%5E2%20f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> may be non-invertible</li><li>the minimum value is <img src="https://math.now.sh?inline=-%5Cfrac%7B1%7D%7B2%7D%20%5Clangle%20%5Cnabla%20f%28x_k%29%2C%20%5Cleft%5B%5Cnabla%5E2%20f(x_k)%20%5Cright%5D%5E%7B-1%7D%5Cnabla%20f(x_k)%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. If <img src="https://math.now.sh?inline=%5Cnabla%5E2f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is not positive definite, the “minimum” may turn out to be “maximum” or somthing else.</li></ul><h3 id="Find-step-size">Find step size</h3><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_k%3Dx_%7Bk_1%7D%2Bt_kd_k%0A" /></p><ul><li>Naive choice: sufficiently small constant <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for all <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Robust and practical choice: back-tracking line search.</li></ul><p>Intuition for back-tracking line search:</p><ul><li>By taylor’s theorem</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28x_k%2Btd_k%29%3Df(x_k)%2Bt%20%5Clangle%20%5Cnabla%20f(x_k)%2Cd_k%20%5Crangle%20%2B%20o(t%5C%7Cd_k%5C%7C_2)%0A" /></p><p>When <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is sufficiently small, <img src="https://math.now.sh?inline=t%20%5Clangle%20%5Cnabla%20f%28x_k%29%2Cd_k%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> dictates the value descrese. But we also want <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to be as large as possible to make rapid progess</p><ul><li>Idea: find a large possible <img src="https://math.now.sh?inline=t%5E*" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to make sure <img src="https://math.now.sh?inline=f%28x_k%2Bt%5E*d_k%29-f(x_k)%20%5Cgeq%20ct%5E*%20%5Clangle%20%5Cnabla%20f(x_k)%2Cd_k%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (key condition) for a chosen parameter <img src="https://math.now.sh?inline=c%20%5Cin%20%280%2C1%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and no less</li><li>Details: start from <img src="https://math.now.sh?inline=t%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. if the key condition not satisfied, <img src="https://math.now.sh?inline=t%3Dpt" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for a chosen parameter <img src="https://math.now.sh?inline=p%20%5Cin%20%280%2C1%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p>A widely implemented strategy in numerical optimization packages:<br><img src="figure6.png" alt="figure6"></p><h3 id="Where-to-initialzie-start">Where to initialzie/start?</h3><p><img src="figure7.png" alt="figure7"></p><ul><li>Convex: most iterative methods converge to the global min no matter the initialization</li><li>Nonconvex: initialization matters a lot. Common heuristics: random initialization, multiple independent runs</li><li>Nonconvex: clever initialization is possible with certain assumptions on the data: <a href="https://sunju.org/research/nonconvex/">https://sunju.org/research/nonconvex/</a></li></ul><h3 id="When-to-stop">When to stop?</h3><p>Fix some positive tolerance values <img src="https://math.now.sh?inline=%5Cepsilon_g%2C%5Cepsilon_H%2C%5Cepsilon_f%2C%5Cepsilon_v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Possibilities:</p><ul><li><img src="https://math.now.sh?inline=%5C%7C%5Cnabla%20f%28x_k%29%5C%7C_2%20%5Cleq%20%5Cepsilon_g" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>m i.e., check 1st order cond</li><li><img src="https://math.now.sh?inline=%5C%7C%5Cnabla%20f%28x_k%29%5C%7C_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Clambda_%7Bmin%7D%20%28%5Cnabla%5E2%20f(x_k%29)%20%5Cgeq%20-%5Cepsilon_H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, i.e., check 2nd order cond</li><li><img src="https://math.now.sh?inline=%7Cf%28x_k%29-f(x_%7Bk-1%7D)%20%5Cleq%20%5Cepsilon_f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=%5C%7Cx_k-x_%7Bk-1%7D%5C%7C_2%20%5Cleq%20%5Cepsilon_v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><h2 id="Advanced-line-search-methods">Advanced line-search methods</h2><h3 id="Momentum-method">Momentum method</h3><p>Why momentum?</p><ul><li>Gradient Descent is cheap (<img src="https://math.now.sh?inline=O%28n%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> per step) but overall convergence sentitive to conditioning.</li><li>Newton’s convergence is not sensitive to conditioning but expensive (<img src="https://math.now.sh?inline=O%28n%5E3%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> per step)</li></ul><p>In physics, a heavy object has a large innertia/momentum – resistance to change of velocity</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%3Dx_k-%5Calpha_k%20%5Cnabla%20f%28x_k%29%20%2B%20%5Cbeta_k%20(%5Cunderbrace%7Bx_k-x_%7Bk-1%7D%7D_%5Ctext%7Bmomentum%7D)%20%5Ctext%7B%20%20due%20to%20Polyak%7D%0A" /></p><p><img src="figure8.png" alt="figure8"><br>This image illustrates the next step will be determined by the summing of gradient and velocity.<br><img src="figure9.png" alt="figure9"></p><h3 id="Quasi-Newton-methods">Quasi-Newton methods</h3><p>Quasi-: seemingly; apparently but not really</p><p>Newton’s method: cost <img src="https://math.now.sh?inline=O%28n%5E2%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> storage and <img src="https://math.now.sh?inline=O%28n%5E3%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> computation per step</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=x_%7Bk%2B1%7D%20%3D%20x_k-t%20%5Cleft%5B%5Cnabla%5E2%20f%28x_k%29%20%5Cright%5D%5E%7B-1%7D%20%5Cnabla%20f(x_k)%0A" /></p><p>Idea: approximate <img src="https://math.now.sh?inline=%5Cnabla%5E2%20f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> or <img src="https://math.now.sh?inline=%5Cleft%5B%5Cnabla%5E2%20f%28x_k%29%20%5Cright%5D%5E%7B-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to allow efficient storage and computation – <strong>Quasi-Newton Methods</strong></p><p>Choose <img src="https://math.now.sh?inline=H_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to approxiamte <img src="https://math.now.sh?inline=%5Cnabla%5E2%20f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> so that</p><ul><li>avoid calculation of second derivative</li><li>simplify matrix inversion, i.e., computing the search direction</li></ul><p><img src="figure10.png" alt="figure10"><br>credit: UCLA ECE236C</p><ul><li>Different variants differ on how to compute <img src="https://math.now.sh?inline=H_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Normally <img src="https://math.now.sh?inline=H_k%5E%7B-1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> or its factorized version stored to simplify calculation of <img src="https://math.now.sh?inline=%5CDelta%20x_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><h4 id="BFGS-method">BFGS method</h4><p>Without being specified, when people say Quasi-Newton method, they usually refer to BFGS method, which is Broyden-Fletcher-Goldfarb-Shanno method.<br><img src="figure11.png" alt="figure11"><br>credit: UCLA ECE236C</p><p>Cost of update: <img src="https://math.now.sh?inline=O%28n%5E2%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> instead of <img src="https://math.now.sh?inline=O%28n%5E3%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> in Newton’s method<br>Cost of Storage: <img src="https://math.now.sh?inline=O%28n%5E2%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li>secant condition: <img src="https://math.now.sh?inline=H_%7Bk%2B1%7Ds%3Dy" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (think of 1st Taylor expansuion to <img src="https://math.now.sh?inline=%5Cnabla%20f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>)</li><li>Curvature condition: <img src="https://math.now.sh?inline=s_k%5ETy_k%3E0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to ensure that <img src="https://math.now.sh?inline=H_%7Bk%2B1%7D%20%5Csucc%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> if <img src="https://math.now.sh?inline=H_k%20%5Csucc%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=H_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=H_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> are close in an appropriate sense</li></ul><p><img src="figure12.png" alt="figure12"><br>This can be further improved by L-BFGS method, which reduce the cost of storage and update to <img src="https://math.now.sh?inline=O%28mn%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, which is linear in dimension <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><h3 id="Block-coordinate-descent">Block coordinate descent</h3><p>If we have a function with many blocks of variables, then each time we only find the minimum of each block of variables.</p><p>Consider a function <img src="https://math.now.sh?inline=f%28x_1%2C%5Cdots%2Cx_p%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with <img src="https://math.now.sh?inline=x_1%20%5Cin%20R%5E%7Bn_1%7D%2C%20%5Cdots%2C%20x_p%20%5Cin%20R%5E%7Bn_p%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="figure13.png" alt="figure13"></p><ul><li>Also called <strong>alternating direction/minimization methods</strong></li><li>When <img src="https://math.now.sh?inline=n_1%3Dn_2%3D%5Cdots%3Dn_p" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, called <strong>coordinate descent</strong></li><li>may work with constrained problems and non-differentiable problems (e.g., <img src="https://math.now.sh?inline=min_%7BA%2CB%7D%20%5C%7CY-AB%5C%7C_F%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> s.t. <img src="https://math.now.sh?inline=A" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> orthogonal, Lasso: <img src="https://math.now.sh?inline=min_x%20%5C%7Cy-Ax%5C%7C_2%5E2%2B%5Clambda%20%5C%7Cx%5C%7C_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>)</li><li>maybe faster than gradient descent or Newton</li><li>maybe simple and cheap</li></ul><h3 id="Conjugate-gradient-methods">Conjugate gradient methods</h3><p>Solve linear equation <img src="https://math.now.sh?inline=y%3DAx%20%5Cleftrightarrow%20min_x%20%5Cfrac%7B1%7D%7B2%7Dx%5ETAx-b%5ETx%20%5Ctext%7B%20with%20%7D%20A%20%5Csucc%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>If we apply coordinate descent:<br><img src="figure14.png" alt="figure14"><br>The two graphs is the case of when <img src="https://math.now.sh?inline=n%3D2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, that’s why in graph of the left-hand side it only takes two steps to find the minimum. We can generalize it to n-dimensional space, then it will need n steps to solve the problem.</p><p><img src="figure15.png" alt="figure15"><br>Conjugate can be understood as orthogonal here, as you can see in the graph above, each step it’s going to a orthogonal direction of last direction.</p><h2 id="Trust-region-methods">Trust-region methods</h2><p>Size first, direction second</p><p>Recall Taylor expansion <img src="https://math.now.sh?inline=f%28x%2Bd%29%20%5Capprox%20f(x)%20%2B%20%5Clangle%20%5Cnabla%20f(x_k)%2Cd%20%5Crangle%20%2B%20%5Cfrac%7B1%7D%7B2%7D%5Clangle%20d%2C%5Cnabla%5E2%20f(x_k)d%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p><img src="figure16.png" alt="figure16"></p><p>To measure approximation quality: <img src="https://math.now.sh?inline=p_k%3D%5Cfrac%7Bf%28x_k%29-f(x_k%2Bd_k)%7D%7Bm_k(0)-m_k(d_k)%7D%3D%5Cfrac%7B%5Ctext%7Bactual%20decrease%7D%7D%7B%5Ctext%7Bmodel%20decrease%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p><img src="figure17.png" alt="figuer17"></p><h3 id="Why-turst-region-method-TRM">Why turst-region method (TRM)?</h3><p>Why we want to consider this method which is quite different with other methods in style?</p><p>Recall Taylor expansion <img src="https://math.now.sh?inline=m_k%28d%29%20%5Cdoteq%20f(x_k)%20%2B%20%5Clangle%20%5Cnabla%20f(x_k)%2Cd%20%5Crangle%20%2B%20%5Cfrac%7B1%7D%7B2%7D%5Clangle%20d%2CB_kd%20%5Crangle" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li>Take <img src="https://math.now.sh?inline=B_k%3D%5Cnabla%5E2%20f%28x_k%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Gradient descent: stop at <img src="https://math.now.sh?inline=%5Cnabla%20f%28x_k%29%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>Why newton’s method is a not a good idea on siatuation that gradient is zero?<br><img src="https://math.now.sh?inline=%5Cleft%5B%5Cnabla%5E2%20f%28x_k%29%5Cright%5D%5E%7B-1%7D%20%5Cnabla%20f(x_k)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> may be just stop at <img src="https://math.now.sh?inline=%5Cnabla%20f%28x_k%29%20%3D%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> or be ill-defined.</li></ul><p><img src="figure18.png" alt="figure18"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Numerical Optimization </tag>
            
            <tag> Trust-region Method </tag>
            
            <tag> Line-search Method </tag>
            
            <tag> Newton&#39;s Method </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Association Rules: Basic and Advanced Concept</title>
      <link href="/2020/10/14/Association-Rules-Basic-Concept/"/>
      <url>/2020/10/14/Association-Rules-Basic-Concept/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><h1>Association Rule: Basic Concept</h1><h2 id="Association-Rule-Mining">Association Rule Mining</h2><p>Given a set of transactions, find rules that predict the occurence of an item based on the occurrenes of other items in the transaction.</p><p>Example of Association Rules (Implication means co-occurrence, not causality)</p><ul><li>{Diaper} =&gt; {Beer}</li><li>{Milk, Bread} =&gt; {Eggs, Coke}</li><li>{Beer, Bread} =&gt; {Milk}</li></ul><h3 id="Def-Frequent-Itemset">Def: Frequent Itemset</h3><p>An <strong>itemset</strong> is a collection of one or more items such as {Milk, Bread, Diaper}, and we use <strong>k-itemset</strong> to represent an itemset that contains k items. Also, we introduce a terminology called <strong>support count</strong> (frequency of occurrrence of an itemset) and <strong>support</strong> (fraction of transactions that contain an itemset). For instance, if this itemset {Milk, Bread, Diaper} shows up twice in transactions, then we can say <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>({Milk, Bread, Diaper})=2 and s({Milk, Bread, Diaper})=2/5. Finally, a <strong>frequent itemset</strong> is an itemset whose support is greater than or equal to a minsup threshold. Other than support, another rule evaluation metrics is <strong>confidence</strong>, which measures how often items in Y appear in transactions that contain X. For exmaple, {Milk, Diaper} =&gt; {Beer}, when X = {Milk, Diaper}, and Y = {Beer}.</p><h3 id="Association-Rule-Mining-Task">Association Rule Mining Task</h3><p>Given a set of transactions T, the goal of association rule mining is to find all rules having</p><ul><li>support &gt;= minsup threshold</li><li>confidence &gt;= minconf threshold</li></ul><p>Brute-force approach:</p><ol><li>List all possible association rules</li><li>Compute the support and confidence for each rule</li><li>Prune rules that fail the minsup and minconf thresholds</li></ol><p><strong>But this is computationally prohibitive!</strong> Because given <img src="https://math.now.sh?inline=d" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> unique items, the total number of itemsets is <img src="https://math.now.sh?inline=2%5Ed" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, so the total number of possible association rules:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=R%3D%5Csum_%7Bk%3D1%7D%5E%7Bd-1%7D%5Cleft%5B%20%7Bd%5Cchoose%20k%7D%20%5Ctimes%20%5Csum_%7Bj%3D1%7D%5E%7Bd-k%7D%20%7Bd-k%20%5Cchoose%20j%7D%20%5Cright%5D%3D3%5Ed-2%5E%7Bd-1%7D%2B1%0A" /></p><p>e.g.: if d=6, R=602 rules.</p><p>Therefore, we need to think of a less computational way. Since each item can be either yes or no in a transaction, if we have <img src="https://math.now.sh?inline=M" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> items, then the possible candidates for a transection is <img src="https://math.now.sh?inline=2%5EM" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. We can reduce the number of candidates by <strong>Apriori principle: if an itemset is frequent, then all of tis subsets must also be frequent.</strong></p><p>Apriori principle holds due to the following property of the support measure:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cforall%20X%2C%20Y%20%3A%20%28X%20%5Csubseteq%20Y%29%20%5Cimplies%20s(X)%20%5Cgeq%20s(Y)%0A" /></p><ul><li>Support of an itemset never exceeds the support of its subsets</li><li>This is known as the anti-monotone property of support</li></ul><p><img src="figure1.png" alt="figure1"><br>In this image, once we found AB is infrequenat, then we can prune any supersets, because if AB is found infrequent already, then any itemset containing more items involving AB would be infrequent too.</p><p><img src="figure2.png" alt="figure2"><br>Another illustration is as the image above. If we’ve already known that Coke and Eggs are infrequent in 1-itemsets, then we we don’t need to generate candidates involving Coke or Eggs in 2-itemsets, 3-itemsets, etc. Meanwhile, since {Bread, Beer} and {Milk, Beer} are infrequent 2-itermsets, then we don’t need to generate canidates involving {Bread, Beer} and {Milk, Beer}.</p><h3 id="Apriori-Algorithm">Apriori Algorithm</h3><p><img src="https://math.now.sh?inline=F_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: frequent k-itemsets<br><img src="https://math.now.sh?inline=L_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: candidate k-itemsets</p><ol><li>let <img src="https://math.now.sh?inline=k%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Generate <img src="https://math.now.sh?inline=F_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> = {frequent 1-itemsets}</li><li>Repeat until <img src="https://math.now.sh?inline=F_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is empty<ol><li>Candidate Generation: Generate <img src="https://math.now.sh?inline=L_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> from <img src="https://math.now.sh?inline=F_k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate Pruning: Prune candidate itemsets in <img src="https://math.now.sh?inline=L_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> containing subsets of length <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> that are infrequent</li><li>Support Counting: Count the support of each candidate in <img src="https://math.now.sh?inline=L_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> by scanning the DB</li><li>Candidate Elimination: Eliminate candidates in <img src="https://math.now.sh?inline=L_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> that are infrequent, leaving only those that are frequent =&gt; <img src="https://math.now.sh?inline=F_%7Bk%2B1%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ol></li></ol><h3 id="Rule-Generation">Rule Generation</h3><p>Given a frequent itemset <img src="https://math.now.sh?inline=L" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, find all non-empty subsets <img src="https://math.now.sh?inline=f%20%5Csubset%20L" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> such that <img src="https://math.now.sh?inline=f%20%5Crightarrow%20L-f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> satisfies the minimum confidence requirement<br><img src="figure3.png" alt="figure3"><br>If <img src="https://math.now.sh?inline=%7CL%7C%3Dk" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then there are <img src="https://math.now.sh?inline=2%5Ek%20-%202" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> candidate association rules (ignoring <img src="https://math.now.sh?inline=L%20%5Crightarrow%20%5Cemptyset" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Cemptyset%20%5Crightarrow%20L" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>)</p><p>In general, confidence does not have an anti-monotone property, but confidence of rules generated from the same itemset has an anti-monotone property. For example, suppose {A,B,C,D} is a frequent 4-itemset:$$c(ABC \rightarrow D \geq c(AB \rightarrow CD) \geq c(A \rightarrow BCD)$$<br>If we found a low confidence rule, then we can pruned the following rules as the image shown below:<br><img src="figure4.png" alt="figure4"></p><h2 id="Algorithms-and-Complexity">Algorithms and Complexity</h2><p>Choice of minimum support threshold</p><ul><li>If you lower the support threshold, there will be more frequent itemsets.</li><li>This may increase the number of candidates and max length of frequent itemsets.</li></ul><p>Dimensionality (number of items) of the dataset</p><ul><li>More space is needed to store support count of itemsets</li><li>If number of requent itemsets also increases, both computation and I/O costs may also increase</li></ul><p>Size of database</p><ul><li>Run time of algorithm increases with number of transactions</li></ul><p>Average transaction width</p><ul><li>Transaction width increases the max length of frequent itemsets</li><li>Number of subsets in a transaction increases with its width, increasing computation time for support counting.</li></ul><p><img src="figure5.png" alt="figure5"></p><h4 id="Maximal-Frequent-Itemset">Maximal Frequent Itemset</h4><p>An itemset is maximal frequent if it is frequent and none of its immediate supersets is frequent.<br><img src="figure6.png" alt="figure6"></p><h4 id="Closed-Itemset">Closed Itemset</h4><p>An itemset X is closed if none of its immediate supersets has the same support as the itemset X.<br>X is not closed if at least one of its immediate supersets has support count as X.</p><p><img src="figure7.png" alt="figure7"><br>In this example, if we look at {B} = 5, and we observe that none of {A,B},{B,C},{B,D}'s support is equal with {B} = 5, then we can say {B} is a closed itemset.</p><p>Another example:<br><img src="figure8.png" alt="figure8"><br>In this example, those red digits are transaction ID of the table in the top-left corner. First, if the support of an itemset’s supersets are all less than this itemset, then this itemset is a closed itemset (in grey). Second, according to the minimum support given (in this case, 2), we can say every node with more than or equal to 2 red digits are frequent. Third, among those grey nodes (closed), we can find those maximal frequent itemset and mark them in blue ring.</p><p>Question: Is any maximal itemsets also close itemsets?</p><ul><li>Yes, because every subsets’ support should be less them this itemset itself, then this itemset is also closed.</li></ul><p>This Venn graph also shows the relationship between these concepts that mentioned above.<br><img src="figure9.png" alt="figure9"></p><h2 id="Pattern-Evaluation">Pattern Evaluation</h2><p>We’re convinced that association rule algorithms can produce large number of rules. In order to evaluate it, we need some interestingness measures that can be used to prune/rank the patterns, since in the original formulation, only support &amp; confidence are the only measures used.</p><p>Given <img src="https://math.now.sh?inline=X%20%5Crightarrow%20Y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> or <img src="https://math.now.sh?inline=%5C%7BX%2CY%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, information needed to compute interestingness can be obtained from a contingency table<br><img src="figure10.png" alt="figure10"><br>Havint this table, I’m able to construct all the measures such as support, confidence, Gini, entropy, etc.</p><p>Let’s look at the drawback of confidence:<br><img src="figure11.png" alt="figure11"><br><strong>Association Rule: Tea -&gt; Coffee</strong><br><img src="https://math.now.sh?inline=Confidence%5Capprox%20P%28coffee%20%7C%20Tea%29%3D%5Cfrac%7B150%7D%7B200%7D%3D0.75" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=Confidence%20%3E%2050%5C%25" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, meaning people who drink tea are more likely to drink coffee than not drink coffee, so rule seems reasonable. However, there is something wrong here with this rule, because we only that people who drink tea is unlikely to drink coffee. What’s wrong here?<br><img src="https://math.now.sh?inline=P%28coffee%29%3D0.8" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, which means knowing that a person drinks tea reduces the probability that the person drinks coffee!<br>Note that <img src="https://math.now.sh?inline=P%28Coffee%20%7C%20Tea%29%3D%5Cfrac%7B650%7D%7B800%7D%3D0.8125" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>Let’s look at another example:<br><strong>Association Rule: Tea -&gt; Honey</strong><br><img src="https://math.now.sh?inline=Confidence%5Capprox%20P%28Honey%20%7C%20Tea%29%3D%5Cfrac%7B100%7D%7B200%7D%3D0.50" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=Confidence%20%3D%2050%5C%25" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, whichi may mean that drinking rea has little influence whether honey is used or not. So rule seems uninteresting.</p><p>Then, what kind of rules do we really want?</p><ul><li>Confidence (X-&gt;Y) should be sufficiently high<ul><li>To ensure that people who buy X will more likely buy Y than not buy Y</li></ul></li><li><strong>Confidence (X-&gt;Y) &gt; Support(Y)</strong><ul><li>otherwise, rule will be misleading because having item X actually reduces the chance of having item Y in the same transaction</li></ul></li></ul><h3 id="Statistical-Relationship-between-X-and-Y">Statistical Relationship between X and Y</h3><p>The criterion: <img src="https://math.now.sh?inline=Confidence%20%28X%20%5Crightarrow%20Y%29%20%3D%20Support%20(Y)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is equivalent to</p><ul><li><img src="https://math.now.sh?inline=P%28Y%7CX%29%3DP(Y)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=P%28X%2CY%29%3DP(X)%5Ctimes%20P(Y)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (X and Y are independent)<ul><li>If <img src="https://math.now.sh?inline=P%28X%2CY%29%20%3E%20P(X)%20x%20P(Y)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: X and Y are positively correlated</li><li>If <img src="https://math.now.sh?inline=P%28X%2CY%29%20%3C%20P(X)%20x%20P(Y)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: X and Y are negatively correlated</li></ul></li></ul><h3 id="Measures-that-take-into-account-statistical-dependence">Measures that take into account statistical dependence</h3><p><img src="https://math.now.sh?inline=Lift%20%3D%20%5Cfrac%7BP%28Y%7CX%29%7D%7BP(Y)%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=Interest%20%3D%20%5Cfrac%7BP%28X%2CY%29%7D%7BP(X)P(Y)%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=PS%3DP%28X%2CY%29-P(X)P(Y)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%5Cphi-coefficient%3D%5Cfrac%7BP%28X%2CY%29-P(X)P(Y)%7D%7B%5Csqrt%7BP(X)%5B1-P(X)%5DP(Y)%5B1-P(Y)%5D%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><p>Now if we look at the coffee-tea example:<br><img src="figure11.png" alt="figure11"><br><img src="https://math.now.sh?inline=Confidence%3DP%28Coffee%7CTea%29%3D0.75" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, but <img src="https://math.now.sh?inline=P%28Coffee%29%3D0.8" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. This implies that:<br><img src="https://math.now.sh?inline=Interest%20%3D%20%5Cfrac%7B0.15%7D%7B0.2%5Ctimes%200.8%7D%3D0.9375" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>(&lt;1, therefore is negativelyt accociated)</p><p>There are more measures:<br><img src="figure13.png" alt="figure13"><br>Then, how do we compare different measures?<br><img src="figure14.png" alt="figure14"><br>These measures are so different, how do we choose which one to use?</p><p>Let’s discover some properties</p><ul><li>Property under Inversion Operation<br>Some measures won’t change due to inversion operation. E.g., Correlation won’t change due to inversion operation.<br><img src="figure15.png" alt="figure15"></li><li>Property under Null Addition<br><img src="figure16.png" alt="figure16"><br>Cosine, Jaccard, All-confidence, condifence won’t change, they’re invariant measures due to Null addition. But some measures will change such as correlation, Interest/Lift, odds ratio, etc.</li><li>Property under Row/Column Scaling<br><img src="figure17.png" alt="figure17"><br>Mosteller: underlying associations hould be independent of the relative number of male and female students in the samples.</li></ul><p>In a table:<br><img src="figure18.png" alt="figure18"></p><h3 id="Simpson’s-Paradox">Simpson’s Paradox</h3><p>Observed relationship in data may be influenced by the presence of other confounding factors (hidden cariables),i.e., hidden variables may cause the observed relationship to disappear or reverse its direction. So, proper stratification is needed to avoid generating spurious patterns.</p><p>For example, say we have two hospitals where hospital A has 80% of recovery rate from COVID, and hospital B has 90% of recovery rate from COVID. Which hospital is better?<br>Let’s further look at the recovery rate of different age group by a age threshold. It turns out that Hospital A has 50% of recovery rate on older population, and Hospital B has 30% of recovery rate on older population. Meanshilw, Hospital A has 99% of recovery rate on younder population while Hospital B’s is 98%.<br>Hospital A has both higher recovery rate than Hospital B in terms of old and yound population, but why the overall recovery is lower than the Hospital B? This is the simpson’s paradox.</p><h1>Data Mining: Advance Concepts of Association Analysis</h1><h2 id="Sequential-Patterns">Sequential Patterns</h2><p>Example of sequence:</p><ul><li>Sequence of different transaction by a customer at an online store<br>&lt;{Digital Camera, iPad} {Memory card} {headphone, iPad cover}&gt;</li><li>Sequence of book checked out at a library:<br>&lt;{Fellowship of the Ring} {The Two Towers} {Return of the King}&gt;</li><li>more on the table below<br><img src="figure21.png" alt="figure1"></li></ul><p>How does the sequence data look like in database?<br><img src="figure22.png" alt="figure2"></p><p>What does sequence data differ from market-basket data?<br><img src="figure23.png" alt="figure3"><br>From Sequence data, we can tell people who bought item {2} would be likely to buy item {1} afterward on the next purchase. And Market-basket data tells us that people who bought item {1,8} would be likely to buy item {7} on the same purchase.</p><h3 id="Formal-def-of-sequence">Formal def of sequence</h3><p>A sequence is an ordered list of elements <img src="https://math.now.sh?inline=s%20%3D%20%3Ce_1%20e_2%20e_3%20%5Cdots%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, when each element contains a collection of events(items) <img src="https://math.now.sh?inline=e_i%20%3D%20%5Clbrace%20i_1%2C%20i_2%2C%20%5Cdots%2C%20i_k%20%5Crbrace" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Length of a sequence <img src="https://math.now.sh?inline=%7Cs%7C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is given by the number of elements in the sequence. A k-sequence is a sequence that contains k events (items).</p><h3 id="Visual-def-of-subsequence">Visual def of subsequence</h3><p><img src="figure24.png" alt="figure4"><br>A subsequence is contained in another data sequence if each element of subsuence is a subset of a corresponding element of the data sequence. For the second row of the table, element {1} of subsuquence is a subset of element {1,2} of data sequence. Since {2} is a element in subsequence but it doesn’t have a corresponding element in data sequence, it’s not contained. Note that the order in subsequence doesn’t matter.</p><h3 id="Sequential-Pattern-Mining">Sequential Pattern Mining</h3><p>Now let’s talk about support again. The support of a subsequence <img src="https://math.now.sh?inline=w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is defined as the fraction of data sequences that contain <img src="https://math.now.sh?inline=w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. A sequential pattern is a frequent subsequence (i.e., a subsequence where <img src="https://math.now.sh?inline=support%20%5Cgeq%20minsup" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>). Suppose we’re given a database of sequences and a user-specified minimum support threshold (i.e., minsup), the task is to find all subsuquences with support greater than or equal to minsup. There is an example of frequent subsequences:<br><img src="figure25.png" alt="figure5"><br>Here are only examples but not all the frequent subsequences. For instance, if we look at subsuquence &lt;{1,2}&gt;, since it’s a subset of sequence A B C out of A B C D E, the support of it is 60% which is higher than our specified minsup, so it’s a frequent subsequence.</p><p>After talking about support, let’s talk about confidence. The calculation of confidence here is different from normal transaction database (market-basket data).<br><img src="figure26.png" alt="figure6"></p><p>How can we extract sequential patterns?</p><ul><li>Given <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> events: <img src="https://math.now.sh?inline=i_1%2C%20i_2%2C%20%5Cdots%2C%20i_n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate 1-subsequences:<br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%2C%20%3C%5C%7Bi_n%5C%7D%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate 2-subsequences:<br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_3%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%20%3C%5C%7Bi_n%5C%7D%2C%5C%7Bi_n%5C%7D%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Candidate 3-subquences:<br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%2C%20i_3%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_2%2C%20i_4%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%2C%20i_2%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%20%3C%5C%7Bi_n%5C%7D%2C%5C%7Bi_n%5C%7D%3E" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="https://math.now.sh?inline=%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%3E%2C%20%3C%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_1%5C%7D%2C%20%5C%7Bi_2%5C%7D%3E%2C%20%5Cdots%2C" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p>A 2 events example:<br><img src="figure27.png" alt="figure7"><br>As you can see, the idea seems to be computational expensive here if we have many events. So we introduce a method called Generalized Sequential Pattern (GSP) to deal with it.</p><ol><li>Make the first pass over the sequence database D to yield all the 1-element frequent sequences</li><li>Repeat until no new frequent sequences are found<ul><li>Candidate Generation: Merge pairs of frequent subsequences found in the (k-1)th pass to generate candidate sequences that contain k items</li><li>Candidate Pruning: Prune candidate k-sequences that contain infrequent (k-1)-subsequences</li><li>Support Counting: Make a new pass over the sequence database D to find the support for these candidate sequences</li><li>Candidate Elimination: Eliminate candidate k-sequences whose actual support is less than minsup</li></ul></li></ol><p>What does “merge” mean above? Some example below:<br><img src="figure28.png" alt="figure8"><br>A visual walk-through of candidate generation:<br><img src="figur29.png" alt="figure9"><br><img src="figure30.png" alt="figure10"><br>No matter which item I cross out in &lt;{1} {2 5} {3}&gt;, I can always find it in the frequent 3-sequences. For instance, if I cross out {1}, check if &lt;{2 5} {3}&gt; is in the frequent 3-sequences. If I cross out {2}, check if &lt;{1} {5} {3}&gt; is in the frequent 3-sequences. If I cross out {3}, check if &lt;{1} {2 5}&gt; is in the frequent 3-sequences. Do it for all cadidate generation and you will find only &lt;{1} {2 5} {3}&gt; survives, the others have been pruned.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Sequential Rules Mining </tag>
            
            <tag> Association Rule </tag>
            
            <tag> Apriori Algorithm </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Overview of Support Vector Machine (SVM) and Ensemble Learning</title>
      <link href="/2020/10/09/Overview-of-Support-Vector-Machine-SVM-and-Ensemble-Learning/"/>
      <url>/2020/10/09/Overview-of-Support-Vector-Machine-SVM-and-Ensemble-Learning/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><h1>Support Vector Machines</h1><p>We will start by looking at this image and think about which decision boundary is better? B1 or B2?<br><img src="figure1a.png" alt="figure1"><br>If we find the hyperplace maximizes the margin as the image does, then we can tell B1 is better than B2, which means if we have one more record B1 is more likely to correctly classify the new record.</p><h2 id="Linear-SVM">Linear SVM</h2><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28%5Coverrightarrow%7Bx%7D%29%20%3D%20%5Cbegin%7Bcases%7D%201%20%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%20if%20%5Coverrightarrow%7Bw%7D%20%5Cbullet%20%5Coverrightarrow%7Bx%7D%20%5Cgeqslant%201%20%5C%5C%20-1%20%5C%2C%20%5C%2C%20%5C%2C%20if%20%5Coverrightarrow%7Bw%7D%20%5Cbullet%20%5Coverrightarrow%7Bx%7D%20%5Cleqslant%20-1%20%5Cend%7Bcases%7D%20%0A" /></p><p>Learning the model is equaivalent to determining the values of <img src="https://math.now.sh?inline=%5Coverrightarrow%7Bw%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=b" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and our objective is to maximize: <img src="https://math.now.sh?inline=Margin%20%3D%20%5Cfrac%7B2%7D%7B%5C%7C%5Coverrightarrow%7Bw%7D%5C%7C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, which is equivalent to minimizing: <img src="https://math.now.sh?inline=L%28%5Coverrightarrow%7Bw%7D%29%3D%5Cfrac%7B%5C%7C%5Coverrightarrow%7Bw%7D%5C%7C%5E2%7D%7B2%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. And this is a <strong>constrained optimization problem</strong>.</p><p>What if the problem is not linearly separable like the image following?<br><img src="figure2a.png" alt="figure2"><br>The notion is the same, we’re still utilizing the idea of margin, but we want to add some adjustment to some errors. Then we introduce slack variables.<br>We need to minimize: <img src="https://math.now.sh?inline=L%28%5Coverrightarrow%7Bw%7D%29%3D%5Cfrac%7B%5C%7C%5Coverrightarrow%7Bw%7D%5C%7C%5E2%7D%7B2%7D%20%2B%20C%5C%7B%5Csum_%7Bi%3D1%7D%5EN%20%5Cxi_i%5Ek%20%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>subject to:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=f%28%5Coverrightarrow%7Bx%7D%29%20%3D%20%5Cbegin%7Bcases%7D%201%20%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%20if%20%5Coverrightarrow%7Bw%7D%20%5Cbullet%20%5Coverrightarrow%7Bx%7D%20%5Cgeqslant%201%20-%20%5Cxi_i%20%5C%5C%20-1%20%5C%2C%20%5C%2C%20%5C%2C%20if%20%5Coverrightarrow%7Bw%7D%20%5Cbullet%20%5Coverrightarrow%7Bx%7D%20%5Cleqslant%20-1%20%2B%20%5Cxi_i%20%5Cend%7Bcases%7D%0A" /></p><p>It turns out that we can actually also use this version in some data set which is separable.<br><img src="figure3a.png" alt="figure3"><br>There is a trade-off here. B1 has a wider margin but also has a record misclassififed (error), while B2 has no errors but with a narrower margin. We can’t tell which one is performaning better because it’s relevant to the specific question, but using the validation set will always give us an answer.</p><h2 id="Nonlinear-SVM">Nonlinear SVM</h2><p><img src="figure4a.png" alt="figure4"><br>We can try to transform the data into higher dimensional space:<br><img src="figure5a.png" alt="figure5"><br>Since this is an intro class, we didn’t go into details of this nonliear example.</p><h2 id="Kernel-Trick">Kernel Trick</h2><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5CPhi%28x_i%29%20%5Cbullet%20%5CPhi(x_j)%20%3D%20K(x_i%2Cx_j)%0A" /></p><p><img src="https://math.now.sh?inline=K%28x_i%2Cx_j%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is a kernal function (expressed in terms of the coordinates in the original space)<br>Examples:</p><ul><li><img src="https://math.now.sh?inline=K%28x%2Cy%29%3D(x%20%5Ccdot%20y%20%2B%201)%5Ep" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=K%28x%2Cy%29%20%3D%20e%5E%7B%5Cfrac%7B-%5C%7Cx%20-%20y%20%5C%7C%5E2%7D%7B2%20%5Csigma%5E2%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=K%28x%2Cy%29%20%3D%20tanh(kx%20%5Ccdot%20y%20-%20%5Cdelta)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p>Advantages of using kernel:</p><ul><li>Don’t have to know the mapping function <img src="https://math.now.sh?inline=%5CPhi" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Computing dot product <img src="https://math.now.sh?inline=%5CPhi%28x_i%29%20%5Cbullet%20%5CPhi(x_j)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> in the original space avoids curse of dimensionality</li></ul><p>Not all functions can be kernels:</p><ul><li>Must make sure there is a corresponding <img src="https://math.now.sh?inline=%5CPhi" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> in some high-dimensional space</li><li>Mercer’s theorem</li></ul><h2 id="Characteristics-of-SVM">Characteristics of SVM</h2><ul><li><p>The learning problem is formulated as a convex optimization problem</p><ul><li>Efficient algorithms are avaiable to find the global minima</li><li>Many of the other methods use greedy approaches and find locally optimal solutions</li><li>High computational complexity for building the model</li></ul></li><li><p>Robust to noise</p></li><li><p>Overfitting is handled by maximizing the margin of the decision boundary</p></li><li><p>SVM can handle irrelevant and redundant better than many other techniques</p></li><li><p>The user needs to provide the type of kernel function and cost function</p></li><li><p>Difficult to handle missing values</p></li></ul><h1>Ensemble Methods</h1><ul><li>Constrct a set of base classifiers leanred from the training data</li><li>Predict class label of test records by combining the predictions made by multiple classifiers (e.g., by taking majority vote)</li></ul><h2 id="Why-does-ensemble-methods-work">Why does ensemble methods work?</h2><p>Suppose there are 25 base classifiers</p><ul><li>Each classifier has error rate, <img src="https://math.now.sh?inline=%5Cepsilon%20%3D%200.35" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>Majority vote of classifiers used for classification</li><li>If all classifiers are identical, then error rate of ensemble = <img src="https://math.now.sh?inline=%5Cepsilon%280.35%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>If all classifiers are independent (errors are uncorrelated): Error rate of ensemble = probability of having more than half of base classifiers being wrong</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=e_ensemble%20%3D%20%5Csum_%7Bi%3D13%7D%5E25%20%7B25%20%5Cchoose%20i%7D%20%5Cepsilon%5Ei%20%281-%5Cepsilon%29%5E%7B25-i%7D%3D0.06%0A" /></p><h2 id="Necessary-conditions-for-ensemble-methods">Necessary conditions for ensemble methods</h2><p>Ensemble methods work better than a single base classifier if:</p><ol><li>All base classifiers are independent of each other</li><li>All base classifiers perform better than random guessing (error rate &lt; 0.5 for binary classification)</li></ol><p><img src="figure1.png" alt="figure1"></p><h2 id="Rationale-for-ensemble-learning">Rationale for ensemble learning</h2><p>Ensemble methods work best with unstable base classifiers</p><ul><li>Classifiers that are sensitive to minor perturbations in training set, due to high model complexity (e.g., a little change of records may end up with a different model)</li><li>Examples: Unpruned decision trees, ANNs, …</li><li>Low Bias in finding optimal decision boundary</li><li>High variance for minor changes in training set or model selection procedure</li></ul><h2 id="Bias-Variance-Decomposition">Bias-Variance Decomposition</h2><p>Analogous problem of reaching a target y by firing projectiles from x (regression problem):<br><img src="figure2.png" alt="figure2"><br>On the right side of the image, those stars are actual values of y, while those dots on the left are predict values of y, and the difference between of their averages is the Bias.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=gen.error%28m%29%3Dc_1%20%5Ctimes%20noise%20%2B%20bias(m)%20%2B%20c_2%20%5Ctimes%20variance(m)%0A" /></p><p><img src="figure3.png" alt="figure3"><br>Both of the situation above are bad. Ensemble methods try to reduce the variance of complex models (with low bias) by aggregating responses of multiple base classfiers.</p><p>A visual for ensemble learning:<br><img src="figure4.png" alt="figure4"></p><h2 id="Constructing-ensemble-classifiers">Constructing ensemble classifiers</h2><ul><li>By manipulating training set (e.g., bagging, boosting)</li><li>By manipulating input features (e.g., random forests)</li><li>By manipulating class labels (e.g., error-correcting output coding)</li><li>By manipulating learning algorithm (e.g., injecting randomness in ANN or decision tree)</li></ul><h2 id="Bagging-Bootstrap-AGGregatING">Bagging (Bootstrap AGGregatING)</h2><ul><li>Bootstrap sampling: sampling with replacement<br><img src="figure5.png" alt="figure5"><br>You can do different round of bagging, and each data is equally probability to be selected.</li><li>Build classifier on each bootstrap sample</li><li>Probability of a training instance being selected in a bootstrap sample is:<ul><li><img src="https://math.now.sh?inline=1%20-%20%281%20-%20%5Cfrac%7B1%7D%7Bn%7D%29%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (n: number of training instances)</li><li>~0.632 when n is large</li></ul></li></ul><p><img src="figure6.png" alt="figure6"></p><h2 id="Boosting">Boosting</h2><p>An iterative procedure to adaptively change distribution of training data by focusing more on previously misclassified records</p><ul><li>Initially, all N records are assigned equal weights (for being selected for training)</li><li>Records that are wrongly classified will have their weights increased in the next round</li><li>Records that are classified correctly wil have their weights decreased in the next round</li><li>Unlike bagging, weights may change at the end of each boosting round</li></ul><p>e.g., AdaBoost</p><h2 id="Random-Forest-Algorithm">Random Forest Algorithm</h2><p>Construct an ensemble of decision trees by manipulating training set as well as features</p><ul><li>Use bootstrap sample to train every decision tree (similiar to Bagging)</li><li>Use the following tree induction algorithm:<ul><li>At every internal node of decision tree, randomly sample p attributes for selecting split criterion</li><li>Repeat this procedure until all leaves are pure (unpruned tree)</li></ul></li></ul><h4 id="Characterstics-of-Random-Forest">Characterstics of Random Forest</h4><ul><li>Base classifiers are unpruned trees and hence are unstable classifiers</li><li>Base classifers are decorrelated (due to randomization in training set as well as features)</li><li>Random forests reduce variance of unstable classifiers without negatively impacting the bias</li><li>Selection of hyper-parameter p<ul><li>Small value ensures lack of correlation</li><li>High value promotes strong base classifiers</li><li>Common default choice <img src="https://math.now.sh?inline=%5Csqrt%7Bd%7D%2C%20log_2%28d%2B1%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Mining </tag>
            
            <tag> SVM </tag>
            
            <tag> Ensemble Learning </tag>
            
            <tag> Random Forest </tag>
            
            <tag> Bagging </tag>
            
            <tag> Boosting </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Mining: Imbalanced class problem</title>
      <link href="/2020/10/06/Data-Mining-Imbalanced-class-problem/"/>
      <url>/2020/10/06/Data-Mining-Imbalanced-class-problem/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><p>Lots of classification problems where the classes are skewed (more records from one class than another)</p><ul><li>Credit card fraud</li><li>Intrusion detection</li><li>Defective products in manufacturing assembly line</li></ul><h2 id="Challenges">Challenges</h2><ul><li>Evaluation measures such as accuracy are not well-suited for imbalanced class.</li><li>Detecting the rare class is like finding a needle in a haystack (classic parable haha)</li></ul><h2 id="Confusion-Matrix">Confusion Matrix</h2><p><img src="figure1.png" alt="figure1"></p><ul><li>a: TP (true positive)</li><li>b: FN (fasle negative)</li><li>c: FP (false postiive)</li><li>d: TN (true negative)</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Accuracy%20%3D%20%5Cfrac%7BTP%2BTN%7D%7BTP%2BTN%2BFP%2BFN%7D%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=ErrorRate%3D1-Accuracy%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Precision%28p%29%3D%20Positive%20%5C%2C%20Predictie%20%5C%2C%20Value%20%3D%20%5Cfrac%7BTP%7D%7BTP%2BFP%7D%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Recall%28r%29%3DSensitivity%20%3D%20%5Cfrac%7BTP%7D%7BTP%2BFN%7D%0A" /></p><p>Recall is out of all the positive samples that are given, what fraction of them this classifier correctly classify. Sensitivity is often used in medical community.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=F-measure%28F%29%20%3D%20%5Cfrac%7B2rp%7D%7Br%2Bp%7D%20%3D%20%5Cfrac%7B2TP%7D%7B2TP%2BFN%2BFP%7D%0A" /></p><p>Accuracy alone is not a sufficient way to evaluate models, so we introduce precision and recall, and then using F-measure to take both of them into account.</p><p><img src="figure2.png" alt="figure2"><br>Let’s look at the example above. There isn’t really a one measure is better than another, because it depends on your situation particularly. For example, the first one here might be a bad idea for COVID testing, because the precision is only 50%, then the second one is favored.</p><p>There are more measures of classification performance.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Specificity%3DTN%20%5C%2C%20Rate%20%3D%20%5Cfrac%7BTN%7D%7BTN%2BFP%7D%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=FP%20%5C%2C%20Rate%20%3D%20%5Calpha%20%3D%20%5Cfrac%7BFN%7D%7BFN%2BTP%7D%20%3D%201%20-%20Specificity%0A" /></p><p><img src="https://math.now.sh?inline=%5Calpha" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the probibility that we reject the null hypothesis when it is true. This is a Type I error or a false positive (FP).</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=FN%20%5C%2C%20Rate%20%3D%20%5Cbeta%20%3D%20%5Cfrac%7BFN%7D%7BFN%2BTP%7D%20%3D%201-%20Sensitivity%0A" /></p><p><img src="https://math.now.sh?inline=%5Cbeta" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the probability that we accept the null hypothesis when it is false. This is a Type II error or a false negative (FN).</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Power%20%3D%20Sensitivity%20%3D%201%20-%20%5Cbeta%0A" /></p><p><img src="figure3.png" alt="figure3"><br>Let’s look at another example. These two cases are actually the same classifier. If we look at the actual class yes row, both case A and B give us 80% of right prediction. And if we look at actual class no row, both case A and B gives us 80% of right prediction too. In short, the <img src="https://math.now.sh?inline=%5Cfrac%7BTP%20Rate%7D%7BFP%20Rate%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the same for these two cases. The only difference here maybe the sample size, but they’re the same classifier. Notice that here the F-measures are different. This is an exmaple to show you that F-measeare can potentially fail us.</p><h2 id="ROC-Receiver-Operating-Characteristic">ROC (Receiver Operating Characteristic)</h2><p><img src="figure4.png" alt="figure4"><br>Every points sitting on the red curve, the TPR is higher than FRP.</p><p>The coordinates on the graph is (TPR,FPR).</p><ul><li>(0,0): declare everything to be negative class</li><li>(1,1): declare everything to be positive class</li><li>(1,0): ideal</li></ul><h3 id="Using-ROC-for-Model-Comparison">Using ROC for Model Comparison</h3><p><img src="figure5.png" alt="figure5"></p><h3 id="Hot-to-construct-an-ROC-curve">Hot to construct an ROC curve</h3><p><img src="figure6.png" alt="figure6"><br>In the image above, the score is the fraction of positive prediction and negative prediction in the leaf node (decision tree, for instance). This is a way to convert discrete ouput value to continuous value because we need continuous value to plot the ROC curve. The following is how it may look like:<br><img src="figure7.png" alt="figure7"></p><h3 id="How-to-build-classifier-with-imbalanced-training-set">How to build classifier with imbalanced training set</h3><p>Modify the distribution of training data so that rare class is well-resented in training set.</p><ul><li>Undersample the majority class</li><li>Oversample the rare class</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Mining </tag>
            
            <tag> Confusion Matrix </tag>
            
            <tag> Receiver operating characteristic </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Overview of K Nearest Neighbor Classifiers and Rule-Based Classifiers</title>
      <link href="/2020/10/03/Overview-of-K-Nearest-Neighbor-Classifiers-and-Rule-Based-Classifiers/"/>
      <url>/2020/10/03/Overview-of-K-Nearest-Neighbor-Classifiers-and-Rule-Based-Classifiers/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><h1>K Nearest Neighbor (KNN) Classfiers (Overview)</h1><p>Basic idea: If it walks like a duck, quacks like a duck, then it’s probably a duck.</p><p>Require three things:</p><ul><li>The set of labeled records</li><li>Distance metric to compute distance between records</li><li>The value of <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, the number of nearest neighbors to retrieve</li></ul><p>To classify an unknown record:</p><ul><li>Compute distance to other training records</li><li>identify k nearest neighbors</li><li>Use class labels of nearest neighbors to determine the class label of unknown record</li></ul><p>Sometimes we call KNN the laziest because it doesn’t do anything until we have to make a decision. In other words, there is not much happening during the training period.</p><p>To recall: to compute proximity between two points, we need certain distance metric.<br>For example: Euclidean distance</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=d%28x%2Cy%29%20%3D%20%5Csqrt%7B%5Csum_i(x_i-y_i)%5E2%7D%0A" /></p><p>Next, determine the class from nearest neighbor list</p><ul><li>Take the majority vote of class labels among the KNNs</li><li>Weight the vote accoridng to distance. E.g. weight factor <img src="https://math.now.sh?inline=w%20%3D%20%5Cfrac%7B1%7D%7Bd%5E2%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><h2 id="The-value-of-k-matters">The value of k matters</h2><ul><li>If k is too small, sensitive to noice points</li><li>If k is too large, neighborhood may include points from other classes</li></ul><h2 id="Choice-of-promixity-measure-matters">Choice of promixity measure matters</h2><p>For documents, cosine is better than correlation or Euclidean. E.g: in the image below, they have the same Euclidean distance but different cosine similarity.</p><p><img src="ex1.png" alt="ex1"></p><h2 id="Data-preprocessing-is-often-required">Data preprocessing is often required</h2><p>Arributes may have to be scaled to prevent distance measures from being dominated by one of the attributes. In addition, time series are often standardized to have a mean of 0 and a standard deviation of 1.</p><p>Is there a notion of complexity in KNN? Yes, the complexity may depend on the choice of <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. If the choice of <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is 1, then we will get many arbitrary shapes that include a single record respectively. Any classifiers we learn, we shall think about its complexity. Decision tree’s complexity can be the depth of the tree, or whether the tree is a binary tree.</p><h2 id="Issues-of-missing-values-in-training-and-test-sets">Issues of missing values in training and test sets</h2><ul><li>Proximity computations normally require the presence of all attributes</li><li>Some appoaches use the subset of attributes present in two instances</li></ul><h2 id="Issues-of-irrelevant-and-redundant-attributes">Issues of irrelevant and redundant attributes</h2><ul><li>Irrelevant attributes add noise to the proximity measure</li><li>Redundant attributes bias the proximity measure towards certain attributes</li><li>Can use variable selection or dimensionality reduction to address irrelevant and redundant attributes</li></ul><h2 id="Improving-KNN-Efficiency">Improving KNN Efficiency</h2><ul><li>Avoid having to compute distance to all objects in the training set<ul><li>Multi-dimensional access methods (k-d trees)</li><li>Fast approximate similarity search</li><li>Locality Sensetive Hashing (LSH)</li></ul></li><li>Condensing<ul><li>Determine a smaller set of objects that give the same performance</li></ul></li><li>Editing<ul><li>Remove objects to improve efficiency</li></ul></li></ul><h1>Rule-Based Classifiers</h1><p>Rule-based classifier: classify records by using a collection of “if…then…” rules.</p><p>Rule: (Condition) <img src="https://math.now.sh?inline=%5Crightarrow" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> <img src="https://math.now.sh?inline=y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li><p>Where</p><ul><li>Condition is a conjection of tests on attributes</li><li><img src="https://math.now.sh?inline=y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the class label</li></ul></li><li><p>Exmaples of classification rules</p><ul><li>(Blood Type=Warm) <img src="https://math.now.sh?inline=%5Cbigcap" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (Lay Eggs=Yes) <img src="https://math.now.sh?inline=%5Crightarrow" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> Birds</li><li>(Taxable Income&lt;50K) <img src="https://math.now.sh?inline=%5Cbigcap" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (Refund=Yes) <img src="https://math.now.sh?inline=%5Crightarrow" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> Evade=No</li></ul></li></ul><p>An example:<br><img src="figure1.png" alt="figure1"><br>A rule <img src="https://math.now.sh?inline=R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> covers an instance <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> if the attributes of the instance satisfy the condition of the rule, just like <img src="https://math.now.sh?inline=R1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=R2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, etc above. <img src="https://math.now.sh?inline=R1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> covers a bird.</p><h2 id="Rule-Coverage-and-Accuracy">Rule Coverage and Accuracy</h2><ul><li>Coverage of a rule</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7B%5Ctext%7Brecords%20that%20satisfy%20the%20antecedent%20of%20a%20rule%7D%7D%7B%5Ctext%7Btotal%20records%7D%7D%0A" /></p><ul><li>Accuracy of a rule</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7B%5Ctext%7Brecords%20that%20satisfy%20the%20antecedent%20that%20also%20satisfy%20the%20consequent%20of%20a%20rule%7D%7D%7B%5Ctext%7Brecords%20that%20satisfy%20the%20antecedent%20of%20a%20rule%7D%7D%0A" /></p><h2 id="Characteristics-of-Rule-Sets-Strategy-1">Characteristics of Rule Sets: Strategy 1</h2><ul><li><p>Mutually exclusive rules</p><ul><li>Classifier contains mutually exclusive rules if the rules are independent of each other</li><li>Every record is covered by at most one rule</li></ul></li><li><p>Exhaustive Rules</p><ul><li>Classifier has exhaustive coverage if it accounts for every possible combination of attribute values</li><li>Each record is covered by at least one rule</li></ul></li></ul><h2 id="What-if-rules-are-not-mutually-exclusive">What if rules are not mutually exclusive?</h2><ul><li>We can solve this by ordering rule sets. Rules are rank ordered according to their priority. When a test record is presented to the classifier, it will be assigned to the class label of the higheset ranked rule it has triggered. If none of the rules fired, it will be assigned to the default class. There are two ways to order rules:<ul><li>Rule-based ordering: Individual rules are ranked based on their quality</li><li>Class-based ordering: Rules that belong to the same class appear together</li></ul></li></ul><h2 id="Direct-method-to-build-classification-rules">Direct method to build classification rules</h2><ol><li>Start from an empty rule</li><li>Grow a rule using the Learn-One-Rule function</li><li>Remove training records covered by the rule</li><li>Repeat Step 2 and 3 until stopping criterion is met</li></ol><p>Here is a visual example of the steps above:<br><img src="figure2.png" alt="figure2"><br><img src="figure3.png" alt="figure3"></p><p>Here are two common strategies to grow the rule:<br><img src="figure4.png" alt="figure4"></p><h2 id="Rule-evaluation">Rule evaluation</h2><ul><li>Foil’s Information Gain (FOIL: First Order Inductive Learner – an early rule-based learning algorithm)</li><li><img src="https://math.now.sh?inline=R_0%3A%20%5C%7B%5C%7D%20%5Crightarrow%20class%20%5Ctext%7B%28initial%20rule%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=R_1%3A%20%5C%7BA%5C%7D%20%5Crightarrow%20class%20%5Ctext%7B%28rule%20after%20adding%20conject%29%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Gain%28R_0%2CR_1%29%20%3D%20p_1%20%5Ctimes%20%5B%20log_2(%5Cfrac%7Bp_1%7D%7Bp_1%2Bn_1%7D)-%20log_2(%5Cfrac%7Bp_0%7D%7Bp_0%2Bn_0%7D)%20%5D%0A" /></p><ul><li><img src="https://math.now.sh?inline=p_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of positive instances covered by R0</li><li><img src="https://math.now.sh?inline=n_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of negative instances covered by R0</li><li><img src="https://math.now.sh?inline=p_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of positive instances covered by R1</li><li><img src="https://math.now.sh?inline=n_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of negative instances covered by R1</li></ul><h2 id="Direct-Method-RIPPER">Direct Method: RIPPER</h2><ul><li>For 2-class problem, choose one of the classes as positive class, and the other as negative class.<ul><li>Learn rules for postiive class</li><li>Negative class will be default class</li></ul></li><li>For multi-class problem<ul><li>Order the classes according to increasing class prevelence (fraction of instances that belong to a particular class)</li><li>Learning the rule set for smallest class first, treat the rest as negative class</li><li>Repeat with next smallest class as positive class</li></ul></li></ul><p>How to grow a rule in RIPPER?</p><ul><li>Start from empty rule</li><li>Add conjuncts as long as they improve FOIL’s information gain</li><li>Stop when rule no longer covers negative examples</li><li>Prune the rule immediately using incremental reduced error pruning</li><li>Measure for pruning <img src="https://math.now.sh?inline=v%20%3D%20%5Cfrac%7Bp-n%7D%7Bp%2Bn%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><ul><li><img src="https://math.now.sh?inline=p" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of positive examples covered by the rule in the validation set</li><li><img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of negative examples covered by the rule in the validation set</li></ul></li><li>Pruning method: delete any final sequence of conditions that maximizes <img src="https://math.now.sh?inline=v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><p>Build a rule set:</p><ul><li>Use sequential covering algorithms<ul><li>Find the best rule that covers the current set of positive examples</li><li>Eliminate both positive and negative examples covered by the rule</li></ul></li><li>Each time a rule is added to the rule set compute the new description length<ul><li>Stop adding new rules when the new description length is a bit longer than the smallest description length obtained so far’</li></ul></li></ul><h2 id="Advantages-of-Rule-Based-Classifiers">Advantages of Rule-Based Classifiers</h2><ul><li>Has characterstics quite similiar to decision trees<ul><li>As highly expressive as decision trees</li><li>Easy to interpret (if rules are ordered by class)</li><li>Performance comparable to decision trees<ul><li>Can handle redundant and irrelevant attributes</li><li>Variable interaction can cause issues (e.g., X-OR problem)</li></ul></li></ul></li><li>Better suited for handling imbalanced classes</li><li>Harder to handle missing values in the test set</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Mining </tag>
            
            <tag> Classifier </tag>
            
            <tag> K Nearest Neighbor </tag>
            
            <tag> Rule-Based Classifier </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Math that you need to know for Deep Neural Networks</title>
      <link href="/2020/10/01/Math-that-you-need-to-know-for-Deep-Neural-Networks/"/>
      <url>/2020/10/01/Math-that-you-need-to-know-for-Deep-Neural-Networks/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><h1>MATH for DNN</h1><h2 id="Our-notation">Our notation:</h2><p>The notation in machine learning is not standardized, but this course tends to use the most generally-used notation in machine learning.</p><ul><li>scalars: <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, vectors: <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, matrices: <img src="https://math.now.sh?inline=%5Cmathbb%20X" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, tensors: <img src="https://math.now.sh?inline=%5Cmathcal%20X" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, sets: <img src="https://math.now.sh?inline=S" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>vectors are always <strong>column vectors</strong>, unless stated otherwise</li><li><img src="https://math.now.sh?inline=x_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: <img src="https://math.now.sh?inline=i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>-th element of <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=x_%7Bij%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: <img src="https://math.now.sh?inline=%28i%2C%20j%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>-th element of <img src="https://math.now.sh?inline=%5Cmathbb%20X" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=%5Cmathbb%20x%5Ei" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: <img src="https://math.now.sh?inline=i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>-th row of <img src="https://math.now.sh?inline=%5Cmathbb%20X" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> as a \textbf{row vector}, <img src="https://math.now.sh?inline=%5Cmathbb%20x_j" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: <img src="https://math.now.sh?inline=j" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>-th column of <img src="https://math.now.sh?inline=%5Cmathbb%20X" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> as a <strong>column vector</strong></li><li><img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: real numbers, <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D_%2B" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: positive reals, <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: space of <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>-dimensional vectors, <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: space of <img src="https://math.now.sh?inline=m%20%5Ctimes%20n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> matrices, <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%20%5Ctimes%20k%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: space of <img src="https://math.now.sh?inline=m%20%5Ctimes%20n%20%5Ctimes%20k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> tensors, etc</li><li><img src="https://math.now.sh?inline=%5Bn%5D%20%5Cdoteq%20%5C%7B1%2C%20%5Cdots%2C%20n%20%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><h2 id="Differentiability-–-first-order">Differentiability – first order</h2><p>The definition of differentiability needs to be different in higher dimensional spaces than what is taught in calculus courses. A function is differentiable in higher dimensional space if, for a small perturbation in the input, the function’s value change is linear with respect to that perturbation with some lower-order term.</p><p>Consider <img src="https://math.now.sh?inline=f%28%5Cmathbb%20x%29%3A%20%5Cmathbb%7BR%7D%5En%20%5Cto%20%5Cmathbb%7BR%7D%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li>Definition: a function is <strong>first-order differentiable</strong> at a point <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> if there exists a matrix <img src="https://math.now.sh?inline=%5Cmathbb%20B%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> such that</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cfrac%7Bf%28%5Cmathbb%20x%20%2B%20%5Cmathbb%20%5Cdelta%29%20-%20f(%5Cmathbb%20x)%20-%20%5Cmathbb%20B%20%5Cmathbb%20%5Cdelta%7D%7B%5C%7C%5Cmathbb%20%5Cdelta%5C%7C_%7B2%7D%7D%20%5Cto%20%5Cmathbb%200%20%5Cquad%20%5Cmathrm%7Bas%7D%20%5Cquad%20%5Cmathbb%20%5Cdelta%20%5Cto%20%5Cmathbb%200%0A" /></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=i.e.%2C%20%5Cquad%20f%28%5Cmathbb%20x%20%2B%20%5Cmathbb%20%5Cdelta%29%20%3D%20f(%5Cmathbb%20x)%20%2B%20%5Cmathbb%20B%20%5Cmathbb%20%5Cdelta%20%2B%20o(%5C%7C%5Cmathbb%20%5Cdelta%5C%7C_%7B2%7D)%20%5Cquad%20%5Cmathrm%7Bas%7D%20%5Cquad%20%5Cmathbb%20%5Cdelta%20%5Cto%20%5Cmathbb%200%0A" /></p><ul><li><img src="https://math.now.sh?inline=%5Cmathbb%20B" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is called the (Frechet) derivative.<br>When <img src="https://math.now.sh?inline=m%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=%5Cmathbb%20b%5E%5Cintercal" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (i.e., <img src="https://math.now.sh?inline=%5Cmathbb%20B%5E%5Cintercal" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) called <strong>gradient</strong>, denoted as <img src="https://math.now.sh?inline=%5Cnabla%20f%28%5Cmathbb%20x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. For general <img src="https://math.now.sh?inline=m" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, also called <strong>Jacobian</strong> matrix, denoted as <img src="https://math.now.sh?inline=%5Cmathbb%20J_f%28%5Cmathbb%20x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</li><li>Calculation:  <img src="https://math.now.sh?inline=b_%7Bij%7D%20%3D%20%20%5Cfrac%7B%5Cpartial%20f_i%7D%7B%5Cpartial%20x_j%7D%28%5Cmathbb%20x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><strong>Sufficient (but not necessary) condition for differentiability</strong>: if all partial derivatives exist and are <strong>continuous</strong> at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then <img src="https://math.now.sh?inline=f%28%5Cmathbb%20x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</li></ul><h2 id="Calculus-rules">Calculus rules</h2><p>Many of the rules are similar to the lower-dimensional analogue. However, one rule to pay attention to is the Chain rule. Discussion of this will come after the definition of these rules.</p><p>Assume <img src="https://math.now.sh?inline=f%2C%20g%3A%20%5Cmathbb%7BR%7D%5En%20%5Cto%20%5Cmathbb%7BR%7D%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> are differentiable at a point <img src="https://math.now.sh?inline=%5Cmathbb%20x%20%5Cin%20%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><ul><li><p><strong>linearity</strong>: <img src="https://math.now.sh?inline=%5Clambda_1%20f%20%2B%20%5Clambda_2%20g" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Cnabla%5C%7B%5Clambda_1%20f%20%2B%20%5Clambda_2%20g%5C%7D%28%5Cmathbb%20x%29%3D%20%5Clambda_1%20%5Cnabla%20f(%5Cmathbb%20x)%20%2B%20%5Clambda_2%20%5Cnabla%20g(%5Cmathbb%20x)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p></li><li><p><strong>product</strong>: assume <img src="https://math.now.sh?inline=m%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=fg" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Cnabla%20%5C%7Bfg%5C%7D%20%28%5Cmathbb%20x%29%20%3D%20f(%5Cmathbb%20x)%20%5Cnabla%20g(%5Cmathbb%20x)%20%2B%20%20g(%5Cmathbb%20x)%20%5Cnabla%20f(%5Cmathbb%20x)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p></li><li><p><strong>quotient</strong>: assume <img src="https://math.now.sh?inline=m%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=g%28%5Cmathbb%20x%29%20%5Cne%200" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, <img src="https://math.now.sh?inline=%5Cfrac%7Bf%7D%7Bg%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cnabla%20%5C%7B%5Cfrac%7Bf%7D%7Bg%7D%5C%7D%28%5Cmathbb%20x%29)%20%3D%20%5Cfrac%7Bg(%5Cmathbb%20x)%20%5Cnabla%20f(%5Cmathbb%20x)%20-%20f(%5Cmathbb%20x)%20%5Cnabla%20g(%5Cmathbb%20x)%7D%7Bg%5E2%20(%5Cmathbb%20x)%7D%0A" /></p></li><li><p><strong>Chain rule</strong>: Let <img src="https://math.now.sh?inline=f%3A%20%5Cmathbb%7BR%7D%5Em%20%5Cto%20%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=h%3A%20%5Cmathbb%7BR%7D%5En%20%5Cto%20%5Cmathbb%7BR%7D%5Ek" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=%5Cmathbb%20y%20%3D%20f%28%5Cmathbb%20x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Then, <img src="https://math.now.sh?inline=h%5Ccirc%20f%3A%20%5Cmathbb%7BR%7D%5En%20%5Cto%20%5Cmathbb%7BR%7D%5Ek" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is differentiable at <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and</p></li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cmathbb%20J_%7B%5C%7Bh%20%5Ccirc%20f%5C%7D%7D%20%28%5Cmathbb%20x%29%20%3D%20%5Cmathbb%20J_%7Bh%7D%20(f(%5Cmathbb%20x))%20%5Cmathbb%20J_f(%5Cmathbb%20x).%0A" /></p><p>When <img src="https://math.now.sh?inline=k%3D1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>,</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=%5Cnabla%20%5C%7Bh%20%5Ccirc%20f%5C%7D%20%28%5Cmathbb%20x%29%20%3D%20%5Cmathbb%20J%5E%5Ctop_f(%5Cmathbb%20x)%20%5Cnabla%20h(f(%5Cmathbb%20x))%0A" /></p><p>The thing to note with the chain rule is that when you take the Jacobian of the composition of two matrices, you need to multiply the Jacobian matrices of each. However, when you take the gradient of the composition of two matrices, you need to reverse the order and appply the proper transpose. This is because the gradient is already the transposed form of the first derivative.</p><p><strong>First-order differentiable</strong> at a point <img src="https://math.now.sh?inline=%5Cmathbb%20x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> if there exists a matrix <img src="https://math.now.sh?inline=%5Cmathbb%20B%20%5Cin%20%5Cmathbb%7BR%7D%5E%7Bm%20%5Ctimes%20n%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> such that</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=i.e.%2C%20%5Cquad%20f%28%5Cmathbb%20x%20%2B%20%5Cmathbb%20%5Cdelta%29%20%3D%20f(%5Cmathbb%20x)%20%2B%20%5Cmathbb%20B%20%5Cmathbb%20%5Cdelta%20%2B%20o(%5C%7C%5Cmathbb%20%5Cdelta%5C%7C_%7B2%7D)%20%5Cquad%20%5Cmathrm%7Bas%7D%20%5Cquad%20%5Cmathbb%20%5Cdelta%20%5Cto%20%5Cmathbb%200%0A" /></p><ul><li>to prove the chain rule for <img src="https://math.now.sh?inline=h%20%5Ccirc%20f%28x%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="figure1.png" alt="figure1"></li></ul><h2 id="Differentiability-–-second-order">Differentiability – second order</h2><p>Consider <img src="https://math.now.sh?inline=f%28x%29%20%3A%20%5Cmathbb%7BR%7D%5E2%20%5Crightarrow%20%5Cmathbb%7BR%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and assure <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is 1st-order differentiable in a small ball around around <img src="https://math.now.sh?inline=x" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="figure2.png" alt="figure2"></p><h2 id="Taylor’s-theorem">Taylor’s theorem</h2><p>Vector version: consider <img src="https://math.now.sh?inline=f%28x%29%20%3A%20%5Cmathbb%7BR%7D%5E2%20%5Crightarrow%20%5Cmathbb%7BR%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br><img src="figure3.png" alt="figure3"><br>Gradient always the same form as the variable. In matrix version, we replace L2 norm with frobenius form, which is a generlization of L2 norm in matrix space. The difference of second order and first order is that second-order has a extra Hessian.</p><p><img src="figure4.png" alt="figure4"></p><p>before: <strong>gradient, Hessian</strong> <img src="https://math.now.sh?inline=%5Crightarrow" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> <strong>Taylor Espansion</strong><br>now: <strong>Taylor Espansion</strong> <img src="https://math.now.sh?inline=%5Crightarrow" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> <strong>gradient, Hessian</strong></p><h2 id="Taylor-approximation-–-asymptotic-uniqueness">Taylor approximation – asymptotic uniqueness</h2><p><img src="figure5.png" alt="figure5"></p><h2 id="Directional-derivatives-and-curvatures">Directional derivatives and curvatures</h2><p>Consider <img src="https://math.now.sh?inline=f%28x%29%20%3A%20%5Cmathbb%7BR%7D%5En%20%5Crightarrow%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li>directional derivative: <img src="https://math.now.sh?inline=D_vf%28x%29%3D%5Cfrac%7Bd%7D%7Bdt%7Df(x%2Btv)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li>When f is 1-st order differentiable at x</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=D_vf%28x%29%20%3D%20%5Clangle%20%5Cnabla%20f(x)%2C%20v%20%5Crangle%0A" /></p><ul><li>Now <img src="https://math.now.sh?inline=D_vf%28x%29%20%3A%20%5Cmathbb%7BR%7D%5En%20%5Crightarrow%20%5Cmathbb%7BR%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what is <img src="https://math.now.sh?inline=D_u%28D_vf%29(x)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>?</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=D_u%28D_vf%29(x)%3D%5Clangle%20u%2C%20%5Cnabla%20%5E2%20f(x)%20v%20%5Crangle%0A" /></p><ul><li>When <img src="https://math.now.sh?inline=u%3Dv" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>,</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=D_u%28D_uf%29(x)%3D%5Clangle%20u%2C%20%5Cnabla%20%5E2%20f(x)%20u%20%5Crangle%20%3D%20%5Cfrac%7Bd%5E2%7D%7Bdt%5E2%7Df(x%2Btu)%0A" /></p><p><img src="figure6.png" alt="figure6"></p><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Taylor&#39;s Theorem </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Mining: Bayesian Classifiers</title>
      <link href="/2020/09/29/Data-Mining-Bayesian-Classifiers/"/>
      <url>/2020/09/29/Data-Mining-Bayesian-Classifiers/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><h1>Bayesian Classifiers</h1><p>Let’s recall what bayes theorem is from Intro to Stat.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=P%28Y%20%7C%20X%29%20%3D%20%5Cfrac%7BP(X%20%7C%20Y)P(Y)%7D%7BP(X)%7D%0A" /></p><h2 id="Using-bayes-theorem-for-classification">Using bayes theorem for classification</h2><p><img src="figure1.png" alt="figure1"></p><p>If each attribute <img src="https://math.now.sh?inline=X_d" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is independent while being given a class attribute <img src="https://math.now.sh?inline=Y_j" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, we can have:</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=P%28X_1%2CX_2%2C...%2CX_d%7CY_j%29%3DP(X_1%7CY_j)P(X_2%7CY_j)...P(X_d%7CY_j)%0A" /></p><p>For instance:<br><img src="figure2.png" alt="figure2"></p><h3 id="Estimate-probabilities-from-data">Estimate probabilities from data</h3><p><img src="figure4.png" alt="figure4"><br>While considering binary values are easy by counting, let’s look at what should we do with continues data.<br><img src="figure3.png" alt="figure3"></p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=P%28X_i%7CY_j%29%3D%5Cfrac%7B1%7D%7B%5Csqrt%7B2%20%5Cpi%20%5Csigma_%7Bij%7D%5E2%7D%7De%5E-%5Cfrac%7B(X_i-%20%5Cmu_%7Bij%7D)%5E2%7D%7B2%20%5Csigma_%7Bij%7D%5E2%7D%0A" /></p><p>Still the sample dataset above, let’s apply this naive bayer classifier.</p><ul><li>given a test data point<br><img src="figure5.png" alt="figure5"></li><li>follow a decision tree<br><img src="figure6.png" alt="figure6"></li></ul><h3 id="Issue-with-naive-bayes-classifier">Issue with naive bayes classifier</h3><ol><li>If the test data point has missing attribute, we might have the possibility to identify one class to be 0.</li><li>If there is a missing data, we might not be able to classify as following:<br><img src="figure7.png" alt="figure7"></li></ol><p>Therefore, we want to use other estimates of conditional probabilities than simple fraction.</p><p>Original: <img src="https://math.now.sh?inline=P%28X_i%20%3D%20c%20%7C%20y%29%20%3D%20%5Cfrac%7Bn_c%7D%7Bn%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li><img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of training instances belonging to class y</li><li><img src="https://math.now.sh?inline=n_c" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of instances with <img src="https://math.now.sh?inline=X_i%20%3D%20c" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and <img src="https://math.now.sh?inline=Y%20%3D%20y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/><br>Laplace Estimate: <img src="https://math.now.sh?inline=P%28X_i%20%3D%20c%20%7C%20y%29%20%3D%20%5Cfrac%7Bn_c%20%2B%201%7D%7Bn%20%2B%20v%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=v" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the total number of attribute values that <img src="https://math.now.sh?inline=X_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> can take<br>m - estimate: <img src="https://math.now.sh?inline=P%28X_i%20%3D%20c%20%7C%20y%29%20%3D%20%5Cfrac%7Bn_c%20%2B%20mp%7D%7Bn%20%2B%20m%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li><li><img src="https://math.now.sh?inline=p" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the initial estimate of <img src="https://math.now.sh?inline=P%28X_i%20%3D%20c%20%7C%20y%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> known apriori</li><li><img src="https://math.now.sh?inline=m" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the hyper-parameter for our confidence in <img src="https://math.now.sh?inline=p" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></li></ul><h2 id="Naive-Bayes-Summary">Naive Bayes (Summary)</h2><ul><li>Robust to isolated noise points</li><li>Handle missing values by ignoring the instance during probability estimate calculations</li><li>Robust to irrelevant attributes (because irrelevant attributes will have the similar weights to classified label e.g: 50%, 50%)</li><li><strong>Drawback</strong>: redundant and correlated attributes will violate class condition assumption<ul><li>Use other techniques such as Bayesian Belief Networks (BBN)</li></ul></li></ul><p>A intuitive bad example:<br><img src="figure8.png" alt="figure8"><br>No, we cannot use naive bayes because conditional independence of attributes is violated. For instance, if <img src="https://math.now.sh?inline=x%3D5" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then <img src="https://math.now.sh?inline=y" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> can be either red or blue.</p>]]></content>
      
      
      
        <tags>
            
            <tag> Data Mining </tag>
            
            <tag> Bayesian Classifier </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Visual and Rigorous Proof of Universal Approximation Theorem (UAT)</title>
      <link href="/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/"/>
      <url>/2020/09/27/Visual-and-Rigorous-Proof-of-Universal-Approximation-Theorem-UAT/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><blockquote><p>Gaoxiang: This lecture is scribed by myself and Andrew Walker.</p></blockquote><h1>Why should we trust Neural Networks (NNs)?</h1><p>We will start by looking at the supervised learning. Although today’s NNs are not only for the supervised learning, we will use this embedded illustration from machine learning to give you some ideas.</p><p><img src="general_view_and_nn_view.png" alt="general_view_and_nn_view"><br>As shown above, the only difference between these two views is that we choose a NN architecture instead of selecting a family of functions. The idea behind both views is function approximation, and we want to emphasize more in function approximation to give you a more accurate description of supervised learning.</p><p><img src="figure1.png" alt="figure1"><br>Basically you can think of supervised learning in this way. First of all, we have an underlying true function <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and our data can be generated by <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with dense sampling, which are the blue dots in above. Second, we choose a family of functions <img src="https://math.now.sh?inline=H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. The purpose here is to learn from this family <img src="https://math.now.sh?inline=H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to find a function <img src="https://math.now.sh?inline=f%20%5Cin%20H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> (orange curve) that is close to the ground truth function <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. This is different with the views mentioned earlier. Those views are to fit the data, which is more about the training error. But here if you really find the ground truth function by learning, you will do perfectly well on eliminating test error.</p><p>There are two aspects of this more accurate description. Does our family of functions <img src="https://math.now.sh?inline=H" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> really have the power to find <img src="https://math.now.sh?inline=f_0" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? This is what we called <strong>Approximation Capacity</strong>. Another important aspect to consider is <strong>Optimization &amp; Generalization</strong>, because sometimes even you choose a powerful function class, it does not guarantee that you will find the best <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Since optimization will be covered later in this class, now let us look at the capacity of our family functions.</p><p>Before we look at the capacity of NN, let us clarify some notations.</p><ul><li>k-layer NNs: with k layers of weights (along the deepest path)</li><li>k-hidden-layer NNs: with k hidden layers of nodes</li></ul><p><img src="figure2.png" alt="figure2"><br>Now let us think of a single-output (i.e., <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cmapsto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) problem, and we can start with one neuron. It’s basically summing up all input with weights, add a threshold/offset, and pass through a non-linear function <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> which is called the activation function <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. As <img src="https://math.now.sh?inline=%5Cleft%5C%7B%5Cmathbf%20x%20%5Cmapsto%20%5Csigma%28%5Cmathbf%20w%5E%5Cintercal%20%5Cmathbf%20x%20%2B%20b%29%20%5Cright%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> shown, the output that a single neuron can represent largely depends on what kind of activation function <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> we have. If we choose an identity function, it will turn out to be linear, which is not powerful. If we choose a sign function like perceptron, which is a 0/1 function with hyperplane threshold, it has some constrain as well.</p><p><img src="figure3.png" alt="figure3"><br>For instance, if we have 1s on 1-quadrant and 3-quadrant, and 0s on 2-quadrant and 4-quadrant, we cannot draw a line to classify these two classes. Even if we choose sigmoid function <img src="https://math.now.sh?inline=%5Cleft%5C%7B%5Cmathbb%20x%20%5Cmapsto%20%5Cfrac%7B1%7D%7B1%2B%20e%5E%7B-%5Cleft%28%20%5Cmathbb%20w%5E%5Cintercal%20%5Cmathbb%20x%20%2B%20b%20%5Cright%29%7D%7D%20%5Cright%5C%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and ReLU, we still cannot solve the quadrants’ example mentioned earlier, because all of the functions above are monotonic in a certain direction (as shown in above), when the ground truth function, that we try to get close to, is not monotonic.</p><p><img src="figure4.png" alt="figure4"><br>Instead of trying to think of a very complicated <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what if we add more layers like <img src="https://math.now.sh?inline=%5Csigma%5Cleft%28%20%5Cmathbb%20w_L%5E%5Cintercal%20%5Cleft(%20%5Cmathbb%20W_%7BL-1%7D%20%20%20%5Cleft(%20%5Cdots%20%20%5Cleft(%20%5Cmathbb%20W_1%20%5Cmathbb%20x%20%2B%20%5Cmathbb%20b_1%20%5Cright%29%20%2B%20%5Cdots%20%5Cright)%20%20%5Cmathbb%20b_%7BL-1%7D%20%20%20%20%5Cright)%20%20%2B%20b_L%20%5Cright)" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>? Adding depth alone is not going to help because it’s multiplying weights repeatedly, and composition of linear operation will still be linear. Therefore, we want to try not only adding layers but also adding nonlinearity into NNs. Surpassingly, this turns out to be really powerful. This leads to the fundamental belief of DNNs – <strong>Universal Approximation Theorem (UAT)</strong>. This theorem states:<br><strong>The 2-layer network can approximate arbitrary continuous functions arbitrarily well, provided that the hidden layer is sufficiently wide.</strong></p><h1>Why should UAT hold?</h1><p><img src="1d.png" alt="1d"><br>The live demo is from <a href="http://neuralnetworksanddeeplearning.com/chap4.html">http://neuralnetworksanddeeplearning.com/chap4.html</a>.<br>Let us start with a single-input-single-output function <img src="https://math.now.sh?inline=%5Cmathbb%20R%20%5Cto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> using sigmoid <img src="https://math.now.sh?inline=%5Csigma%20%3D%20%5Cfrac%7B1%7D%7B1%2B%20e%5E%7B-%5Cleft%28%20%5Cmathbb%20w%5E%5Cintercal%20%5Cmathbb%20x%20%2B%20b%20%5Cright%29%7D%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, whose graph is typically like (a). If we increase the value of <img src="https://math.now.sh?inline=w" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> significantly, we will get a function which is almost the same as step function, as illustrated in (b). Next, if we change the value of <img src="https://math.now.sh?inline=b" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what we’re doing is moving the graph horizontally like ©. Now let us consider two neurons summing up in (d), which is similar to adding two step functions together. More interestingly, if we change the weight of <img src="https://math.now.sh?inline=w_2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> to the opposite of <img src="https://math.now.sh?inline=w_1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, we will get a bump function in (e). Once we take more neurons into account, we will end up with lots of consecutive bumps in (f).</p><p><img src="figure5.png" alt="figure5"><br>This is really similar to Riemann Sum while defining an integral, where you can draw a smooth curve passing through upper bound’s midpoint of the bump (Midpoint Rule) or the top-left corner of the bump (Trapezoidal Rule). Therefore, this 1-hidden layer NN is powerful enough to approximate many non-linear functions if we want to expend the number of neurons as many as we need. Now the question is how about high-dimensional?</p><p><img src="2d.png" alt="2d"><br>The idea is similar in high dimensions. This is a two-inputs-one-output function <img src="https://math.now.sh?inline=%5Cmathbb%20R%5E2%20%5Cto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> using sigmoid. First of all, we turn off the weight in one direction, and the graph just looks like sigmoid in (1). If we again increase the weight sharply, we will get a step function in (2). Now let us turn on weight for another direction, and repeat the previous steps. What we get is is a bump function (two step functions in two orthogonal directions) in (3). Next, if we add more neurons to each direction, then there will be summing up of step functions in each direction, which will generally lead to summing up of bump functions in (4). We observe that if the height of a bump is <img src="https://math.now.sh?inline=h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, then in (4) the highest bump is in height <img src="https://math.now.sh?inline=2h" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Having comparing to the 1D case mentioned earlier, we want to get only the highest bump, which we call a tower in (5), by applying some offsets/cut-off positions. At this point, if we double the neurons in the hidden layer corresponding to each input, we’re able to get two towers. I believe you will get the idea at this point. More neurons in the hidden layers, more towers we can construct.</p><p><img src="figure67.png" alt="figure67"><br>As shown in the left above, I believe you’re convinced that with 1 hidden layer, we can construct many towers (in this case, square towers as inputs are 2D), to approximate any 2D functions arbitrarily well. This is also what we called <strong>Shallow Network Networks</strong>, which is NN with 1 hidden layer. The example above in based on 2D input <img src="https://math.now.sh?inline=%5Cmathbb%20R%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, what if we want to have high-dimensional input <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. Then we don’t have to be as rigid as we were in only x and y directions to construct many square towers. As the input space increases, we could have had more cuts on our square towers then it will be closer and closer to many circle towers. At this point, you might ask what if the output space is also high-dimensional such as <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cto%20%5Cmathbb%20R%5Em" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> functions. The answer is we can approximate each <img src="https://math.now.sh?inline=%5Cmathbb%20R%5En%20%5Cto%20%5Cmathbb%20R" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> separately and then glue them together. I believe you’re convinced that a shallow NN or a 2-layer NN is already powerful enough, but one constrain obviously is that we need lots of neurons if we only have 1 hidden layer. Later we will introduce Deep Neural Networks (DNNs) and why we want to add one more hidden layer.</p><h1>UAT in rigorous form</h1><p>The Universal Approximation Theorem is a fundamental theorem underpinning the power behind the neural network’s prediction ability. The first formulation of the UAT (that has now developed into many variations) was developed in the late 1980’s. This section includes the mathematical discussion of the UAT.</p><p><img src="theorem01.png" alt="theorem01"><br>Breaking this theorem down, we see <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is an activation function. The variable <img src="https://math.now.sh?inline=%5Cvarepsilon" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the arbitrary level of precision we would like to reach between our target function <img src="https://math.now.sh?inline=f" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> and our neural network function <img src="https://math.now.sh?inline=F" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. This theorem states that within the constraints, a single layer neural network with a large enough number of nodes can fit with arbitrarily small error any target function. The visual proof in the last section was intuitive, but the rigorous proof requires functional analysis and quadratic theory. We will not cover the rigorous proof in this course.</p><p>Notice the key limitations in the original formulation of the UAT — the target function must lie on the hypercube, the activation function must be non-constant, bounded, and continuous, the target function must be continuous. These statements have been somewhat addressed since the original formulation. The target function may lie on a space other than the hypercube; it just has to be compact (bounded and closed). A commonly-used activation function (ReLU) is not bounded, although a composition of ReLUs is. The target function needs to be continuous, although the classification problem is by definition discontinuous. However, the discontinuous classification can be approximated arbitrarily well by a very steep sigmoid function, for example.</p><p><img src="diff.png" alt="diff"><br>In fact, the UAT has been found to apply for <img src="https://math.now.sh?inline=%5Csigma" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> as general as the set of all non-polynomial functions. [LLPS93]</p><h1>From shallow to deep Neural Networks</h1><p>The UAT says that a shallow, single-layer neural network can hit arbitrarily accurate levels of prediction. So why do we use multi-layer (or deep) neural networks? The UAT says the number of nodes is an integer N, but places no upper limit on N.</p><p>The value of N blows up very quickly for higher-dimensionality datasets. To show this, we return to our visual proof terminology. Assume our target function is 1-Lipschitz (essentially, it does not ever have a slope greater than 1 or -1. Formally: <img src="https://math.now.sh?inline=%5Cleft%7C%20f%28x%29%20-%20f(y)%20%5Cright%7C%20%5Cle%20%5Cleft%7C%20x%20-%20y%20%5Cright%7C%2C%20%5Cforall%5C%3B%20x%2C%20y%20%5Cin%20%5Cmathbb%7BR%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) and has a domain in <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5E1" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. With this in mind, to achieve <img src="https://math.now.sh?inline=%5Cvarepsilon" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> accuracy, we need at most  <img src="https://math.now.sh?inline=%5Cfrac%7B1%7D%7B%5Cvarepsilon%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> bumps per unit length along the domain. For a 2D target function, we need <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28%5Cvarepsilon%5E%7B-2%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>. In fact, in general, for a target function with domain n-Dimensions, we need <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28%5Cvarepsilon%5E%7B-n%7D%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> bumps.</p><p>As you can see, this exponential growth makes single layer neural networks infeasible for higher dimension problems. The value of deep NNs is that they can provide much better computing power. In 2017, it was shown that DNNs can have the number of nodes <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28n%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> while 2-layer NNs need <img src="https://math.now.sh?inline=%5Cmathcal%7BO%7D%28a%5En%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> for Boolean functions in domain <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><p>To show this, we define two classes of functions —<br><img src="two_class_fun.png" alt="two_class_fun"></p><p>The 2017 theorems:<br><img src="thm1.png" alt="thm1"><br><img src="thm2.png" alt="thm2"><br>These theorems essentially show (within the constraints) that shallow networks are exponential with respect to domain dimension and that deep networks are linear with respect to domain dimension.</p><p>Since we have covered so many variations on the UAT, you may be wondering, what is the most general variation of the UAT so far?<br><img src="pro2.png" alt="pro2"></p><p>This activation function must be continuous and not a polynomial. Then, given a target continuous function, you can find a shallow neural network that approximates the target function arbitrarily well.</p><p>However, deeper is not always better. Theorems [LPW+17][KL19]  have shown that to maintain the UAT property of arbitrary approximation power, deep networks need around <img src="https://math.now.sh?inline=n" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> nodes per hidden layer in <img src="https://math.now.sh?inline=%5Cmathbb%7BR%7D%5En" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><p><img src="thm13.png" alt="thm13"><br>However, this is still an active area of research and in practice, the most optimal network is often forgone for a less theoretically optimal but still practically better option.</p><h1>Conclusion</h1><p>While designing your network, do not try to use these theorems and mathematical results to advise your design. Deep Learning is a very new and volatile field and it is often the case that researchers develop new architectures without knowing why they work, and later on mathematicians try to prove why a certain architecture is optimal.<br>The reason we covered the UAT is so we get an understanding of why we can just take a neural network to approximate some function. If we have no other understanding of the target function, maybe a neural network would be a good choice.</p><h1>Reference</h1><p><img src="reference.png" alt="reference"></p>]]></content>
      
      
      
        <tags>
            
            <tag> Study Note </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Neural Network </tag>
            
            <tag> Theory </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Data Mining: Classification with Decision Tree</title>
      <link href="/2020/09/25/Data-Mining-Classification-with-Decision-Tree/"/>
      <url>/2020/09/25/Data-Mining-Classification-with-Decision-Tree/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 5523) is being offered by <a href="https://www-users.cs.umn.edu/~kumar001/">Prof. Vipin Kumar</a> at the University of Minnesota in Fall 2020.</p></blockquote><p>Base Classifiers</p><ul><li>Decision Tree based Methods</li><li>Rule-based Methods</li><li>Nearest-neighbor</li><li>Neural Networks, Deep Neural Nets</li><li>Naive Bayes and Bayesian Belief Networks</li><li>Support Vector Machines</li></ul><p>Ensemble Classifiers</p><ul><li>Boosting, Bagging, Random Forests</li></ul><h1>Decision Tree</h1><h2 id="Decision-Tree-Induction-Algorithms">Decision Tree Induction Algorithms</h2><ul><li>Hunt’s Algorithm (one of the earliest)</li><li>CART</li><li>ID3, C4.5</li><li>SLIQ,SPRINT</li></ul><h2 id="Hunt’s-Algorithm">Hunt’s Algorithm</h2><p><img src="figure1a.png" alt="figure1a"><br>As you may see in the picture, a Hunt’s Algorithm in decision tree is to define a condition to split data into two or more branches when a node is not pure (involving both labeled classes), until the leaf node has all the data with the same class. Now with this model, we might ask how do we determine the best spiltting. Therefore, some evaluation metrics may come into place.</p><h2 id="Measures-of-Node-Impurity">Measures of Node Impurity</h2><p>First, we have to know what is node impurity. If a node has 10 data points in total, and 5 of them are labeled class 1 and 5 of them are labeled class 0, then it has a high degree of impurity. But if a node has 9 data points labeled class 1 and only 1 data point labeled class 0, then we say it has a low degree of impurity. People have designed methods to measure node impurity. There are three most popular ones:</p><ul><li>Gini Index</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Gini%20%5C%2C%20Index%3D1-%20%5Csum_%7Bi%3D0%7D%5E%7Bc-1%7Dp_i%28t%29%5E2%0A" /></p><p>where <img src="https://math.now.sh?inline=p%5Ei%28t%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the frequency of class <img src="https://math.now.sh?inline=i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> at node <img src="https://math.now.sh?inline=t" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>, and <img src="https://math.now.sh?inline=c" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the total number of classes</p><pre><code>- It has a minimum of 0 when all records belong to one class, which is the most beneficial situation for classification.- It has a maximum of $1 - \frac&#123;1&#125;&#123;c&#125;$ when records are equally distributed among all classes, which is the least beneficial situation.- It's used in decision tree algorithems such as CART, SLIQ, SPRINT </code></pre><ul><li>Entropy</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Entropy%3D%20-%20%5Csum_%7Bi%3D0%7D%5E%7Bc-1%7Dp_i%28t%29log_2p_i(t)%0A" /></p><pre><code>- It has a minimum of 0 and a maximum of $log_2c$.- Entropy based computations are quite similiar to the GINI index computations.</code></pre><ul><li>Misclassification Error</li></ul><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Classification%20%5C%2C%20Error%20%3D%201%20-%20max%5Bp_i%28t%29%5D%0A" /></p><h3 id="How-to-find-the-best-split">How to find the best split?</h3><ol><li>Compute Impurity Measure (<img src="https://math.now.sh?inline=P" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) before splitting</li><li>Compute Impurity Measure (<img src="https://math.now.sh?inline=M" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>) after splitting</li><li>Choose the attribute test condition that produces the highest gain</li></ol><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Gain%20%3D%20P%20-%20M%0A" /></p><p>Particularlly, when we say information gain, it implies the Gain of Entropy method.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Information%20%5C%2C%20Gain%20%3D%20Entropy%28parent%29%20-%20%5Csum_%7Bi%3D1%7Dk%20%5Cfrac%7Bn_i%7D%7Bn%7DEntropy(i)%0A" /></p><p>where Parent Node <img src="https://math.now.sh?inline=p" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is split into <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> partitions (children); <img src="https://math.now.sh?inline=n_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is number of records in child node <img src="https://math.now.sh?inline=i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>.</p><p>Let’s look at a simple example.<br><img src="figure2a.png" alt="figure2a"></p><p>I think this image is straighforward. At this point we may naturally think of the more partitions we have, the more likely we’ll end up with a lower degree of impurity, but does it mean the more partitions the better? No, it’s not always meaningful to do so. For instance, if we classify each customers by ID, it doesn’t do anything or give us any useful information, so we want to have a measure that will penalize too many successors.</p><h4 id="Gain-Ratio-for-Entropy">Gain Ratio (for Entropy)</h4><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=Gain%20%5C%2C%20Ratio%20%3D%20%5Cfrac%7BGain_split%7D%7BSplit%20%5C%2C%20Info%7D%20%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%2C%5C%20Split%20%5C%2C%20Info%20%3D%20-%5Csum_%7Bi%3D1%7D%5Ek%20%5Cfrac%7Bn_i%7D%7Bn%7Dlog_2%5Cfrac%7Bn_i%7D%7Bn%7D%0A" /></p><p>Where parent node <img src="https://math.now.sh?inline=p" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is split into <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> partitions, and <img src="https://math.now.sh?inline=n_i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> is the number of records in child node <img src="https://math.now.sh?inline=i" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/></p><ul><li>Split Info happends to be larget if too many successors, this is a way to prefer small number of successors.</li><li>This is degisned to overcome the disadvantage of information gain</li><li>Used in C4.5 algorithm</li></ul><p><img src="figure3a.png" alt="figure3a"><br>One of the senarios of applying split info may be the image above. We see that the left most split and the right most split has a similiar value of Gini Index, but the right most one has a much lower split info so that we would go with the lower successors split.</p><h2 id="The-Pros-and-Cons-of-Decision-Tree-Based-Classification">The Pros and Cons of Decision Tree Based Classification</h2><p>Advantages:</p><ul><li>Relativelty inexpensive to construct</li><li>Extremely fast at classifying unkown records</li><li>Easy to interpret for small-sized trees</li><li>Robust to noise (especially when methods to avoid overfitting are employed)</li><li>Can easily handle redundant or irrelevant attributes (unless the attributes are interacting)</li></ul><p>Disadvantages:</p><ul><li>Due to the greedy nature of splitting criterion, interacting attributes (that can distinguish between classes together but not individually) may be passed over in favor of other attribtues that are less discriminating</li><li>Each decision boundary involves only a single attribute</li></ul><h2 id="Classification-Errors">Classification Errors</h2><ul><li>Training errors</li><li>Test errors</li><li>Generalization errors: expected error of a model over random selection of records from same distribution</li></ul><p><img src="figure1.png" alt="figure1"></p><p>Let’s look at this example above. The positive class is from a gaussian centered at (10,10) with 400 noisy instances added.</p><p><img src="figure2.png" alt="figure2"></p><p>If we only use 10% of dataset to train a decision tree, it will end up with a tree with 4 nodes as the picture above. While we increase the size of training dataset, the training error continues to goes down slowly, and we might have a decision tree with more nodes. But doesn’t it really improve our model’s performance?</p><p><img src="figure3.png" alt="figure3"></p><p>Actually not! As the model becomes more and more complex with larger training set, the test error starts to go up. This is what we called <strong>overfitting</strong>.</p><ul><li>Underfitting: when model is too simple, both training and test errors are large.</li><li>Overfitting: when model is too complex, training error is small but test error is large.</li></ul><p><img src="figure4.png" alt="figure4"></p><p>What if we increase the size of the model while we have a overfitting model? The anwser is that both the training errors and test error would go down as the image above.</p><p>At this point, let’s summurize the possible reasons for model overfitting.</p><ul><li>Limited training size</li><li>High model complexity: have something to do with multiple comparision procedure</li></ul><h3 id="Notes-on-overfitting">Notes on overfitting</h3><ul><li>Overfitting results in decision trees that are more complex than necessary</li><li>Training errors does not provide a good estimate of how well the tree will perform on previously unseen records</li><li>Need ways for estimating generalization errors</li></ul><h2 id="Model-Selection">Model Selection</h2><p>Purpose: to ensure that model is not overly complex (to avoid overfitting)<br>Goal: to estimate generalization error</p><ul><li>Using validation set</li><li>Incorporating model complexity</li></ul><h3 id="Using-validation-set">Using validation set</h3><ul><li>Diving training data into two parts<ul><li>Training set: use for model building</li><li>Validation set: use for estimating generalization error</li></ul></li><li>Drawback:<ul><li>Less data available for training</li></ul></li></ul><h3 id="Incorporating-model-complexity">Incorporating model complexity</h3><p>Purpose: use some model complexities while building a model with training set.<br>This is to 1) reduce training set error and 2) add penalty to increasing complexity simultaneously.</p><p>Gen.Error(Model) = Train.Error(Model,Train.Data) + <img src="https://math.now.sh?inline=%5Calpha" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> x Complexity(Model)</p><h3 id="Estimating-the-Complexity-of-Decision-Trees">Estimating the Complexity of Decision Trees</h3><p><strong>Pessimistic Error Estimate</strong> of decision tree <img src="https://math.now.sh?inline=T" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> with <img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> leaf nodes.</p><p style="filter: opacity(100%);transform:scale(1.00);text-align:center;"><img src="https://math.now.sh?from=err_%7Bgen%7D%28T%29%20%3D%20err(T)%20%2B%20%5COmega%20%5Ctimes%20%5Cfrac%7Bk%7D%7BN_%7Btrain%7D%7D%0A" /></p><ul><li><img src="https://math.now.sh?inline=err%28T%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: error rate on all training records (number of error divived by the total training examples)</li><li><img src="https://math.now.sh?inline=%5COmega" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: trade-off hyper-parameter (similar to <img src="https://math.now.sh?inline=%5Calpha" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>)<ul><li>relative cost of adding a leaf node</li></ul></li><li><img src="https://math.now.sh?inline=k" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: number of leaf nodes</li><li><img src="https://math.now.sh?inline=N_%7Btrain%7D" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>: total number of training records</li></ul><p>Let’s look at an example:<br><img src="figure5.png" alt="figure5"><br>How to calculate <img src="https://math.now.sh?inline=e%28T_L%29" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/>?<br>For example, if a leaf node has 3 positive and 1 negative, then the negative case is an error case. Applying the same through to all the leaf nodes will give you the total number of error cases. The other parts of this formula is straightforward in the image above.</p><h2 id="Model-selection-for-decision-trees">Model selection for decision trees</h2><h3 id="Pre-Pruning-Early-Stopping-Rule">Pre-Pruning (Early Stopping Rule)</h3><ul><li>Stop the algorithm before it becomes a fully-grown tree</li><li>Typical stopping conditions for a node:<ul><li>stop if all instances belong to the same class</li><li>stop if all the attribute values are the same</li></ul></li><li>More restrictive conditions:<ul><li>stop if number of instances is less than some user-specified threshold</li><li>stop if class distribution of instances are independent of the available features (e.g., using <img src="https://math.now.sh?inline=x%5E2" style="filter: opacity(100%);transform:scale(1.00);text-align:center;display:inline-block;margin: 0;"/> test)</li><li>stop if expanding the current node does not improve impurity measures (e.g., Gini or information gain)</li><li>stop if estimated generalization error falls below certain threshold</li></ul></li></ul><h3 id="Post-pruning">Post-pruning</h3><ul><li>Grow decision tree to its entirety</li><li>Subtree replacement<ul><li>Trim the nodes of the decision tree in a bottom-up fashion</li><li>If generalization error improves after trimming, replace sub-tree by a leaf node</li><li>Class label of leaf node is determined from majority class of instances in the sub-tree.</li></ul></li></ul><h2 id="Model-Evaluation">Model Evaluation</h2><p>Purpose:</p><ul><li>To estimate performance of classifier on previously unseen data (test set)</li></ul><p>Holdout</p><ul><li>Reserve k% for training and (100-k)% for testing</li><li>Random subsampling: repeated holdout</li></ul><p>Cross validation</p><ul><li>Partition data into k disjoint subsets</li><li>k-fold: train on k-1 partitions, test on the remaining one</li><li>Leave-one-out: k = n</li></ul><p>If I only have a small number of dataset, and use too much for test set, then I don’t have enough data for training. I don’t want my model with biases toward how I train my model. What should I do?</p><h3 id="Cross-validation-Example">Cross-validation Example</h3><p><img src="figure6.png" alt="figure6"></p><ul><li>Repeated cross-validation<ul><li>perform cross-validation a number of times</li><li>gives an estimate of the variance of the generalization error</li></ul></li><li>Stratified cross-validation<ul><li>Guarantee the same percentage of class labels in training and test</li><li>Important when classes are imbalanced and the sample is small</li></ul></li><li>Use nested cross-validation approach for model selection and evaluation</li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Data Mining </tag>
            
            <tag> Classifier </tag>
            
            <tag> Decision Tree </tag>
            
            <tag> Gini Index </tag>
            
            <tag> Entropy </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Deep Neural Networks(DNNs) Overview</title>
      <link href="/2020/09/20/Deep-Neural-Networks-DNNs-Overview/"/>
      <url>/2020/09/20/Deep-Neural-Networks-DNNs-Overview/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course (CSCI 8980) is being offered by <a href="https://sunju.org/">Prof. Ju Sun</a> at the University of Minnesota in Fall 2020. Pictures of slides are from the course.</p></blockquote><h1>Why Deep Learning</h1><h2 id="What-is-Deep-Learning-DL">What is Deep Learning (DL)?</h2><h3 id="DL-is-about…">DL is about…</h3><ul><li>Deep Neural Network (DNNs)</li><li><strong>Data</strong> or training DNNs (e.g. images, videos, text sequences)</li><li><strong>Methods</strong> for training DNNs (e.g. AdaGrad, ADAM, RMSProp, Dropout)</li><li><strong>Hardware</strong> platforms for training DNNs (e.g. GPUs, TPUs, FPGAs)</li><li><strong>Software</strong> platforms for training DNNs (e.g., Tensorflow, Pytorch, MXNet)</li><li><strong>Applications!</strong> (e.g. vision, speech, NLP, imaging, physics, mathematics finance)</li></ul><h3 id="DL-leads-to-many-things-…">DL leads to many things …</h3><blockquote><p>Oxford Dictionary </br><br>Revolution: a great change in conditions, ways of working, beliefs, etc. that affects large numbers of people.</p></blockquote><h3 id="Academic-breakthroughs">Academic breakthroughs</h3><ul><li>increasing successful rate in image classification (2012)</li><li>increasing successful rate in speech recognition (2012)</li><li>Go game (2017)</li><li>image generation</li></ul><p><img src="slide5.png" alt="slide5"></p><h2 id="Commercial-breakthroughs">Commercial breakthroughs</h2><ul><li>self-driving vehicles</li><li>smart-home devices</li><li>healthcare</li><li>robotics</li></ul><p>Paper are produced at an <strong>overwhelming</strong> rate. </br><br>Note: <a href="arvis.org">arvis</a> (where people post preprint papers)</p><h1>Why first principles?</h1><ul><li>Tuning and optimizing for a task require basic intuitions</li><li>Historial lesson: model structures in data</li><li>Current challenge: move toward trustworthiness</li><li>Future world: navigate uncertainties</li></ul><h2 id="Structures-are-crucial">Structures are crucial</h2><p><img src="slide14a.png" alt="slide14"></p><h2 id="Toward-trustworthy-AI">Toward trustworthy AI</h2><ul><li>we need to know first principles in order to improve and understand</li><li>Trustworthiness:<ul><li>robustness</li><li>fairness (<em>what if data is primarily from certain population group</em>)</li><li>explainability (<em>what if we make human-level robot but we don’t understand how to make decision</em>)</li><li>transparency</li></ul></li></ul><h2 id="Future-uncertainties">Future uncertainties</h2><ul><li>New types of data (e.g. 6-D tensors)</li><li>New hardware (e.g. better GPU memory)</li><li>New model pipelines (e.g. network of networks, differential programming)</li><li>New applications</li><li>New techniques replacing DL</li></ul><h1>Netruel Networks: Old and New</h1><h2 id="Start-from-Neurons">Start from Neurons</h2><h3 id="Model-of-biological-neurons">Model of biological neurons</h3><p><img src="slide4.png" alt="slide4"></p><h2 id="Shallow-to-DNNs">Shallow to DNNs</h2><h3 id="Artificial-Neurons">Artificial Neurons</h3><p><img src="slide7.png" alt="slide7"><br>ReLU is the most popular activation function nowadays.</p><p><img src="slide8.png" alt="slide8"><br>People play diverse forms of NN but only play with graph without cycles, because we cannot do auto differentiation once we have cycles.</p><h3 id="Supervised-Learning-in-ML">Supervised Learning in ML</h3><p><img src="slide9.png" alt="slide9"></p><h3 id="Supervised-Learning-in-DL">Supervised Learning in DL</h3><p><img src="slide10.png" alt="slide10"><br>Instead of finding a function from a family of functions, we try to find a group of weights (w) and offsets(b) to minimize the average loss.</p><h3 id="Perceptron">Perceptron</h3><p>Def: Perceptron is a single artificial neuron for binary classification.<br><img src="slide12.png" alt="slide12"><br><img src="slide13.png" alt="slide13"><br><img src="slide14.png" alt="slide14"><br><img src="slide16.png" alt="slide16"></p><h3 id="They-are-all-shallow-NNs">They are all (shallow) NNs</h3><ul><li>Linear Regression</li><li>Perceptron and Logistic Regression</li><li>Softmax Regression</li><li>Multilayer Perceptron (feedforward NNs)</li><li>Support Vector Machine (SVM)</li><li>PCA (autoencoder)</li><li>Matrix Factorization</li></ul><h2 id="Some-Background-Knowledge">Some Background Knowledge</h2><h3 id="Turing-Test">Turing Test</h3><p>How we measure whether we achieve human-level AI?<br><img src="slide20.png" alt="slide20"></p><h3 id="Key-ingredients-of-DL">Key ingredients of DL</h3><p><img src="slide26.png" alt="slide26"><br>Suprisingly, we’re still using those computational methods that were invented 25-30 years ago. Nowadays the progress of DL largely depends on improvement of hardware (GPUs), but seldom on new computational methods.</p><p>Question to myself: Are we approaching the third AI winter? Should we focus more on foundamental research instead of picking new applications?</p><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Neural Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>For UMN: How to setup remote enviroment with CSE lab machine via VSCode</title>
      <link href="/2020/09/12/For-UMN-How-to-setup-remote-enviroment-with-CSE-lab-machine-via-VSCode/"/>
      <url>/2020/09/12/For-UMN-How-to-setup-remote-enviroment-with-CSE-lab-machine-via-VSCode/</url>
      
        <content type="html"><![CDATA[<h1>VSCode Setup with CSE Lab Machines on Your Own Computer</h1><h2 id="Demo">Demo</h2><p><img src="Demo.png" alt="Demo"></p><h3 id="Why-should-you-consider-this-setup">Why should you consider this setup?</h3><ul><li>feel like working on CSE Lab Machines literally</li><li>don’t have to install <code>OCaml</code> on your computer because you’re using lab’s <code>OCaml</code></li><li>graphical user interface with <code>OCaml</code> Syntax Highlighting</li><li>faster than <code>vole</code> since it talks to server directly rather than transmitting through web browser</li><li>can be used on <code>Linux</code>, <code>MacOS</code> and <code>Windows</code> because they all have <code>VSCode</code></li><li>file transfer: drag you local file into CSE lab machine</li></ul><h2 id="Tutorial">Tutorial</h2><p>This tutorial can help you to set up your remote enviroment graphically with CSE lab machines on your own computer.</p><hr><ol><li><p>Open <code>VSCode</code>, go to extension on the left nevigation bar and search <code>ssh</code><br><img src="step1.png" alt="step1"></p></li><li><p>Install <code>REMOTE - SSH</code>, click <code>SSH extension</code> icon on the left nevigation bar and click <code>connect</code><br><img src="step2.png" alt="step2"></p></li><li><p>On the pop-up command window, type in <code>ssh &lt;x500&gt;@&lt;cse lab machines&gt; -A</code>.<br>For instance, I will use:</p><ul><li><code>ssh luo00042@atlas.cselabs.umn.edu -A</code> ATLAS is a server machine which has 256G RAM! But sometimes if a student is running heavy-duty task on ATLAS, you may want to use another machine.</li><li><code>ssh luo00042@csel-kh4250-03.cselabs.umn.edu -A</code></li></ul></li></ol><p><img src="step3.png" alt="step3"></p><p><strong>Note:</strong> A list of CSE lab UNIX machines that you can remotely work on, you can find them <a href="https://cseit.umn.edu/computer-classrooms/cse-labs-unix-machine-listings">here</a>.</p><p><strong>Remember:</strong> Replace the <code>x500</code> with yours, not mine; and make sure to include the <code>-A</code> flag, otherwise you have to use VPN or be under university wifi to connect.</p><ol start="4"><li><p>Click to update ssh configuration so you don’t have to type the long ssh command every time.<br><img src="step4.png" alt="step4"></p></li><li><p>When it’s done, there will be a SSH target on the left. Click <code>connect</code><br><img src="step5.png" alt="step5"></p></li><li><p>A new window will pop up and there will be prompt that you need to enter your <code>x500</code> password.<br><img src="step6.png" alt="step6"></p></li><li><p>You are in CSE lab machine via SSH connection! Click <code>Open Folder</code>. Doesn’t it look familiar to you? That’s your CSE lab folder! Navigate to your own repo and click <code>OK</code><br><img src="step7.png" alt="step7"></p></li><li><p>That’s it! You can open a terminal within <code>VSCode</code>, and it will be under SSH connection as well!<br><img src="step8.png" alt="step8"></p></li></ol><h3 id="OCaml-Syntax-Highlighting-Enable">OCaml Syntax Highlighting Enable</h3><ol start="9"><li><p>This is how it looks before enabling <code>OCaml</code> syntax highlighting<br><img src="step9.png" alt="step9"></p></li><li><p>Go to extension on the left nevigation bar again and search <code>OCaml</code>. Install it, and reload the window.<br><img src="step10.png" alt="step10"></p></li><li><p>Now you <code>OCaml</code> code should be highlighted accoridng to the syntax.<br><img src="step11.png" alt="step11"></p></li></ol><p>Now you can edit your code <strong>on lab machine</strong>, save your code <strong>on lab machine</strong>, and test your code with terminal <strong>on lab machine</strong>!</p><p><strong>Editor Note:</strong> While it’s easier to edit your code with a nice-looking IDE, it’s still good to pick up tools like emacs and vim. I hope you find this tutorial helpful to you!</p>]]></content>
      
      
      
        <tags>
            
            <tag> How-to </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Robotics: Perception study note week 1</title>
      <link href="/2020/09/06/Robotics-Perception-study-note-week-1/"/>
      <url>/2020/09/06/Robotics-Perception-study-note-week-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>Acknowledgement: This course is being offered on <a href="https://www.coursera.org/learn/robotics-perception/">Coursera</a> for free to audit.</p></blockquote><blockquote><p>Gaoxiang: Due to the characteristic of this course, there maybe lots of pictures.</p></blockquote><h1>Overview</h1><ul><li>Week 1: Geometry of Projection</li><li>Week 2: Augmented Reality &amp; Visual Metrology</li><li>Week 3 &amp; 4: Where am I?</li></ul><hr><h1>Week 1</h1><p><img src="camera_types.png" alt="camera_type"><br>There are panoromic cameras, stereos camera, laser scanner and Kinect.</p><h1>How does a thin lens work?</h1><p><img src="thin_lens.png" alt="thin_lens"></p><ul><li>Rays parallet to the optical axis meet the focus after leaving the lens.</li><li>Rays through center of the lens do not change direction.</li></ul><p><img src="thin_lens_equation.png" alt="equation"></p><h1>What happens when we move the image plane?</h1><p>moving image plane = focusing (practically)<br><img src="move_image_plane.png" alt="plane_move"><br>The read line segment is what makes image blur.</p><h1>Perspective projection: size of object image</h1><p><img src="perspective_projection.png" alt="perspective_projection"></p><ul><li>This is easily proved by similarity of triangle.</li><li>A point object of the same size coming closer results on a larger image.</li><li>A point moving on the same ray does not change its image.</li></ul><hr><h1>Single View Geometry</h1><h2 id="Two-facts">Two facts:</h2><ul><li>When we take a pictuer, the 3D location has become a 2D plane. We have lost the third dimension in this process.</li><li>It matters how are oritented to the world when we take a picture.</li></ul><h2 id="Ideas-I-Measurements-on-planes">Ideas I: Measurements on planes</h2><p>We can unwarp then measutre, which means to make parallel lines stay parallel and perpendicular angle stay perpendicular.<br><img src="measure_planes.png" alt="measure_planes"></p><h2 id="Ideas-II-Vanishing-points">Ideas II: Vanishing points</h2><p><img src="vanishing_point.png" alt="vanishing_point"><br>The roof and ground are parellel in real world (blue lines), and they converge to a point if we draw them. That’s the vanishing point.</p><p><img src="imaging_vanishing_point.png" alt="imaging_vanishing_point"><br>As the blue dot moves further away, the projection point on the image plane will be closer and closer to the vanishing point.</p><hr><h1>More on Perspective Projection</h1><h2 id="Bi-perspectograph">Bi-perspectograph</h2><p><img src="prove_bi_perspectograph.png" alt="prove_bi_perspectograph"><br>Take some time to understand this proof. As the point P* on image plane moves, we’re able to draw the projection curve on the ground plane with point P’.</p><h2 id="Two-parameters">Two parameters:</h2><ul><li>Height of camera (line O*S)<ul><li>If we project a circle from image plane, the lower the camera is, the more squeezed is the ellipse.</li></ul></li><li>Distance of projection center from image plane (distance between two parallel lines LM and OS); also known as focal length<ul><li>When it moves, it <strong>only change the size not the shape</strong>.</li></ul></li></ul><hr><h1>Glimpse on Vanishing Points</h1><p><img src="properties_vanishing_point.png" alt="properties_vanishing_point"><br>The three properties of vanishing points are on the image above.</p><h2 id="Vanishing-Lines">Vanishing Lines</h2><p><img src="vanishing_lines.png" alt="vanishing_lines"><br>Horizon is a set of all directions to the infinity.</p><p>In other words, vanishing lines (horizon) is the intersection of image plane and the ground plane that is lifted up.<br><img src="compute_vanishing_lines.png" alt="compute_vanishing_lines"></p><h2 id="How-to-measure-height">How to measure height?</h2><p>If we draw a line of a walking person’s feet (ground plane), and lift up this line to the person’s head, these two lines are parellel in the third-person perspective. But in my perspective, these two lines will intersect to a vanishing point on horizon, which is the same height of camera.<br><img src="comparing_heights.png" alt="comparsing_heights"><br>According to this rule, we need a referenc2e object with known length then we can measure the heights in the scene.<br><img src="measuring_height.png" alt="measuring_height"><br>Connect the bottom of the object and the reference on the groud plane, it will intersect with horizon on a vanishing point. Then connect the vanishing point and the head of the object back to the reference. Now you have a ratio between object and reference so that you can measure the height.</p><hr><h1>Homogeneous Coordinates</h1><p>Before we move on to next section, I think it’s neccesary to know what is homogeneous coordinates and why we use it. This part is from the course video but my understandings.</p><h2 id="What-is-homogeneous-coordinates">What is homogeneous coordinates?</h2><p>It represents coordinates in 2 dimensions with a 3-vector.</p><ul><li>From euclidean to homogeneous<ul><li>add third coordinate as 1<br>(2,3)’ – (2,3,1)’</li><li>add third coordinate as 0 to express infinity<br>(2,3)’ – (2,3,0)’</li></ul></li><li>From homogeneous to euclidean<ul><li>divived by value of third coordinate<br>(4,5,1)’ – (4,5)<br>(8,6,3)’ – (8/3,6/3)</li><li>divived by 0 also proves that the point is in infinity</li></ul></li></ul><h2 id="Why-we-use-homogeneous-coordinates">Why we use homogeneous coordinates?</h2><ul><li>x = cx (x!=0)<br>e.g: (2,4,1)’ == (4,8,2)</li><li>it can represent point at infinity by the form (x,y,0)</li></ul><hr><h1>Perspective Projection</h1><h2 id="How-to-represent-a-point">How to represent a point?</h2><p><img src="projective_plane.png" alt="projective_plane"><br>The point in the image plane can be considered as a ray pointing to infinity.<br><img src="point.png" alt="point"><br>Since we consider a point on place as a ray going through the point and penetrating to the space, we can represent it as a vector using homogeneous coordinates.</p><h2 id="How-to-represent-a-line">How to represent a line?</h2><p><img src="lines.png" alt="lines"><br><strong>Important:</strong> a line is a plane of rays through origin.<br>(a,b,c) is a normal vector to the plane.<br><img src="line_representation.png" alt="line_representation"><br>We can also represent the line with polar coordinate representation.</p><h2 id="Line-passing-through-two-points">Line passing through two points</h2><p><img src="line_two_points.png" alt="line_two_points"><br>For every two points on the plane, there are two rays passing through them respectively from origin. It’s known that two lines define a plane, and sometimes we describe this plane by using it’s normal line.</p><p><img src="calculate_line.png" alt="calculate_line"><br>This is a sample MATLAB code to calculate the line.</p><pre class=" language-language-matlab"><code class="language-language-matlab">function I = get_line_by_two_points(x,y)x1 = [x(1), y(1), 1]';x2 = [x(2), y(2), 1]';I = cross(x1,x2);I = I / sqrt(I(1)*I(1) + I(2)*I(2));</code></pre><h2 id="How-to-find-the-intersection-of-two-lines">How to find the intersection of two lines?</h2><p><img src="intersection_of_lines.png" alt="intersection_of_lines"></p><pre class=" language-language-matlab"><code class="language-language-matlab">function x0 = get_point_by_two_line(I, II)x0 = cross(I,II);x0 = [x0(1)/x0(3); x0(2)/x0(3)];</code></pre><hr><h1>Point-Line Duality</h1><p><img src="duality.png" alt="duality"><br>This slide is to realize the duality of point and line in projective space. If given any formula, we can switch the meanings of poitns and lines to get another formula.</p><p><strong>Good to think:</strong> Now we know that take the cross product of two lines we get a point(ray) on the image plane, but what if the point we get has the form of (x,y,0). If we convert from 3D to 2D, either x or y divived by 0 we will get a point in infinity.<br><img src="point_at_infinity.png" alt="point_at_infinity"></p><p>That’s the point at infinity, what is line at infinity. We have to find a line that every points with form (x,y,0) will pass through it. So, algebraically:<br><img src="line_at_infinity.png" alt="line_at_infinity"></p><h2 id="Ideal-Points-and-Lines">Ideal Points and Lines</h2><p><img src="ideal_point_and_line.png" alt="ideal_point_and_line"></p><hr><h1>Rotations and Translations</h1><h2 id="Camera-Coordinates-World-Coordinates">Camera Coordinates &amp; World Coordinates</h2><p><img src="rgb_xyz.png" alt="rgb_xyz"><br>Convention: rgb to xyz</p><h2 id="What-is-the-geometric-meaning-of-translation">What is the geometric meaning of translation?</h2><p><img src="translation.png" alt="translation"><br>Mathematically, if the world coordinates of point P is (0,0,0), then the camera coordinates of point P is the vector from camera origin to world origin as shown on picture above.</p><h2 id="What-is-the-geometric-meaning-of-rotation">What is the geometric meaning of rotation?</h2><p><img src="rotation.png" alt="rotation"></p><ul><li>r1 is the x-axis of the world with repect to the camera as red</li><li>r2 is the y-axis of the world with repect to the camera as green</li><li>r3 is the z-axis of the world with repect to the camera as blue</li></ul><h2 id="An-example-of-how-to-read-rotation-matrix-and-tranlation-vector">An example of how to read rotation matrix and tranlation vector</h2><p><img src="rotation_matrix.png" alt="rotation_matrix"></p><ul><li>x is parellel to r1 but opposite direction, so r1 is (-1,0,0)’</li><li>y is parellel to r3 but opposite direction, so r2 is (0,0,-1)’</li><li>z is parellel to r2 but opposite direction, so r3 is (0,-1,0)’</li></ul><p><img src="read_translation.png" alt="read_translation"><br>Reading translation is simply read the origin of world to origin of camera. In this case, origin goes toward y direction for 5, and z direction for 10.<br><strong>Important:</strong> the vectors of rotation matrix have to be orthogonal to each other and determinant of rotation matrix has to equal one.</p><h2 id="body-coordinate-system">body coordinate system</h2><p>What if we have one more more coordinate system which is the body coordinates?<br><img src="transform_coordinate.png" alt="transform_coordinate"><br>It will be the same idea of using rotation and translation, but we have a simpler expression which is to use a 4x4 matrix.</p><h2 id="inverse-transformation">inverse transformation</h2><p><img src="inverse_transformation.png" alt="inverse_transformation"><br>Since we know the translation is the vector from camera’s origin to world’s origin, then inverse transformation is from world’s origin back to camera’s origin when keeping the rotation unchanged.</p><h2 id="Alternative-way-to-find-coordinates-after-transformation">Alternative way to find coordinates after transformation</h2><p><img src="golden_fule.png" alt="golden_fule"><br>The approach previously is more intuition-based I think. If you prefer mathematical computation, the formula can be applied to find the coordinates after transformation. Remember to put translation in front of rotations.</p><p><img src="rotation_rule.png" alt="rotation_rule"><br>This is a picture I found from wikipedia if you’re not familiar with rotation with repect to a certain axis.</p><h1>Pinhole Camera Model</h1><p><img src="camera_model.png" alt="camera_model"></p><ul><li>Pink: camera body (camera oritentation and position in the world)</li><li>Blue: sensor (transform optical measurement into pixel)</li><li>Red: focal length</li></ul><p><img src="pinhole_camera.png" alt="pinhole_camera"><br>In daily life, the camera is not a canvas but a reverse canvas. The image plane is behind us rather than in front of us, but we can imagine there is a virtual image in front of us.</p><h2 id="1st-Person-Camera-World">1st Person Camera World</h2><p><img src="1st_person.png" alt="1st_person"></p><p>How to define is that x-axis is the horizontal line in front of you, and y-axis is a vertical line in front of you, then z-axis is pointing toward/from you due to right-hand rule.</p><p>The point c in the image in you, as the center of the universe (0,0,0), and there is a xy-plane in front of you. The item we see through the image plane can be shrinked to the image plane through the equations above.</p><p>Since the image plane is fixed-size. If I take image plane further out, away from object, then object image will be smaller.</p><p>At this point, it’s good to think about:</p><ul><li>Where is the center of projection?</li><li>What is the focal length?</li></ul><h2 id="Let’s-do-a-experiement">Let’s do a experiement</h2><ol><li><p>Draw a set of rediating line on a piece of paper.</p></li><li><p>Place your phone camera as the picture shown.<br><img src="locating_center.png" alt="locating_center"></p></li><li><p>Look at the image in your camera, and move your camera back and forth until you see every line is parellel to each other.<br><img src="parellel_lines.gif" alt="parellel_lines"><br>(from my iPhone)</p></li><li><p>Draw a line to record the camera position.</p></li></ol><p>This process can be illustrated in this diagram.<br><img src="locate_center.png" alt="locate_center"></p><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> Study Note </tag>
            
            <tag> Coursera </tag>
            
            <tag> Robotics </tag>
            
            <tag> Perception </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Build a blog with Hexo</title>
      <link href="/2020/08/29/Build-a-blog-with-Hexo/"/>
      <url>/2020/08/29/Build-a-blog-with-Hexo/</url>
      
        <content type="html"><![CDATA[<h2 id="Setup">Setup</h2><ol><li><p>Install <code>Node.js</code>.</p><ul><li>MacOS: Download <code>Node.js</code> from <code>https://nodejs.org/</code>. When you install <code>Node.js</code>, <code>npm</code> will be installed automatically.</li><li>Ubuntu 20.04: Download them from command line.<pre class=" language-language-bash"><code class="language-language-bash">$ sudo apt update$ sudo apt install nodejs$ sudo apt install npm</code></pre></li></ul></li><li><p>When you install <code>Node.js</code>, <code>npm</code> will be installed automatically.</p></li><li><p>Make sure you have <code>git</code> installed.</p></li><li><p>Download Hexo’s framework using <code>npm</code>.</p><pre class=" language-language-bash"><code class="language-language-bash">$ sudo npm install -g hexo-cli</code></pre></li></ol><hr><h2 id="Initialization">Initialization</h2><ol><li><p>Make a new folder and navigate to it through terminal.</p></li><li><p>Initialize a blog with Hexo command line under the folder.</p><pre class=" language-language-bash"><code class="language-language-bash">$ hexo init</code></pre></li><li><p>Start a local server to host your blog.</p><pre class=" language-language-bash"><code class="language-language-bash">$ hexo server</code></pre></li><li><p>Now open a browser, and type <code>localhost:4000</code> in address bar. You will see the blog that you just created!</p></li></ol><hr><h2 id="Host-the-blog-on-Github">Host the blog on Github</h2><ol><li><p>In order to have others see your blog, you have to find a place to host your blog. Here I suggest using GitHub page, because each Github account can have a free domain ending with <code>github.io</code>.<br>npm install hexo-deployer-git --save</p></li><li><p>Go to Github, create a new repository and name it <code>web-name.github.io</code> (<strong>replace <code>web-name</code> with the name that you want</strong>). Make sure the repository is <strong>public</strong>.<br><img src="init-github-io.png" alt="Make a new repo to host blogs"></p></li><li><p>Open <code>_config.yml</code> with your favorite editor, and configure it as follows:</p><pre class=" language-language-yml"><code class="language-language-yml">deploy:  type: git  repo: https://github.com/GaoxiangLuo/web-name.github.io.git  branch: master</code></pre></li><li><p>Deploy your blog onto Github, login with username and password if being prompted</p><pre class=" language-language-bash"><code class="language-language-bash">$ hexo deploy</code></pre></li><li><p>Congratulation! You blog has been published at <code>web-name.github.io</code>!</p></li></ol><hr><div style="text-align: right"> To be continued... </div>]]></content>
      
      
      
        <tags>
            
            <tag> How-to </tag>
            
            <tag> Web Dev </tag>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>I started my blog</title>
      <link href="/2020/08/29/I-started-my-blog/"/>
      <url>/2020/08/29/I-started-my-blog/</url>
      
        <content type="html"><![CDATA[<p>Hey all! I finally started my own blog, since I’ve been captured by how elegant the markdown language is. There are some reasons for me to start blogging.  Firstly, it motivates me to summarize the cool stuff that I’ve learned, which helps me to review and gain deeper insights of those knowledge. Secondly, I hope my blog will be a place where people can know me more; meanwhile, I would like to contribute my effort to the overall ComSci society, in publishing blogs that help people resolve technical issues. I hope it’s not too late to start as a rising junior undergrad, and I would like to see my blog grows as I grow!</p>]]></content>
      
      
      
        <tags>
            
            <tag> Log </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
